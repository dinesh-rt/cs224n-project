{"url": "https://github.com/google/grumpy/blob/3ec87959189cfcdeae82eb68a47648ac25ceb10b/third_party/pypy/_struct.py#L101-L108", "repo": "grumpy", "func_name": "pack_unsigned_int", "original_string": ["def pack_unsigned_int(number, size, le):\n", "  if not isinstance(number, int):\n", "    raise StructError(\"argument for i,I,l,L,q,Q,h,H must be integer\")\n", "  if number < 0:\n", "    raise TypeError(\"can't convert negative long to unsigned\")\n", "  if number > (1 << (8 * size)) - 1:\n", "    raise OverflowError(\"Number:%i too large to convert\" % number)\n", "  return pack_int(number, size, le)\n"], "language": "python", "code": "def pack_unsigned_int(number, size, le):\n    if not isinstance(number, int):\n        raise StructError('argument for i,I,l,L,q,Q,h,H must be integer')\n    if number < 0:\n        raise TypeError(\"can't convert negative long to unsigned\")\n    if number > (1 << 8 * size) - 1:\n        raise OverflowError('Number:%i too large to convert' % number)\n    return pack_int(number, size, le)\n", "code_tokens": ["pack", "unsigned", "int", "number", "size", "le", "if", "not", "isinstance", "number", "int", "raise", "structerror", "argument", "for", "must", "be", "integer", "if", "number", "0", "raise", "typeerror", "can", "convert", "negative", "long", "to", "unsigned", "if", "number", "1", "8", "size", "1", "raise", "overflowerror", "number", "too", "large", "to", "convert", "number", "return", "pack", "int", "number", "size", "le"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 439}
{"url": "https://github.com/gunthercox/ChatterBot/blob/1a03dcb45cba7bdc24d3db5e750582e0cb1518e2/chatterbot/parsing.py#L506-L517", "repo": "ChatterBot", "func_name": "convert_string_to_number", "original_string": ["def convert_string_to_number(value):\n", "    \"\"\"\n", "    Convert strings to numbers\n", "    \"\"\"\n", "    if value is None:\n", "        return 1\n", "    if isinstance(value, int):\n", "        return value\n", "    if value.isdigit():\n", "        return int(value)\n", "    num_list = map(lambda s: NUMBERS[s], re.findall(numbers + '+', value.lower()))\n", "    return sum(num_list)\n"], "language": "python", "code": "def convert_string_to_number(value):\n    \"\"\"\"\"\"\n    if value is None:\n        return 1\n    if isinstance(value, int):\n        return value\n    if value.isdigit():\n        return int(value)\n    num_list = map(lambda s: NUMBERS[s], re.findall(numbers + '+', value.\n        lower()))\n    return sum(num_list)\n", "code_tokens": ["convert", "string", "to", "number", "value", "if", "value", "is", "none", "return", "1", "if", "isinstance", "value", "int", "return", "value", "if", "value", "isdigit", "return", "int", "value", "num", "list", "map", "lambda", "numbers", "re", "findall", "numbers", "value", "lower", "return", "sum", "num", "list"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 440}
{"url": "https://github.com/klen/zeta-library/blob/b76f89000f467e10ddcc94aded3f6c6bf4a0e5bd/zetalibrary/scss/__init__.py#L1898-L1910", "repo": "zeta-library", "func_name": "to_str", "original_string": ["def to_str(num):\n", "    if isinstance(num, dict):\n", "        s = sorted(num.items())\n", "        sp = num.get('_', '')\n", "        return (sp + ' ').join(to_str(v) for n, v in s if n != '_')\n", "    elif isinstance(num, float):\n", "        num = ('%0.03f' % round(num, 3)).rstrip('0').rstrip('.')\n", "        return num\n", "    elif isinstance(num, bool):\n", "        return 'true' if num else 'false'\n", "    elif num is None:\n", "        return ''\n", "    return str(num)\n"], "language": "python", "code": "def to_str(num):\n    if isinstance(num, dict):\n        s = sorted(num.items())\n        sp = num.get('_', '')\n        return (sp + ' ').join(to_str(v) for n, v in s if n != '_')\n    elif isinstance(num, float):\n        num = ('%0.03f' % round(num, 3)).rstrip('0').rstrip('.')\n        return num\n    elif isinstance(num, bool):\n        return 'true' if num else 'false'\n    elif num is None:\n        return ''\n    return str(num)\n", "code_tokens": ["to", "str", "num", "if", "isinstance", "num", "dict", "sorted", "num", "items", "sp", "num", "get", "return", "sp", "join", "to", "str", "for", "in", "if", "elif", "isinstance", "num", "float", "num", "0", "round", "num", "3", "rstrip", "0", "rstrip", "return", "num", "elif", "isinstance", "num", "bool", "return", "true", "if", "num", "else", "false", "elif", "num", "is", "none", "return", "return", "str", "num"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 441}
{"url": "https://github.com/LettError/MutatorMath/blob/10318fc4e7c9cee9df6130826829baea3054a42b/Lib/mutatorMath/objects/location.py#L14-L29", "repo": "MutatorMath", "func_name": "numberToString", "original_string": ["def numberToString(value):\n", "    # return a nicely formatted string of this value\n", "    # return tuples as a tuple-looking string with formatted numbers\n", "    # return ints as ints, no commas\n", "    # return floats as compact rounded value\n", "    if value is None:\n", "        return \"None\"\n", "    if type(value)==tuple:\n", "        t = []\n", "        for v in value:\n", "            t.append(numberToString(v))\n", "        return \"(%s)\"%(\",\".join(t))\n", "    if int(value) == value:\n", "        # it is an int\n", "        return \"%d\"%(value)\n", "    return \"%3.3f\"%value\n"], "language": "python", "code": "def numberToString(value):\n    if value is None:\n        return 'None'\n    if type(value) == tuple:\n        t = []\n        for v in value:\n            t.append(numberToString(v))\n        return '(%s)' % ','.join(t)\n    if int(value) == value:\n        return '%d' % value\n    return '%3.3f' % value\n", "code_tokens": ["numbertostring", "value", "if", "value", "is", "none", "return", "none", "if", "type", "value", "tuple", "for", "in", "value", "append", "numbertostring", "return", "join", "if", "int", "value", "value", "return", "value", "return", "3", "value"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 442}
{"url": "https://github.com/balemessenger/bale-bot-python/blob/92bfd60016b075179f16c212fc3fc20a4e5f16f4/balebot/utils/util_functions.py#L70-L75", "repo": "bale-bot-python", "func_name": "standardize_phone_number", "original_string": ["def standardize_phone_number(number):\n", "    number_str = str(number)\n", "    if number_str.startswith(\"0098\"):\n", "        return \"+98\" + number_str[4:]\n", "    elif number_str.startswith(\"0\"):\n", "        return \"+98\" + number_str[1:]\n"], "language": "python", "code": "def standardize_phone_number(number):\n    number_str = str(number)\n    if number_str.startswith('0098'):\n        return '+98' + number_str[4:]\n    elif number_str.startswith('0'):\n        return '+98' + number_str[1:]\n", "code_tokens": ["standardize", "phone", "number", "number", "number", "str", "str", "number", "if", "number", "str", "startswith", "0098", "return", "98", "number", "str", "4", "elif", "number", "str", "startswith", "0", "return", "98", "number", "str", "1"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 443}
{"url": "https://github.com/pasztorpisti/json-cfg/blob/4627b14a92521ef8a39bbedaa7af8d380d406d07/src/jsoncfg/tree_python.py#L61-L69", "repo": "json-cfg", "func_name": "default_number_converter", "original_string": ["def default_number_converter(number_str):\n", "    \"\"\"\n", "    Converts the string representation of a json number into its python object equivalent, an\n", "    int, long, float or whatever type suits.\n", "    \"\"\"\n", "    is_int = (number_str.startswith('-') and number_str[1:].isdigit()) or number_str.isdigit()\n", "    # FIXME: this handles a wider range of numbers than allowed by the json standard,\n", "    # etc.: float('nan') and float('inf'). But is this a problem?\n", "    return int(number_str) if is_int else float(number_str)\n"], "language": "python", "code": "def default_number_converter(number_str):\n    \"\"\"\"\"\"\n    is_int = number_str.startswith('-') and number_str[1:].isdigit(\n        ) or number_str.isdigit()\n    return int(number_str) if is_int else float(number_str)\n", "code_tokens": ["default", "number", "converter", "number", "str", "is", "int", "number", "str", "startswith", "and", "number", "str", "1", "isdigit", "or", "number", "str", "isdigit", "return", "int", "number", "str", "if", "is", "int", "else", "float", "number", "str"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 444}
{"url": "https://github.com/nickmckay/LiPD-utilities/blob/5dab6bbeffc5effd68e3a6beaca6b76aa928e860/Python/lipd/noaa_lpd.py#L546-L556", "repo": "LiPD-utilities", "func_name": "__convert_num", "original_string": ["    def __convert_num(number):\n", "        \"\"\"\n", "        All path items are automatically strings. If you think it's an int or float, this attempts to convert it.\n", "        :param str number:\n", "        :return float or str:\n", "        \"\"\"\n", "        try:\n", "            return float(number)\n", "        except ValueError as e:\n", "            logger_noaa_lpd.warn(\"convert_num: ValueError: {}\".format(e))\n", "            return number\n"], "language": "python", "code": "def __convert_num(number):\n    \"\"\"\"\"\"\n    try:\n        return float(number)\n    except ValueError as e:\n        logger_noaa_lpd.warn('convert_num: ValueError: {}'.format(e))\n        return number\n", "code_tokens": ["convert", "num", "number", "try", "return", "float", "number", "except", "valueerror", "as", "logger", "noaa", "lpd", "warn", "convert", "num", "valueerror", "format", "return", "number"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 445}
{"url": "https://github.com/lawsie/guizero/blob/84c7f0b314fa86f9fc88eb11c9a0f6c4b57155e2/examples/binary_counter.py#L6-L11", "repo": "guizero", "func_name": "to_str", "original_string": ["def to_str(n,base):\n", "    convert_string = \"0123456789ABCDEF\"\n", "    if n < base:\n", "        return convert_string[n]\n", "    else:\n", "        return to_str(n//base,base) + convert_string[n%base]\n"], "language": "python", "code": "def to_str(n, base):\n    convert_string = '0123456789ABCDEF'\n    if n < base:\n        return convert_string[n]\n    else:\n        return to_str(n // base, base) + convert_string[n % base]\n", "code_tokens": ["to", "str", "base", "convert", "string", "if", "base", "return", "convert", "string", "else", "return", "to", "str", "base", "base", "convert", "string", "base"], "docstring": "convert string to number", "docstring_tokens": ["convert", "string", "to", "number"], "idx": 446}
{"url": "https://github.com/mapbox/mapbox-sdk-py/blob/72d19dbcf2d254a6ea08129a726471fd21f13023/mapbox/services/base.py#L122-L144", "repo": "mapbox-sdk-py", "func_name": "handle_http_error", "original_string": ["    def handle_http_error(self, response, custom_messages=None,\n", "                          raise_for_status=False):\n", "        \"\"\"Converts service errors to Python exceptions\n", "\n", "        Parameters\n", "        ----------\n", "        response : requests.Response\n", "            A service response.\n", "        custom_messages : dict, optional\n", "            A mapping of custom exception messages to HTTP status codes.\n", "        raise_for_status : bool, optional\n", "            If True, the requests library provides Python exceptions.\n", "\n", "        Returns\n", "        -------\n", "        None\n", "        \"\"\"\n", "        if not custom_messages:\n", "            custom_messages = {}\n", "        if response.status_code in custom_messages.keys():\n", "            raise errors.HTTPError(custom_messages[response.status_code])\n", "        if raise_for_status:\n", "            response.raise_for_status()\n"], "language": "python", "code": "def handle_http_error(self, response, custom_messages=None,\n    raise_for_status=False):\n    \"\"\"\"\"\"\n    if not custom_messages:\n        custom_messages = {}\n    if response.status_code in custom_messages.keys():\n        raise errors.HTTPError(custom_messages[response.status_code])\n    if raise_for_status:\n        response.raise_for_status()\n", "code_tokens": ["handle", "http", "error", "self", "response", "custom", "messages", "none", "raise", "for", "status", "false", "if", "not", "custom", "messages", "custom", "messages", "if", "response", "status", "code", "in", "custom", "messages", "keys", "raise", "errors", "httperror", "custom", "messages", "response", "status", "code", "if", "raise", "for", "status", "response", "raise", "for", "status"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 447}
{"url": "https://github.com/lepture/flask-oauthlib/blob/9e6f152a5bb360e7496210da21561c3e6d41b0e1/flask_oauthlib/provider/oauth1.py#L902-L905", "repo": "flask-oauthlib", "func_name": "_error_response", "original_string": ["def _error_response(e):\n", "    res = make_response(e.urlencoded, e.status_code)\n", "    res.headers['Content-Type'] = 'application/x-www-form-urlencoded'\n", "    return res\n"], "language": "python", "code": "def _error_response(e):\n    res = make_response(e.urlencoded, e.status_code)\n    res.headers['Content-Type'] = 'application/x-www-form-urlencoded'\n    return res\n", "code_tokens": ["error", "response", "res", "make", "response", "urlencoded", "status", "code", "res", "headers", "content", "type", "application", "www", "form", "urlencoded", "return", "res"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 448}
{"url": "https://github.com/FelixSchwarz/pymta/blob/1884accc3311e6c2e89259784f9592314f6d34fc/pymta/session.py#L175-L180", "repo": "pymta", "func_name": "_send_custom_response", "original_string": ["    def _send_custom_response(self, reply):\n", "        code, custom_response = reply\n", "        if self._is_multiline_reply(custom_response):\n", "            self.multiline_reply(code, custom_response)\n", "        else:\n", "            self.reply(code, custom_response)\n"], "language": "python", "code": "def _send_custom_response(self, reply):\n    code, custom_response = reply\n    if self._is_multiline_reply(custom_response):\n        self.multiline_reply(code, custom_response)\n    else:\n        self.reply(code, custom_response)\n", "code_tokens": ["send", "custom", "response", "self", "reply", "code", "custom", "response", "reply", "if", "self", "is", "multiline", "reply", "custom", "response", "self", "multiline", "reply", "code", "custom", "response", "else", "self", "reply", "code", "custom", "response"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 449}
{"url": "https://github.com/nestauk/gtr/blob/49e1b8db1f4376612ea1ec8585a79375fa15a899/gtr/services/base.py#L25-L33", "repo": "gtr", "func_name": "handle_http_error", "original_string": ["    def handle_http_error(self, response, custom_messages=None,\n", "                          raise_for_status=False):\n", "        if not custom_messages:\n", "            custom_messages = {}\n", "        if response.status_code in custom_messages.keys():\n", "            raise requests.exceptions.HTTPError(\n", "                custom_messages[response.status_code])\n", "        if raise_for_status:\n", "            response.raise_for_status()\n"], "language": "python", "code": "def handle_http_error(self, response, custom_messages=None,\n    raise_for_status=False):\n    if not custom_messages:\n        custom_messages = {}\n    if response.status_code in custom_messages.keys():\n        raise requests.exceptions.HTTPError(custom_messages[response.\n            status_code])\n    if raise_for_status:\n        response.raise_for_status()\n", "code_tokens": ["handle", "http", "error", "self", "response", "custom", "messages", "none", "raise", "for", "status", "false", "if", "not", "custom", "messages", "custom", "messages", "if", "response", "status", "code", "in", "custom", "messages", "keys", "raise", "requests", "exceptions", "httperror", "custom", "messages", "response", "status", "code", "if", "raise", "for", "status", "response", "raise", "for", "status"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 450}
{"url": "https://github.com/JamesGardiner/chwrapper/blob/50f9cb2f5264c59505e8cc4e45ee6dc5d5669134/chwrapper/services/base.py#L97-L109", "repo": "chwrapper", "func_name": "handle_http_error", "original_string": ["    def handle_http_error(\n", "        self, response, ignore=None, custom_messages=None, raise_for_status=True\n", "    ):\n", "        status = response.status_code\n", "        ignore = ignore or []\n", "        custom_messages = custom_messages or {}\n", "\n", "        if status in ignore or status in self._ignore_codes:\n", "            return None\n", "        elif response.status_code in custom_messages.keys():\n", "            raise requests.exceptions.HTTPError(custom_messages[response.status_code])\n", "        elif raise_for_status:\n", "            response.raise_for_status()\n"], "language": "python", "code": "def handle_http_error(self, response, ignore=None, custom_messages=None,\n    raise_for_status=True):\n    status = response.status_code\n    ignore = ignore or []\n    custom_messages = custom_messages or {}\n    if status in ignore or status in self._ignore_codes:\n        return None\n    elif response.status_code in custom_messages.keys():\n        raise requests.exceptions.HTTPError(custom_messages[response.\n            status_code])\n    elif raise_for_status:\n        response.raise_for_status()\n", "code_tokens": ["handle", "http", "error", "self", "response", "ignore", "none", "custom", "messages", "none", "raise", "for", "status", "true", "status", "response", "status", "code", "ignore", "ignore", "or", "custom", "messages", "custom", "messages", "or", "if", "status", "in", "ignore", "or", "status", "in", "self", "ignore", "codes", "return", "none", "elif", "response", "status", "code", "in", "custom", "messages", "keys", "raise", "requests", "exceptions", "httperror", "custom", "messages", "response", "status", "code", "elif", "raise", "for", "status", "response", "raise", "for", "status"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 451}
{"url": "https://github.com/onecodex/onecodex/blob/326a0a1af140e3a57ccf31c3c9c5e17a5775c13d/onecodex/vendored/potion_client/links.py#L73-L90", "repo": "onecodex", "func_name": "raise_for_status", "original_string": ["    def raise_for_status(self, response):\n", "        http_error_msg = ''\n", "\n", "        if 400 <= response.status_code < 500:\n", "            try:\n", "                http_error_msg = response.json()\n", "            except:\n", "                http_error_msg = ('{code} Client Error: {reason} for url: {url}'.format(\n", "                    code=response.status_code, reason=response.reason, url=response.url)\n", "                )\n", "\n", "        elif 500 <= response.status_code < 600:\n", "            http_error_msg = ('{code} Server Error: {reason} for url: {url}'.format(\n", "                code=response.status_code, reason=response.reason, url=response.url)\n", "            )\n", "\n", "        if http_error_msg:\n", "            raise HTTPError(http_error_msg, response=response)\n"], "language": "python", "code": "def raise_for_status(self, response):\n    http_error_msg = ''\n    if 400 <= response.status_code < 500:\n        try:\n            http_error_msg = response.json()\n        except:\n            http_error_msg = ('{code} Client Error: {reason} for url: {url}'\n                .format(code=response.status_code, reason=response.reason,\n                url=response.url))\n    elif 500 <= response.status_code < 600:\n        http_error_msg = '{code} Server Error: {reason} for url: {url}'.format(\n            code=response.status_code, reason=response.reason, url=response.url\n            )\n    if http_error_msg:\n        raise HTTPError(http_error_msg, response=response)\n", "code_tokens": ["raise", "for", "status", "self", "response", "http", "error", "msg", "if", "400", "response", "status", "code", "500", "try", "http", "error", "msg", "response", "json", "except", "http", "error", "msg", "code", "client", "error", "reason", "for", "url", "url", "format", "code", "response", "status", "code", "reason", "response", "reason", "url", "response", "url", "elif", "500", "response", "status", "code", "600", "http", "error", "msg", "code", "server", "error", "reason", "for", "url", "url", "format", "code", "response", "status", "code", "reason", "response", "reason", "url", "response", "url", "if", "http", "error", "msg", "raise", "httperror", "http", "error", "msg", "response", "response"], "docstring": "custom http error response", "docstring_tokens": ["custom", "http", "error", "response"], "idx": 452}
{"url": "https://github.com/SmartTeleMax/iktomi/blob/80bc0f1408d63efe7f5844367d1f6efba44b35f2/iktomi/web/reverse.py#L218-L229", "repo": "iktomi", "func_name": "_build_url_silent", "original_string": ["    def _build_url_silent(self, _name, **kwargs):\n", "        subreverse = self\n", "        used_args = set()\n", "        for part in _name.split('.'):\n", "            if not subreverse._ready and subreverse._need_arguments:\n", "                used_args |= subreverse.url_arguments\n", "                subreverse = subreverse(**kwargs)\n", "            subreverse = getattr(subreverse, part)\n", "        if not subreverse._ready and subreverse._is_endpoint:\n", "            used_args |= subreverse.url_arguments\n", "            subreverse = subreverse(**kwargs)\n", "        return used_args, subreverse\n"], "language": "python", "code": "def _build_url_silent(self, _name, **kwargs):\n    subreverse = self\n    used_args = set()\n    for part in _name.split('.'):\n        if not subreverse._ready and subreverse._need_arguments:\n            used_args |= subreverse.url_arguments\n            subreverse = subreverse(**kwargs)\n        subreverse = getattr(subreverse, part)\n    if not subreverse._ready and subreverse._is_endpoint:\n        used_args |= subreverse.url_arguments\n        subreverse = subreverse(**kwargs)\n    return used_args, subreverse\n", "code_tokens": ["build", "url", "silent", "self", "name", "kwargs", "subreverse", "self", "used", "args", "set", "for", "part", "in", "name", "split", "if", "not", "subreverse", "ready", "and", "subreverse", "need", "arguments", "used", "args", "subreverse", "url", "arguments", "subreverse", "subreverse", "kwargs", "subreverse", "getattr", "subreverse", "part", "if", "not", "subreverse", "ready", "and", "subreverse", "is", "endpoint", "used", "args", "subreverse", "url", "arguments", "subreverse", "subreverse", "kwargs", "return", "used", "args", "subreverse"], "docstring": "how to reverse a string", "docstring_tokens": ["how", "to", "reverse", "a", "string"], "idx": 453}
{"url": "https://github.com/mclarkk/lifxlan/blob/ead0e3114d6aa2e5e77dab1191c13c16066c32b0/lifxlan/message.py#L126-L130", "repo": "lifxlan", "func_name": "convert_MAC_to_int", "original_string": ["def convert_MAC_to_int(addr):\n", "    reverse_bytes_str = addr.split(':')\n", "    reverse_bytes_str.reverse()\n", "    addr_str = \"\".join(reverse_bytes_str)\n", "    return int(addr_str, 16)\n"], "language": "python", "code": "def convert_MAC_to_int(addr):\n    reverse_bytes_str = addr.split(':')\n    reverse_bytes_str.reverse()\n    addr_str = ''.join(reverse_bytes_str)\n    return int(addr_str, 16)\n", "code_tokens": ["convert", "mac", "to", "int", "addr", "reverse", "bytes", "str", "addr", "split", "reverse", "bytes", "str", "reverse", "addr", "str", "join", "reverse", "bytes", "str", "return", "int", "addr", "str", "16"], "docstring": "how to reverse a string", "docstring_tokens": ["how", "to", "reverse", "a", "string"], "idx": 454}
{"url": "https://github.com/frnsys/broca/blob/7236dcf54edc0a4a54a55eb93be30800910667e7/broca/similarity/doc/wikipedia.py#L28-L41", "repo": "broca", "func_name": "compute_bridge_similarity", "original_string": ["    def compute_bridge_similarity(self, vec1, vec2):\n", "        EWP = 1 - np.multiply(vec1, vec2)\n", "\n", "        # not sure exactly how to sort the EWP vector\n", "        #EWP = sorted(EWP, reverse=True)\n", "        EWP = sorted(EWP, reverse=True)\n", "\n", "        k = 10\n", "        EWP = EWP[:k]\n", "\n", "        # The paper does not mention using logs but start to get into underflow\n", "        # issues multiplying so many decimal values\n", "        lEWP = -1 * np.log(EWP)\n", "        return 1/np.sum(lEWP)\n"], "language": "python", "code": "def compute_bridge_similarity(self, vec1, vec2):\n    EWP = 1 - np.multiply(vec1, vec2)\n    EWP = sorted(EWP, reverse=True)\n    k = 10\n    EWP = EWP[:k]\n    lEWP = -1 * np.log(EWP)\n    return 1 / np.sum(lEWP)\n", "code_tokens": ["compute", "bridge", "similarity", "self", "ewp", "1", "np", "multiply", "ewp", "sorted", "ewp", "reverse", "true", "10", "ewp", "ewp", "lewp", "1", "np", "log", "ewp", "return", "1", "np", "sum", "lewp"], "docstring": "how to reverse a string", "docstring_tokens": ["how", "to", "reverse", "a", "string"], "idx": 455}
{"url": "https://github.com/keon/algorithms/blob/4d6569464a62a75c1357acc97e2dd32ee2f9f4a3/algorithms/strings/reverse_words.py#L9-L14", "repo": "algorithms", "func_name": "reverse_words", "original_string": ["def reverse_words(string):\n", "    arr = string.strip().split()  # arr is list of words\n", "    n = len(arr)\n", "    reverse(arr, 0, n-1)\n", "\n", "    return \" \".join(arr)\n"], "language": "python", "code": "def reverse_words(string):\n    arr = string.strip().split()\n    n = len(arr)\n    reverse(arr, 0, n - 1)\n    return ' '.join(arr)\n", "code_tokens": ["reverse", "words", "string", "arr", "string", "strip", "split", "len", "arr", "reverse", "arr", "0", "1", "return", "join", "arr"], "docstring": "how to reverse a string", "docstring_tokens": ["how", "to", "reverse", "a", "string"], "idx": 456}
{"url": "https://github.com/nilp0inter/cpe/blob/670d947472a7652af5149324977b50f9a7af9bcf/cpe/cpe.py#L115-L146", "repo": "cpe", "func_name": "_trim", "original_string": ["    def _trim(cls, s):\n", "        \"\"\"\n", "        Remove trailing colons from the URI back to the first non-colon.\n", "\n", "        :param string s: input URI string\n", "        :returns: URI string with trailing colons removed\n", "        :rtype: string\n", "\n", "        TEST: trailing colons necessary\n", "\n", "        >>> s = '1:2::::'\n", "        >>> CPE._trim(s)\n", "        '1:2'\n", "\n", "        TEST: trailing colons not necessary\n", "\n", "        >>> s = '1:2:3:4:5:6'\n", "        >>> CPE._trim(s)\n", "        '1:2:3:4:5:6'\n", "        \"\"\"\n", "        reverse = s[::-1]\n", "        idx = 0\n", "        for i in range(0, len(reverse)):\n", "            if reverse[i] == \":\":\n", "                idx += 1\n", "            else:\n", "                break\n", "\n", "        # Return the substring after all trailing colons,\n", "        # reversed back to its original character order.\n", "        new_s = reverse[idx: len(reverse)]\n", "        return new_s[::-1]\n"], "language": "python", "code": "def _trim(cls, s):\n    \"\"\"\"\"\"\n    reverse = s[::-1]\n    idx = 0\n    for i in range(0, len(reverse)):\n        if reverse[i] == ':':\n            idx += 1\n        else:\n            break\n    new_s = reverse[idx:len(reverse)]\n    return new_s[::-1]\n", "code_tokens": ["trim", "cls", "reverse", "1", "idx", "0", "for", "in", "range", "0", "len", "reverse", "if", "reverse", "idx", "1", "else", "break", "new", "reverse", "idx", "len", "reverse", "return", "new", "1"], "docstring": "how to reverse a string", "docstring_tokens": ["how", "to", "reverse", "a", "string"], "idx": 457}
{"url": "https://github.com/dragnet-org/dragnet/blob/532c9d9f28e5b1b57f3cabc708218d3863a16322/dragnet/__init__.py#L9-L13", "repo": "dragnet", "func_name": "extract_content", "original_string": ["def extract_content(html, encoding=None, as_blocks=False):\n", "    if 'content' not in _LOADED_MODELS:\n", "        _LOADED_MODELS['content'] = load_pickled_model(\n", "            'kohlschuetter_readability_weninger_content_model.pkl.gz')\n", "    return _LOADED_MODELS['content'].extract(html, encoding=encoding, as_blocks=as_blocks)\n"], "language": "python", "code": "def extract_content(html, encoding=None, as_blocks=False):\n    if 'content' not in _LOADED_MODELS:\n        _LOADED_MODELS['content'] = load_pickled_model(\n            'kohlschuetter_readability_weninger_content_model.pkl.gz')\n    return _LOADED_MODELS['content'].extract(html, encoding=encoding,\n        as_blocks=as_blocks)\n", "code_tokens": ["extract", "content", "html", "encoding", "none", "as", "blocks", "false", "if", "content", "not", "in", "loaded", "models", "loaded", "models", "content", "load", "pickled", "model", "kohlschuetter", "readability", "weninger", "content", "model", "pkl", "gz", "return", "loaded", "models", "content", "extract", "html", "encoding", "encoding", "as", "blocks", "as", "blocks"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 458}
{"url": "https://github.com/monarch-initiative/dipper/blob/24cc80db355bbe15776edc5c7b41e0886959ba41/scripts/scrape-impc.py#L14-L40", "repo": "dipper", "func_name": "parse_item", "original_string": ["    def parse_item(self, response):\n", "        key = None\n", "        if re.search(r'parameterontologies', response.url) and \\\n", "            response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                         '.dark::text').extract() is not None and \\\n", "            len(response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                             '.dark::text').extract()) > 0:\n", "            key = response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                               '.dark::text').extract()[0]\n", "        elif (re.search(r'parameters', response.url) or re.search(r'protocol', response.url)) and \\\n", "            response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                         '.dark::text').extract() is not None and \\\n", "            len(response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                             '.dark::text').extract()) > 0:\n", "            key = response.css('html body div#SiteWrapper div#Content h2 span.procedurekey'\n", "                               '.dark::text').extract()[0]\n", "        elif re.search(r'procedures', response.url) and \\\n", "            response.css('html body div#SiteWrapper div#Content h2 span.pipelinekey'\n", "                         '::text').extract() is not None and \\\n", "            len(response.css('html body div#SiteWrapper div#Content h2 span.pipelinekey'\n", "                             '::text').extract()) > 0:\n", "            key = response.css('html body div#SiteWrapper div#Content h2 span.pipelinekey'\n", "                               '::text').extract()[0]\n", "        if key is not None:\n", "            yield {\n", "                key: response.url\n", "            }"], "language": "python", "code": "def parse_item(self, response):\n    key = None\n    if re.search('parameterontologies', response.url) and response.css(\n        'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n        ).extract() is not None and len(response.css(\n        'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n        ).extract()) > 0:\n        key = response.css(\n            'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n            ).extract()[0]\n    elif (re.search('parameters', response.url) or re.search('protocol',\n        response.url)) and response.css(\n        'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n        ).extract() is not None and len(response.css(\n        'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n        ).extract()) > 0:\n        key = response.css(\n            'html body div#SiteWrapper div#Content h2 span.procedurekey.dark::text'\n            ).extract()[0]\n    elif re.search('procedures', response.url) and response.css(\n        'html body div#SiteWrapper div#Content h2 span.pipelinekey::text'\n        ).extract() is not None and len(response.css(\n        'html body div#SiteWrapper div#Content h2 span.pipelinekey::text').\n        extract()) > 0:\n        key = response.css(\n            'html body div#SiteWrapper div#Content h2 span.pipelinekey::text'\n            ).extract()[0]\n    if key is not None:\n        yield {key: response.url}\n", "code_tokens": ["parse", "item", "self", "response", "key", "none", "if", "re", "search", "parameterontologies", "response", "url", "and", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "is", "not", "none", "and", "len", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "0", "key", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "0", "elif", "re", "search", "parameters", "response", "url", "or", "re", "search", "protocol", "response", "url", "and", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "is", "not", "none", "and", "len", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "0", "key", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "procedurekey", "dark", "text", "extract", "0", "elif", "re", "search", "procedures", "response", "url", "and", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "pipelinekey", "text", "extract", "is", "not", "none", "and", "len", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "pipelinekey", "text", "extract", "0", "key", "response", "css", "html", "body", "div", "sitewrapper", "div", "content", "span", "pipelinekey", "text", "extract", "0", "if", "key", "is", "not", "none", "yield", "key", "response", "url"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 459}
{"url": "https://github.com/davgeo/clear/blob/5ec85d27efd28afddfcd4c3f44df17f0115a77aa/clear/epguides.py#L219-L245", "repo": "clear", "func_name": "_ExtractDataFromShowHtml", "original_string": ["  def _ExtractDataFromShowHtml(self, html):\n", "    \"\"\"\n", "    Extracts csv show data from epguides html source.\n", "\n", "    Parameters\n", "    ----------\n", "      html : string\n", "        Block of html text\n", "\n", "    Returns\n", "    ----------\n", "       string\n", "        Show data extracted from html text in csv format.\n", "    \"\"\"\n", "    htmlLines = html.splitlines()\n", "    for count, line in enumerate(htmlLines):\n", "      if line.strip() == r'<pre>':\n", "        startLine = count+1\n", "      if line.strip() == r'</pre>':\n", "        endLine = count\n", "\n", "    try:\n", "      dataList = htmlLines[startLine:endLine]\n", "      dataString = '\\n'.join(dataList)\n", "      return dataString.strip()\n", "    except:\n", "      raise Exception(\"Show content not found - check EPGuides html formatting\")\n"], "language": "python", "code": "def _ExtractDataFromShowHtml(self, html):\n    \"\"\"\"\"\"\n    htmlLines = html.splitlines()\n    for count, line in enumerate(htmlLines):\n        if line.strip() == '<pre>':\n            startLine = count + 1\n        if line.strip() == '</pre>':\n            endLine = count\n    try:\n        dataList = htmlLines[startLine:endLine]\n        dataString = '\\n'.join(dataList)\n        return dataString.strip()\n    except:\n        raise Exception(\n            'Show content not found - check EPGuides html formatting')\n", "code_tokens": ["extractdatafromshowhtml", "self", "html", "htmllines", "html", "splitlines", "for", "count", "line", "in", "enumerate", "htmllines", "if", "line", "strip", "pre", "startline", "count", "1", "if", "line", "strip", "pre", "endline", "count", "try", "datalist", "htmllines", "startline", "endline", "datastring", "join", "datalist", "return", "datastring", "strip", "except", "raise", "exception", "show", "content", "not", "found", "check", "epguides", "html", "formatting"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 460}
{"url": "https://github.com/usc-isi-i2/etk/blob/aab077c984ea20f5e8ae33af622fe11d3c4df866/etk/cli/html_content_extractor.py#L20-L32", "repo": "etk", "func_name": "run", "original_string": ["def run(args):\n", "    \"\"\"\n", "    Args:\n", "        args (argparse.Namespace)\n", "    \"\"\"\n", "    html_content_extractor = HTMLContentExtractor()\n", "\n", "    with warnings.catch_warnings():\n", "        warnings.simplefilter('ignore')\n", "\n", "        extractions = html_content_extractor.extract(html_text=args.input_file)\n", "        for e in extractions:\n", "            print(e.value)\n"], "language": "python", "code": "def run(args):\n    \"\"\"\"\"\"\n    html_content_extractor = HTMLContentExtractor()\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore')\n        extractions = html_content_extractor.extract(html_text=args.input_file)\n        for e in extractions:\n            print(e.value)\n", "code_tokens": ["run", "args", "html", "content", "extractor", "htmlcontentextractor", "with", "warnings", "catch", "warnings", "warnings", "simplefilter", "ignore", "extractions", "html", "content", "extractor", "extract", "html", "text", "args", "input", "file", "for", "in", "extractions", "print", "value"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 461}
{"url": "https://github.com/tintinweb/pyetherchain/blob/cfeee3944b84fd12842ec3031d1d08ec7d63d33c/pyetherchain/pyetherchain.py#L185-L193", "repo": "pyetherchain", "func_name": "get_hardforks", "original_string": ["    def get_hardforks(self):\n", "        rows = self._parse_tbodies(self.session.get(\"/hardForks\").text)[0]  # only use first tbody\n", "        result = []\n", "        for col in rows:\n", "            result.append({'name': self._extract_text_from_html( col[0]),\n", "                      'on_roadmap': True if \"yes\" in col[1].lower() else False,\n", "                      'date': self._extract_text_from_html(col[2]),\n", "                      'block': int(self._extract_text_from_html(col[3]))})\n", "        return result\n"], "language": "python", "code": "def get_hardforks(self):\n    rows = self._parse_tbodies(self.session.get('/hardForks').text)[0]\n    result = []\n    for col in rows:\n        result.append({'name': self._extract_text_from_html(col[0]),\n            'on_roadmap': True if 'yes' in col[1].lower() else False,\n            'date': self._extract_text_from_html(col[2]), 'block': int(self\n            ._extract_text_from_html(col[3]))})\n    return result\n", "code_tokens": ["get", "hardforks", "self", "rows", "self", "parse", "tbodies", "self", "session", "get", "hardforks", "text", "0", "result", "for", "col", "in", "rows", "result", "append", "name", "self", "extract", "text", "from", "html", "col", "0", "on", "roadmap", "true", "if", "yes", "in", "col", "1", "lower", "else", "false", "date", "self", "extract", "text", "from", "html", "col", "2", "block", "int", "self", "extract", "text", "from", "html", "col", "3", "return", "result"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 462}
{"url": "https://github.com/usc-isi-i2/etk/blob/aab077c984ea20f5e8ae33af622fe11d3c4df866/etk/extractors/html_metadata_extractor.py#L40-L90", "repo": "etk", "func_name": "extract", "original_string": ["    def extract(self, html_text: str,\n", "                extract_title: bool = False,\n", "                extract_meta: bool = False,\n", "                extract_microdata: bool = False,\n", "                microdata_base_url: str = \"\",\n", "                extract_json_ld: bool = False,\n", "                extract_rdfa: bool = False,\n", "                rdfa_base_url: str = \"\") \\\n", "            -> List[Extraction]:\n", "        \"\"\"\n", "        Args:\n", "            html_text (str): input html string to be extracted\n", "            extract_title (bool): True if string of 'title' tag needs to be extracted, return as { \"title\": \"...\" }\n", "            extract_meta (bool): True if string of 'meta' tags needs to be extracted, return as { \"meta\": { \"author\": \"...\", ...}}\n", "            extract_microdata (bool): True if microdata needs to be extracted, returns as { \"microdata\": [...] }\n", "            microdata_base_url (str): base namespace url for microdata, empty string if no base url is specified\n", "            extract_json_ld (bool): True if json-ld needs to be extracted, return as { \"json-ld\": [...] }\n", "            extract_rdfa (bool): True if rdfs needs to be extracted, returns as { \"rdfa\": [...] }\n", "            rdfa_base_url (str): base namespace url for rdfa, empty string if no base url is specified\n", "\n", "        Returns:\n", "            List[Extraction]: the list of extraction or the empty list if there are no matches.\n", "        \"\"\"\n", "        res = list()\n", "        soup = BeautifulSoup(html_text, 'html.parser')\n", "\n", "        if soup.title and extract_title:\n", "            title = self._wrap_data(\"title\", soup.title.string.encode('utf-8').decode('utf-8'))\n", "            res.append(title)\n", "\n", "        if soup.title and extract_meta:\n", "            meta_content = self._wrap_meta_content(soup.find_all(\"meta\"))\n", "            meta_data = self._wrap_data(\"meta\", meta_content)\n", "            res.append(meta_data)\n", "\n", "        # if extract_microdata:\n", "        #     mde = MicrodataExtractor()\n", "        #     mde_data = self._wrap_data(\"microdata\", mde.extract(html_text, microdata_base_url))\n", "        #     res.append(mde_data)\n", "        #\n", "        # if extract_json_ld:\n", "        #     jslde = JsonLdExtractor()\n", "        #     jslde_data = self._wrap_data(\"json-ld\", jslde.extract(html_text))\n", "        #     res.append(jslde_data)\n", "        #\n", "        # if extract_rdfa:\n", "        #     rdfae = RDFaExtractor()\n", "        #     rdfae_data = self._wrap_data(\"rdfa\", rdfae.extract(html_text, rdfa_base_url))\n", "        #     res.append(rdfae_data)\n", "\n", "        return res\n"], "language": "python", "code": "def extract(self, html_text: str, extract_title: bool=False, extract_meta:\n    bool=False, extract_microdata: bool=False, microdata_base_url: str='',\n    extract_json_ld: bool=False, extract_rdfa: bool=False, rdfa_base_url:\n    str='') ->List[Extraction]:\n    \"\"\"\"\"\"\n    res = list()\n    soup = BeautifulSoup(html_text, 'html.parser')\n    if soup.title and extract_title:\n        title = self._wrap_data('title', soup.title.string.encode('utf-8').\n            decode('utf-8'))\n        res.append(title)\n    if soup.title and extract_meta:\n        meta_content = self._wrap_meta_content(soup.find_all('meta'))\n        meta_data = self._wrap_data('meta', meta_content)\n        res.append(meta_data)\n    return res\n", "code_tokens": ["extract", "self", "html", "text", "str", "extract", "title", "bool", "false", "extract", "meta", "bool", "false", "extract", "microdata", "bool", "false", "microdata", "base", "url", "str", "extract", "json", "ld", "bool", "false", "extract", "rdfa", "bool", "false", "rdfa", "base", "url", "str", "list", "extraction", "res", "list", "soup", "beautifulsoup", "html", "text", "html", "parser", "if", "soup", "title", "and", "extract", "title", "title", "self", "wrap", "data", "title", "soup", "title", "string", "encode", "utf", "8", "decode", "utf", "8", "res", "append", "title", "if", "soup", "title", "and", "extract", "meta", "meta", "content", "self", "wrap", "meta", "content", "soup", "find", "all", "meta", "meta", "data", "self", "wrap", "data", "meta", "meta", "content", "res", "append", "meta", "data", "return", "res"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 463}
{"url": "https://github.com/kibitzr/kibitzr/blob/749da312488f1dda1ed1093cf4c95aaac0a604f7/kibitzr/transformer/jinja_transform.py#L81-L88", "repo": "kibitzr", "func_name": "text_filter", "original_string": ["\n", "\n", "def text_filter(html):\n", "    if isinstance(html, list):\n", "        html = \"\".join(html)\n", "    ok, content = SoupOps.extract_text(html)\n", "    if ok:\n", "        return content\n"], "language": "python", "code": "def text_filter(html):\n    if isinstance(html, list):\n        html = ''.join(html)\n    ok, content = SoupOps.extract_text(html)\n    if ok:\n        return content\n", "code_tokens": ["text", "filter", "html", "if", "isinstance", "html", "list", "html", "join", "html", "ok", "content", "soupops", "extract", "text", "html", "if", "ok", "return", "content"], "docstring": "extract data from html content", "docstring_tokens": ["extract", "data", "from", "html", "content"], "idx": 464}
{"url": "https://github.com/anthonynguyen/pyrcon/blob/278cba95dd4d53a347d37acfce556ad375370e15/pyrcon/rcon.py#L97-L122", "repo": "pyrcon", "func_name": "recvall", "original_string": ["    def recvall(self, timeout=0.5):\n", "        \"\"\"\n", "        Receive the RCON command response\n", "        :param timeout: The timeout between consequent data receive\n", "        :return str: The RCON command response with header stripped out\n", "        \"\"\"\n", "        response = ''\n", "        self.socket.setblocking(False)\n", "        start = time.time()\n", "        while True:\n", "            if response and time.time() - start > timeout:\n", "                break\n", "            elif time.time() - start > timeout * 2:\n", "                break\n", "\n", "            try:\n", "                data = self.socket.recv(4096)\n", "                if data:\n", "                    response += data.replace(self._rconreplystring, '')\n", "                    start = time.time()\n", "                else:\n", "                    time.sleep(0.1)\n", "            except socket.error:\n", "                pass\n", "\n", "        return response.strip()\n"], "language": "python", "code": "def recvall(self, timeout=0.5):\n    \"\"\"\"\"\"\n    response = ''\n    self.socket.setblocking(False)\n    start = time.time()\n    while True:\n        if response and time.time() - start > timeout:\n            break\n        elif time.time() - start > timeout * 2:\n            break\n        try:\n            data = self.socket.recv(4096)\n            if data:\n                response += data.replace(self._rconreplystring, '')\n                start = time.time()\n            else:\n                time.sleep(0.1)\n        except socket.error:\n            pass\n    return response.strip()\n", "code_tokens": ["recvall", "self", "timeout", "0", "5", "response", "self", "socket", "setblocking", "false", "start", "time", "time", "while", "true", "if", "response", "and", "time", "time", "start", "timeout", "break", "elif", "time", "time", "start", "timeout", "2", "break", "try", "data", "self", "socket", "recv", "4096", "if", "data", "response", "data", "replace", "self", "rconreplystring", "start", "time", "time", "else", "time", "sleep", "0", "1", "except", "socket", "error", "pass", "return", "response", "strip"], "docstring": "socket recv timeout", "docstring_tokens": ["socket", "recv", "timeout"], "idx": 465}
{"url": "https://github.com/AirtestProject/Poco/blob/2c559a586adf3fd11ee81cabc446d4d3f6f2d119/poco/utils/simplerpc/transport/tcp/main.py#L34-L40", "repo": "Poco", "func_name": "recv", "original_string": ["    def recv(self):\n", "        try:\n", "            msg_bytes = self.c.recv()\n", "        except socket.timeout:\n", "            # print(\"socket recv timeout\")\n", "            msg_bytes = b\"\"\n", "        return self.prot.input(msg_bytes)\n"], "language": "python", "code": "def recv(self):\n    try:\n        msg_bytes = self.c.recv()\n    except socket.timeout:\n        msg_bytes = b''\n    return self.prot.input(msg_bytes)\n", "code_tokens": ["recv", "self", "try", "msg", "bytes", "self", "recv", "except", "socket", "timeout", "msg", "bytes", "return", "self", "prot", "input", "msg", "bytes"], "docstring": "socket recv timeout", "docstring_tokens": ["socket", "recv", "timeout"], "idx": 466}
{"url": "https://github.com/cablehead/vanilla/blob/c9f5b86f45720a30e8840fb68b1429b919c4ca66/vanilla/message.py#L57-L58", "repo": "vanilla", "func_name": "recv_n", "original_string": ["    def recv_n(self, n, timeout=-1):\n", "        return self.recver.recv_n(n, timeout=timeout)\n"], "language": "python", "code": "def recv_n(self, n, timeout=-1):\n    return self.recver.recv_n(n, timeout=timeout)\n", "code_tokens": ["recv", "self", "timeout", "1", "return", "self", "recver", "recv", "timeout", "timeout"], "docstring": "socket recv timeout", "docstring_tokens": ["socket", "recv", "timeout"], "idx": 467}
{"url": "https://github.com/nfcpy/nfcpy/blob/6649146d1afdd5e82b2b6b1ea00aa58d50785117/src/nfc/snep/client.py#L51-L74", "repo": "nfcpy", "func_name": "recv_response", "original_string": ["def recv_response(socket, acceptable_length, timeout):\n", "    if socket.poll(\"recv\", timeout):\n", "        snep_response = socket.recv()\n", "\n", "        if len(snep_response) < 6:\n", "            log.debug(\"snep response initial fragment too short\")\n", "            return None\n", "\n", "        version, status, length = struct.unpack(\">BBL\", snep_response[:6])\n", "\n", "        if length > acceptable_length:\n", "            log.debug(\"snep response exceeds acceptable length\")\n", "            return None\n", "\n", "        if len(snep_response) - 6 < length:\n", "            # request remaining fragments\n", "            socket.send(b\"\\x10\\x00\\x00\\x00\\x00\\x00\")\n", "            while len(snep_response) - 6 < length:\n", "                if socket.poll(\"recv\", timeout):\n", "                    snep_response += socket.recv()\n", "                else:\n", "                    return None\n", "\n", "        return bytearray(snep_response)\n"], "language": "python", "code": "def recv_response(socket, acceptable_length, timeout):\n    if socket.poll('recv', timeout):\n        snep_response = socket.recv()\n        if len(snep_response) < 6:\n            log.debug('snep response initial fragment too short')\n            return None\n        version, status, length = struct.unpack('>BBL', snep_response[:6])\n        if length > acceptable_length:\n            log.debug('snep response exceeds acceptable length')\n            return None\n        if len(snep_response) - 6 < length:\n            socket.send(b'\\x10\\x00\\x00\\x00\\x00\\x00')\n            while len(snep_response) - 6 < length:\n                if socket.poll('recv', timeout):\n                    snep_response += socket.recv()\n                else:\n                    return None\n        return bytearray(snep_response)\n", "code_tokens": ["recv", "response", "socket", "acceptable", "length", "timeout", "if", "socket", "poll", "recv", "timeout", "snep", "response", "socket", "recv", "if", "len", "snep", "response", "6", "log", "debug", "snep", "response", "initial", "fragment", "too", "short", "return", "none", "version", "status", "length", "struct", "unpack", "bbl", "snep", "response", "6", "if", "length", "acceptable", "length", "log", "debug", "snep", "response", "exceeds", "acceptable", "length", "return", "none", "if", "len", "snep", "response", "6", "length", "socket", "send", "while", "len", "snep", "response", "6", "length", "if", "socket", "poll", "recv", "timeout", "snep", "response", "socket", "recv", "else", "return", "none", "return", "bytearray", "snep", "response"], "docstring": "socket recv timeout", "docstring_tokens": ["socket", "recv", "timeout"], "idx": 468}
{"url": "https://github.com/rameshg87/pyremotevbox/blob/123dffff27da57c8faa3ac1dd4c68b1cf4558b1a/pyremotevbox/ZSI/wstools/TimeoutSocket.py#L90-L93", "repo": "pyremotevbox", "func_name": "recv", "original_string": ["    def recv(self, amt, flags=0):\n", "        if select.select([self.sock], [], [], self.timeout)[0]:\n", "            return self.sock.recv(amt, flags)\n", "        raise TimeoutError('socket recv() timeout.')\n"], "language": "python", "code": "def recv(self, amt, flags=0):\n    if select.select([self.sock], [], [], self.timeout)[0]:\n        return self.sock.recv(amt, flags)\n    raise TimeoutError('socket recv() timeout.')\n", "code_tokens": ["recv", "self", "amt", "flags", "0", "if", "select", "select", "self", "sock", "self", "timeout", "0", "return", "self", "sock", "recv", "amt", "flags", "raise", "timeouterror", "socket", "recv", "timeout"], "docstring": "socket recv timeout", "docstring_tokens": ["socket", "recv", "timeout"], "idx": 469}
{"url": "https://github.com/patarapolw/AnkiTools/blob/fab6836dfd9cf5171d9cbff5c55fbb14d2786f05/AnkiTools/editor.py#L53-L59", "repo": "AnkiTools", "func_name": "unzip", "original_string": ["    def unzip(self, in_file, out_file):\n", "        with ZipFile(in_file) as zf:\n", "            zf.extract('collection.anki2', path=self.tempdir)\n", "        shutil.move(os.path.join(self.tempdir, 'collection.anki2'),\n", "                    out_file)\n", "\n", "        return out_file\n"], "language": "python", "code": "def unzip(self, in_file, out_file):\n    with ZipFile(in_file) as zf:\n        zf.extract('collection.anki2', path=self.tempdir)\n    shutil.move(os.path.join(self.tempdir, 'collection.anki2'), out_file)\n    return out_file\n", "code_tokens": ["unzip", "self", "in", "file", "out", "file", "with", "zipfile", "in", "file", "as", "zf", "zf", "extract", "collection", "path", "self", "tempdir", "shutil", "move", "os", "path", "join", "self", "tempdir", "collection", "out", "file", "return", "out", "file"], "docstring": "unzipping large files", "docstring_tokens": ["unzipping", "large", "files"], "idx": 470}
{"url": "https://github.com/milinda/htrc-sdk-for-python/blob/d08dbba1a441dcb2bade47deaebc07be68c3a173/htrc/utils.py#L45-L62", "repo": "htrc-sdk-for-python", "func_name": "unzip", "original_string": ["def unzip(zip_content, dest_dir):\n", "    # From http://stackoverflow.com/a/12886818\n", "    with zipfile.ZipFile(zip_content, \"r\") as zf:\n", "        for member in zf.infolist():\n", "            # Path traversal defense copied from\n", "            # http://hg.python.org/cpython/file/tip/Lib/http/server.py#l789\n", "            words = member.filename.split('/')\n", "            path = dest_dir\n", "            for word in words[:-1]:\n", "                drive, word = os.path.splitdrive(word)\n", "                head, word = os.path.split(word)\n", "\n", "                if word in (os.curdir, os.pardir, ''):\n", "                    continue\n", "\n", "                path = os.path.join(path, word)\n", "\n", "            zf.extract(member, path)"], "language": "python", "code": "def unzip(zip_content, dest_dir):\n    with zipfile.ZipFile(zip_content, 'r') as zf:\n        for member in zf.infolist():\n            words = member.filename.split('/')\n            path = dest_dir\n            for word in words[:-1]:\n                drive, word = os.path.splitdrive(word)\n                head, word = os.path.split(word)\n                if word in (os.curdir, os.pardir, ''):\n                    continue\n                path = os.path.join(path, word)\n            zf.extract(member, path)\n", "code_tokens": ["unzip", "zip", "content", "dest", "dir", "with", "zipfile", "zipfile", "zip", "content", "as", "zf", "for", "member", "in", "zf", "infolist", "words", "member", "filename", "split", "path", "dest", "dir", "for", "word", "in", "words", "1", "drive", "word", "os", "path", "splitdrive", "word", "head", "word", "os", "path", "split", "word", "if", "word", "in", "os", "curdir", "os", "pardir", "continue", "path", "os", "path", "join", "path", "word", "zf", "extract", "member", "path"], "docstring": "unzipping large files", "docstring_tokens": ["unzipping", "large", "files"], "idx": 471}
{"url": "https://github.com/JIC-CSB/jicbioimage.transform/blob/494c282d964c3a9b54c2a1b3730f5625ea2a494b/appveyor/install.py#L19-L23", "repo": "jicbioimage.transform", "func_name": "unzip_file", "original_string": ["def unzip_file(zip_fname):\n", "    \"\"\"Unzip the zip_fname in the current directory.\"\"\" \n", "    print(\"Unzipping {}\".format(zip_fname))\n", "    with zipfile.ZipFile(zip_fname) as zf:\n", "        zf.extractall()\n"], "language": "python", "code": "def unzip_file(zip_fname):\n    \"\"\"\"\"\"\n    print('Unzipping {}'.format(zip_fname))\n    with zipfile.ZipFile(zip_fname) as zf:\n        zf.extractall()\n", "code_tokens": ["unzip", "file", "zip", "fname", "print", "unzipping", "format", "zip", "fname", "with", "zipfile", "zipfile", "zip", "fname", "as", "zf", "zf", "extractall"], "docstring": "unzipping large files", "docstring_tokens": ["unzipping", "large", "files"], "idx": 472}
{"url": "https://github.com/nvbn/thefuck/blob/40ab4eb62db57627bff10cf029d29c94704086a2/thefuck/rules/dirty_unzip.py#L15-L25", "repo": "thefuck", "func_name": "_zip_file", "original_string": ["def _zip_file(command):\n", "    # unzip works that way:\n", "    # unzip [-flags] file[.zip] [file(s) ...] [-x file(s) ...]\n", "    #                ^          ^ files to unzip from the archive\n", "    #                archive to unzip\n", "    for c in command.script_parts[1:]:\n", "        if not c.startswith('-'):\n", "            if c.endswith('.zip'):\n", "                return c\n", "            else:\n", "                return u'{}.zip'.format(c)\n"], "language": "python", "code": "def _zip_file(command):\n    for c in command.script_parts[1:]:\n        if not c.startswith('-'):\n            if c.endswith('.zip'):\n                return c\n            else:\n                return u'{}.zip'.format(c)\n", "code_tokens": ["zip", "file", "command", "for", "in", "command", "script", "parts", "1", "if", "not", "startswith", "if", "endswith", "zip", "return", "else", "return", "zip", "format"], "docstring": "unzipping large files", "docstring_tokens": ["unzipping", "large", "files"], "idx": 473}
{"url": "https://github.com/wolfhong/formic/blob/0d81eb88dcbb6fa705194fc6ccf2993f4abbaa76/formic/formic.py#L182-L187", "repo": "formic", "func_name": "match", "original_string": ["    def match(self, string):\n", "        \"\"\"Returns True if the argument matches the constant.\"\"\"\n", "        if self.casesensitive:\n", "            return self.pattern == os.path.normcase(string)\n", "        else:\n", "            return self.pattern.lower() == os.path.normcase(string).lower()\n"], "language": "python", "code": "def match(self, string):\n    \"\"\"\"\"\"\n    if self.casesensitive:\n        return self.pattern == os.path.normcase(string)\n    else:\n        return self.pattern.lower() == os.path.normcase(string).lower()\n", "code_tokens": ["match", "self", "string", "if", "self", "casesensitive", "return", "self", "pattern", "os", "path", "normcase", "string", "else", "return", "self", "pattern", "lower", "os", "path", "normcase", "string", "lower"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 474}
{"url": "https://github.com/spyder-ide/spyder/blob/f76836ce1b924bcc4efd3f74f2960d26a4e528e0/spyder/utils/stringmatching.py#L18-L47", "repo": "spyder", "func_name": "get_search_regex", "original_string": ["\n", "def get_search_regex(query, ignore_case=True):\n", "    \"\"\"Returns a compiled regex pattern to search for query letters in order.\n", "\n", "    Parameters\n", "    ----------\n", "    query : str\n", "        String to search in another string (in order of character occurrence).\n", "    ignore_case : True\n", "        Optional value perform a case insensitive search (True by default).\n", "\n", "    Returns\n", "    -------\n", "    pattern : SRE_Pattern\n", "\n", "    Notes\n", "    -----\n", "    This function adds '.*' between the query characters and compiles the\n", "    resulting regular expression.\n", "    \"\"\"\n", "    regex_text = [char for char in query if char != ' ']\n", "    regex_text = '.*'.join(regex_text)\n", "\n", "    regex = u'({0})'.format(regex_text)\n", "\n", "    if ignore_case:\n", "        pattern = re.compile(regex, re.IGNORECASE)\n", "    else:\n", "        pattern = re.compile(regex)\n", "\n"], "language": "python", "code": "def get_search_regex(query, ignore_case=True):\n    \"\"\"\"\"\"\n    regex_text = [char for char in query if char != ' ']\n    regex_text = '.*'.join(regex_text)\n    regex = u'({0})'.format(regex_text)\n    if ignore_case:\n        pattern = re.compile(regex, re.IGNORECASE)\n    else:\n        pattern = re.compile(regex)\n", "code_tokens": ["get", "search", "regex", "query", "ignore", "case", "true", "regex", "text", "char", "for", "char", "in", "query", "if", "char", "regex", "text", "join", "regex", "text", "regex", "0", "format", "regex", "text", "if", "ignore", "case", "pattern", "re", "compile", "regex", "re", "ignorecase", "else", "pattern", "re", "compile", "regex"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 475}
{"url": "https://github.com/refnode/liquid/blob/8b2b5efc635b0dbfe610db9036fdb4ae3e3d5439/src/liquid/strscan.py#L516-L535", "repo": "liquid", "func_name": "get_regex", "original_string": ["def get_regex(regex):\n", "    \"\"\"\n", "    Ensure we have a compiled regular expression object.\n", "\n", "        >>> import re\n", "        >>> get_regex('string') # doctest: +ELLIPSIS\n", "        <_sre.SRE_Pattern object at 0x...>\n", "        >>> pattern = re.compile(r'string')\n", "        >>> get_regex(pattern) is pattern\n", "        True\n", "        >>> get_regex(3) # doctest: +ELLIPSIS\n", "        Traceback (most recent call last):\n", "        ...\n", "        TypeError: Invalid regex type: 3\n", "    \"\"\"\n", "    if isinstance(regex, basestring):\n", "        return re.compile(regex)\n", "    elif not isinstance(regex, re._pattern_type):\n", "        raise TypeError(\"Invalid regex type: %r\" % (regex,))\n", "    return regex\n"], "language": "python", "code": "def get_regex(regex):\n    \"\"\"\"\"\"\n    if isinstance(regex, basestring):\n        return re.compile(regex)\n    elif not isinstance(regex, re._pattern_type):\n        raise TypeError('Invalid regex type: %r' % (regex,))\n    return regex\n", "code_tokens": ["get", "regex", "regex", "if", "isinstance", "regex", "basestring", "return", "re", "compile", "regex", "elif", "not", "isinstance", "regex", "re", "pattern", "type", "raise", "typeerror", "invalid", "regex", "type", "regex", "return", "regex"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 476}
{"url": "https://github.com/openstates/billy/blob/5fc795347f12a949e410a8cfad0c911ea6bced67/billy/web/api/handlers.py#L27-L48", "repo": "billy", "func_name": "_build_mongo_filter", "original_string": ["def _build_mongo_filter(request, keys, icase=True):\n", "    _filter = {}\n", "    keys = set(keys) - set(['fields'])\n", "\n", "    for key in keys:\n", "        value = request.GET.get(key)\n", "        if value:\n", "            if key in _lower_fields:\n", "                _filter[key] = value.lower()\n", "            elif key.endswith('__in'):\n", "                values = value.split('|')\n", "                _filter[key[:-4]] = values\n", "            elif key == 'bill_id':\n", "                _filter[key] = fix_bill_id(value.upper())\n", "            else:\n", "                # We use regex queries to get case insensitive search - this\n", "                # means they won't use any indexes for now. Real case\n", "                # insensitive queries are coming eventually:\n", "                # http://jira.mongodb.org/browse/SERVER-90\n", "                _filter[key] = re.compile('^%s$' % value, re.IGNORECASE)\n", "\n", "    return _filter\n"], "language": "python", "code": "def _build_mongo_filter(request, keys, icase=True):\n    _filter = {}\n    keys = set(keys) - set(['fields'])\n    for key in keys:\n        value = request.GET.get(key)\n        if value:\n            if key in _lower_fields:\n                _filter[key] = value.lower()\n            elif key.endswith('__in'):\n                values = value.split('|')\n                _filter[key[:-4]] = values\n            elif key == 'bill_id':\n                _filter[key] = fix_bill_id(value.upper())\n            else:\n                _filter[key] = re.compile('^%s$' % value, re.IGNORECASE)\n    return _filter\n", "code_tokens": ["build", "mongo", "filter", "request", "keys", "icase", "true", "filter", "keys", "set", "keys", "set", "fields", "for", "key", "in", "keys", "value", "request", "get", "get", "key", "if", "value", "if", "key", "in", "lower", "fields", "filter", "key", "value", "lower", "elif", "key", "endswith", "in", "values", "value", "split", "filter", "key", "4", "values", "elif", "key", "bill", "id", "filter", "key", "fix", "bill", "id", "value", "upper", "else", "filter", "key", "re", "compile", "value", "re", "ignorecase", "return", "filter"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 477}
{"url": "https://github.com/goshuirc/irc/blob/d6a5e3e04d337566c009b087f108cd76f9e122cc/girc/imapping.py#L194-L197", "repo": "irc", "func_name": "lower", "original_string": ["    def lower(self):\n", "        new_string = IString(self._irc_lower(self))\n", "        new_string.set_std(self._std)\n", "        return new_string\n"], "language": "python", "code": "def lower(self):\n    new_string = IString(self._irc_lower(self))\n    new_string.set_std(self._std)\n    return new_string\n", "code_tokens": ["lower", "self", "new", "string", "istring", "self", "irc", "lower", "self", "new", "string", "set", "std", "self", "std", "return", "new", "string"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 478}
{"url": "https://github.com/petermelias/valhalla/blob/b08d7a4a94fd8d85a6f5ea86200ec60ef4525e3d/valhalla/filters/strings.py#L90-L99", "repo": "valhalla", "func_name": "regex", "original_string": ["def regex(regex, case=False, _value=None, *args, **kwargs):\n", "    if kwargs.get('case'):\n", "        regex = re.compile(regex)\n", "    else:\n", "        regex = re.compile(regex, re.IGNORECASE)\n", "\n", "    if not regex.match(_value):\n", "        raise ValidationError('The _value must match the regex %s' % regex)\n", "\n", "    return _value\n"], "language": "python", "code": "def regex(regex, case=False, _value=None, *args, **kwargs):\n    if kwargs.get('case'):\n        regex = re.compile(regex)\n    else:\n        regex = re.compile(regex, re.IGNORECASE)\n    if not regex.match(_value):\n        raise ValidationError('The _value must match the regex %s' % regex)\n    return _value\n", "code_tokens": ["regex", "regex", "case", "false", "value", "none", "args", "kwargs", "if", "kwargs", "get", "case", "regex", "re", "compile", "regex", "else", "regex", "re", "compile", "regex", "re", "ignorecase", "if", "not", "regex", "match", "value", "raise", "validationerror", "the", "value", "must", "match", "the", "regex", "regex", "return", "value"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 479}
{"url": "https://github.com/nefarioustim/parker/blob/ccc1de1ac6bfb5e0a8cfa4fdebb2f38f2ee027d6/parker/parsedpage.py#L65-L75", "repo": "parker", "func_name": "_filter_by_regex", "original_string": ["    def _filter_by_regex(self, regex, text, group=1):\n", "        \"\"\"Filter @text by @regex.\"\"\"\n", "        match = re.search(\n", "            regex,\n", "            text,\n", "            re.MULTILINE\n", "        )\n", "\n", "        return match.group(group).strip() if (\n", "            match and match.groups()\n", "        ) else text\n"], "language": "python", "code": "def _filter_by_regex(self, regex, text, group=1):\n    \"\"\"\"\"\"\n    match = re.search(regex, text, re.MULTILINE)\n    return match.group(group).strip() if match and match.groups() else text\n", "code_tokens": ["filter", "by", "regex", "self", "regex", "text", "group", "1", "match", "re", "search", "regex", "text", "re", "multiline", "return", "match", "group", "group", "strip", "if", "match", "and", "match", "groups", "else", "text"], "docstring": "regex case insensitive", "docstring_tokens": ["regex", "case", "insensitive"], "idx": 480}
{"url": "https://github.com/JoseAntFer/pyny3d/blob/fb81684935a24f7e50c975cb4383c81a63ab56df/pyny3d/utils.py#L8-L33", "repo": "pyny3d", "func_name": "sort_numpy", "original_string": ["def sort_numpy(array, col=0, order_back=False):\n", "    \"\"\"\n", "    Sorts the columns for an entire ``ndarrray`` according to sorting\n", "    one of them.\n", "    \n", "    :param array: Array to sort.\n", "    :type array: ndarray\n", "    :param col: Master column to sort.\n", "    :type col: int\n", "    :param order_back: If True, also returns the index to undo the\n", "        new order.\n", "    :type order_back: bool\n", "    :returns: sorted_array or [sorted_array, order_back]\n", "    :rtype: ndarray, list\n", "    \"\"\"\n", "    x = array[:,col]\n", "    sorted_index = np.argsort(x, kind = 'quicksort')\n", "    sorted_array = array[sorted_index]\n", "    \n", "    if not order_back:\n", "        return sorted_array\n", "    else:\n", "        n_points = sorted_index.shape[0]\n", "        order_back = np.empty(n_points, dtype=int)\n", "        order_back[sorted_index] = np.arange(n_points)\n", "        return [sorted_array, order_back]\n"], "language": "python", "code": "def sort_numpy(array, col=0, order_back=False):\n    \"\"\"\"\"\"\n    x = array[:, col]\n    sorted_index = np.argsort(x, kind='quicksort')\n    sorted_array = array[sorted_index]\n    if not order_back:\n        return sorted_array\n    else:\n        n_points = sorted_index.shape[0]\n        order_back = np.empty(n_points, dtype=int)\n        order_back[sorted_index] = np.arange(n_points)\n        return [sorted_array, order_back]\n", "code_tokens": ["sort", "numpy", "array", "col", "0", "order", "back", "false", "array", "col", "sorted", "index", "np", "argsort", "kind", "quicksort", "sorted", "array", "array", "sorted", "index", "if", "not", "order", "back", "return", "sorted", "array", "else", "points", "sorted", "index", "shape", "0", "order", "back", "np", "empty", "points", "dtype", "int", "order", "back", "sorted", "index", "np", "arange", "points", "return", "sorted", "array", "order", "back"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 481}
{"url": "https://github.com/google/prettytensor/blob/75daa0b11252590f548da5647addc0ea610c4c45/prettytensor/tutorial/data_utils.py#L82-L89", "repo": "prettytensor", "func_name": "permute_data", "original_string": ["def permute_data(arrays, random_state=None):\n", "  \"\"\"Permute multiple numpy arrays with the same order.\"\"\"\n", "  if any(len(a) != len(arrays[0]) for a in arrays):\n", "    raise ValueError('All arrays must be the same length.')\n", "  if not random_state:\n", "    random_state = np.random\n", "  order = random_state.permutation(len(arrays[0]))\n", "  return [a[order] for a in arrays]\n"], "language": "python", "code": "def permute_data(arrays, random_state=None):\n    \"\"\"\"\"\"\n    if any(len(a) != len(arrays[0]) for a in arrays):\n        raise ValueError('All arrays must be the same length.')\n    if not random_state:\n        random_state = np.random\n    order = random_state.permutation(len(arrays[0]))\n    return [a[order] for a in arrays]\n", "code_tokens": ["permute", "data", "arrays", "random", "state", "none", "if", "any", "len", "len", "arrays", "0", "for", "in", "arrays", "raise", "valueerror", "all", "arrays", "must", "be", "the", "same", "length", "if", "not", "random", "state", "random", "state", "np", "random", "order", "random", "state", "permutation", "len", "arrays", "0", "return", "order", "for", "in", "arrays"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 482}
{"url": "https://github.com/loverajoel/sqlalchemy-elasticquery/blob/4c99b81f59e7bb20eaeedb3adbf5126e62bbc25c/sqlalchemy_elasticquery/elastic_query.py#L159-L167", "repo": "sqlalchemy-elasticquery", "func_name": "sort", "original_string": ["    def sort(self, sort_list):\n", "        \"\"\" Sort \"\"\"\n", "        order = []\n", "        for sort in sort_list:\n", "            if sort_list[sort] == \"asc\":\n", "                order.append(asc(getattr(self.model, sort, None)))\n", "            elif sort_list[sort] == \"desc\":\n", "                order.append(desc(getattr(self.model, sort, None)))\n", "        return order\n"], "language": "python", "code": "def sort(self, sort_list):\n    \"\"\"\"\"\"\n    order = []\n    for sort in sort_list:\n        if sort_list[sort] == 'asc':\n            order.append(asc(getattr(self.model, sort, None)))\n        elif sort_list[sort] == 'desc':\n            order.append(desc(getattr(self.model, sort, None)))\n    return order\n", "code_tokens": ["sort", "self", "sort", "list", "order", "for", "sort", "in", "sort", "list", "if", "sort", "list", "sort", "asc", "order", "append", "asc", "getattr", "self", "model", "sort", "none", "elif", "sort", "list", "sort", "desc", "order", "append", "desc", "getattr", "self", "model", "sort", "none", "return", "order"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 483}
{"url": "https://github.com/stephan-mclean/KickassTorrentsAPI/blob/4d867a090c06ce95b9ed996b48092cb5bfe28bbd/kat.py#L202-L212", "repo": "KickassTorrentsAPI", "func_name": "_format_sort", "original_string": ["\tdef _format_sort(self, sort, order):\n", "\t\tsorting = \"\"\n", "\t\tif sort:\n", "\t\t\tself.sort = sort\n", "\t\t\tsorting = \"?field=\" + self.sort\n", "\t\t\tif order:\n", "\t\t\t\tself.order = order\n", "\t\t\telse:\n", "\t\t\t\tself.order = Sorting.Order.DESC\n", "\t\t\tsorting = sorting + \"&sorder=\" + self.order\n", "\t\treturn sorting\n"], "language": "python", "code": "def _format_sort(self, sort, order):\n    sorting = ''\n    if sort:\n        self.sort = sort\n        sorting = '?field=' + self.sort\n        if order:\n            self.order = order\n        else:\n            self.order = Sorting.Order.DESC\n        sorting = sorting + '&sorder=' + self.order\n    return sorting\n", "code_tokens": ["format", "sort", "self", "sort", "order", "sorting", "if", "sort", "self", "sort", "sort", "sorting", "field", "self", "sort", "if", "order", "self", "order", "order", "else", "self", "order", "sorting", "order", "desc", "sorting", "sorting", "sorder", "self", "order", "return", "sorting"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 484}
{"url": "https://github.com/PiotrDabkowski/Js2Py/blob/c0fa43f5679cf91ca8986c5747fcb07a433dc584/js2py/internals/prototypes/jsarray.py#L157-L183", "repo": "Js2Py", "func_name": "sort", "original_string": ["    def sort(\n", "            this, args\n", "    ):  # todo: this assumes array continous (not sparse) - fix for sparse arrays\n", "        cmpfn = get_arg(args, 0)\n", "        if not GetClass(this) in ('Array', 'Arguments'):\n", "            return to_object(this, args.space)  # do nothing\n", "        arr_len = js_arr_length(this)\n", "        if not arr_len:\n", "            return this\n", "        arr = [\n", "            (this.get(unicode(e)) if this.has_property(unicode(e)) else None)\n", "            for e in xrange(arr_len)\n", "        ]\n", "        if not is_callable(cmpfn):\n", "            cmpfn = None\n", "        cmp = lambda a, b: sort_compare(a, b, cmpfn)\n", "        if six.PY3:\n", "            key = functools.cmp_to_key(cmp)\n", "            arr.sort(key=key)\n", "        else:\n", "            arr.sort(cmp=cmp)\n", "        for i in xrange(arr_len):\n", "            if arr[i] is None:\n", "                this.delete(unicode(i))\n", "            else:\n", "                this.put(unicode(i), arr[i])\n", "        return this\n"], "language": "python", "code": "def sort(this, args):\n    cmpfn = get_arg(args, 0)\n    if not GetClass(this) in ('Array', 'Arguments'):\n        return to_object(this, args.space)\n    arr_len = js_arr_length(this)\n    if not arr_len:\n        return this\n    arr = [(this.get(unicode(e)) if this.has_property(unicode(e)) else None\n        ) for e in xrange(arr_len)]\n    if not is_callable(cmpfn):\n        cmpfn = None\n    cmp = lambda a, b: sort_compare(a, b, cmpfn)\n    if six.PY3:\n        key = functools.cmp_to_key(cmp)\n        arr.sort(key=key)\n    else:\n        arr.sort(cmp=cmp)\n    for i in xrange(arr_len):\n        if arr[i] is None:\n            this.delete(unicode(i))\n        else:\n            this.put(unicode(i), arr[i])\n    return this\n", "code_tokens": ["sort", "this", "args", "cmpfn", "get", "arg", "args", "0", "if", "not", "getclass", "this", "in", "array", "arguments", "return", "to", "object", "this", "args", "space", "arr", "len", "js", "arr", "length", "this", "if", "not", "arr", "len", "return", "this", "arr", "this", "get", "unicode", "if", "this", "has", "property", "unicode", "else", "none", "for", "in", "xrange", "arr", "len", "if", "not", "is", "callable", "cmpfn", "cmpfn", "none", "cmp", "lambda", "sort", "compare", "cmpfn", "if", "six", "key", "functools", "cmp", "to", "key", "cmp", "arr", "sort", "key", "key", "else", "arr", "sort", "cmp", "cmp", "for", "in", "xrange", "arr", "len", "if", "arr", "is", "none", "this", "delete", "unicode", "else", "this", "put", "unicode", "arr", "return", "this"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 485}
{"url": "https://github.com/shawnbot/py-organ/blob/1663b0943dd9d35a43618b4914c839f7c07d7966/organ/__init__.py#L45-L52", "repo": "py-organ", "func_name": "multisorter", "original_string": ["def multisorter(*sorts):\n", "    def _sort(aa, bb):\n", "        for sort in sorts:\n", "            order = sort(aa, bb)\n", "            if order != 0:\n", "                return order\n", "        return 0\n", "    return _sort\n"], "language": "python", "code": "def multisorter(*sorts):\n\n    def _sort(aa, bb):\n        for sort in sorts:\n            order = sort(aa, bb)\n            if order != 0:\n                return order\n        return 0\n    return _sort\n", "code_tokens": ["multisorter", "sorts", "def", "sort", "aa", "bb", "for", "sort", "in", "sorts", "order", "sort", "aa", "bb", "if", "order", "0", "return", "order", "return", "0", "return", "sort"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 486}
{"url": "https://github.com/radujica/baloo/blob/f6e05e35b73a75e8a300754c6bdc575e5f2d53b9/baloo/weld/weld_ops.py#L464-L491", "repo": "baloo", "func_name": "_weld_sort", "original_string": ["def _weld_sort(arrays, weld_types, ascending=True):\n", "    obj_id, index_obj = create_weld_object(arrays[0])\n", "    index_obj.weld_code = 'len({})'.format(obj_id)\n", "    # get indexes that will be sorted and returned\n", "    index_column = weld_range(0, index_obj, 1)\n", "\n", "    arrays.insert(0, index_column)\n", "    weld_types.insert(0, WeldLong())\n", "    weld_obj_vec_of_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n", "\n", "    weld_obj = create_empty_weld_object()\n", "    weld_obj_vec_of_struct_id = get_weld_obj_id(weld_obj, weld_obj_vec_of_struct)\n", "\n", "    types = struct_of('{e}', weld_types)\n", "    # TODO: update here when sorting on structs is possible\n", "    ascending_sort_func = '{}'.format(', '.join(('e.${}'.format(i) for i in range(1, len(arrays)))))\n", "    zero_literals = dict(enumerate([to_weld_literal(0, weld_type) for weld_type in weld_types]))\n", "    descending_sort_func = '{}'.format(', '.join(('{} - e.${}'.format(zero_literals[i], i)\n", "                                                  for i in range(1, len(arrays)))))\n", "    sort_func = ascending_sort_func if ascending else descending_sort_func\n", "\n", "    weld_template = 'sort({struct}, |e: {types}| {sort_func})'\n", "\n", "    weld_obj.weld_code = weld_template.format(struct=weld_obj_vec_of_struct_id,\n", "                                              types=types,\n", "                                              sort_func=sort_func)\n", "\n", "    return weld_obj\n"], "language": "python", "code": "def _weld_sort(arrays, weld_types, ascending=True):\n    obj_id, index_obj = create_weld_object(arrays[0])\n    index_obj.weld_code = 'len({})'.format(obj_id)\n    index_column = weld_range(0, index_obj, 1)\n    arrays.insert(0, index_column)\n    weld_types.insert(0, WeldLong())\n    weld_obj_vec_of_struct = weld_arrays_to_vec_of_struct(arrays, weld_types)\n    weld_obj = create_empty_weld_object()\n    weld_obj_vec_of_struct_id = get_weld_obj_id(weld_obj,\n        weld_obj_vec_of_struct)\n    types = struct_of('{e}', weld_types)\n    ascending_sort_func = '{}'.format(', '.join('e.${}'.format(i) for i in\n        range(1, len(arrays))))\n    zero_literals = dict(enumerate([to_weld_literal(0, weld_type) for\n        weld_type in weld_types]))\n    descending_sort_func = '{}'.format(', '.join('{} - e.${}'.format(\n        zero_literals[i], i) for i in range(1, len(arrays))))\n    sort_func = ascending_sort_func if ascending else descending_sort_func\n    weld_template = 'sort({struct}, |e: {types}| {sort_func})'\n    weld_obj.weld_code = weld_template.format(struct=\n        weld_obj_vec_of_struct_id, types=types, sort_func=sort_func)\n    return weld_obj\n", "code_tokens": ["weld", "sort", "arrays", "weld", "types", "ascending", "true", "obj", "id", "index", "obj", "create", "weld", "object", "arrays", "0", "index", "obj", "weld", "code", "len", "format", "obj", "id", "index", "column", "weld", "range", "0", "index", "obj", "1", "arrays", "insert", "0", "index", "column", "weld", "types", "insert", "0", "weldlong", "weld", "obj", "vec", "of", "struct", "weld", "arrays", "to", "vec", "of", "struct", "arrays", "weld", "types", "weld", "obj", "create", "empty", "weld", "object", "weld", "obj", "vec", "of", "struct", "id", "get", "weld", "obj", "id", "weld", "obj", "weld", "obj", "vec", "of", "struct", "types", "struct", "of", "weld", "types", "ascending", "sort", "func", "format", "join", "format", "for", "in", "range", "1", "len", "arrays", "zero", "literals", "dict", "enumerate", "to", "weld", "literal", "0", "weld", "type", "for", "weld", "type", "in", "weld", "types", "descending", "sort", "func", "format", "join", "format", "zero", "literals", "for", "in", "range", "1", "len", "arrays", "sort", "func", "ascending", "sort", "func", "if", "ascending", "else", "descending", "sort", "func", "weld", "template", "sort", "struct", "types", "sort", "func", "weld", "obj", "weld", "code", "weld", "template", "format", "struct", "weld", "obj", "vec", "of", "struct", "id", "types", "types", "sort", "func", "sort", "func", "return", "weld", "obj"], "docstring": "sorting multiple arrays based on another arrays sorted order", "docstring_tokens": ["sorting", "multiple", "arrays", "based", "on", "another", "arrays", "sorted", "order"], "idx": 487}
{"url": "https://github.com/miyakogi/wdom/blob/a21bcd23e94baceee71161829f6897bee3fd39c1/wdom/tag.py#L148-L152", "repo": "wdom", "func_name": "html", "original_string": ["    def html(self) -> str:\n", "        \"\"\"Get whole html representation of this node.\"\"\"\n", "        if self._inner_element:\n", "            return self.start_tag + self._inner_element.html + self.end_tag\n", "        return super().html\n"], "language": "python", "code": "def html(self) ->str:\n    \"\"\"\"\"\"\n    if self._inner_element:\n        return self.start_tag + self._inner_element.html + self.end_tag\n    return super().html\n", "code_tokens": ["html", "self", "str", "if", "self", "inner", "element", "return", "self", "start", "tag", "self", "inner", "element", "html", "self", "end", "tag", "return", "super", "html"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 488}
{"url": "https://github.com/miyakogi/wdom/blob/a21bcd23e94baceee71161829f6897bee3fd39c1/wdom/web_node.py#L305-L311", "repo": "wdom", "func_name": "innerHTML", "original_string": ["    def innerHTML(self, html: str) -> None:  # type: ignore\n", "        \"\"\"Set innerHTML both on this node and related browser node.\"\"\"\n", "        df = self._parse_html(html)\n", "        if self.connected:\n", "            self._set_inner_html_web(df.html)\n", "        self._empty()\n", "        self._append_child(df)\n"], "language": "python", "code": "def innerHTML(self, html: str) ->None:\n    \"\"\"\"\"\"\n    df = self._parse_html(html)\n    if self.connected:\n        self._set_inner_html_web(df.html)\n    self._empty()\n    self._append_child(df)\n", "code_tokens": ["innerhtml", "self", "html", "str", "none", "df", "self", "parse", "html", "html", "if", "self", "connected", "self", "set", "inner", "html", "web", "df", "html", "self", "empty", "self", "append", "child", "df"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 489}
{"url": "https://github.com/maxpowel/scrapium/blob/bc12c425aa5978f953a87d05920ba0f61a00409c/scrapium/scrapium.py#L140-L142", "repo": "scrapium", "func_name": "get_html", "original_string": ["    def get_html(self, url):\n", "        r = self.get(url)\n", "        return self.html(r.text)\n"], "language": "python", "code": "def get_html(self, url):\n    r = self.get(url)\n    return self.html(r.text)\n", "code_tokens": ["get", "html", "self", "url", "self", "get", "url", "return", "self", "html", "text"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 490}
{"url": "https://github.com/tensorflow/lucid/blob/d1a1e2e4fd4be61b89b8cba20dc425a5ae34576e/lucid/scratch/web/svelte.py#L43-L68", "repo": "lucid", "func_name": "SvelteComponent", "original_string": ["def SvelteComponent(name, path):\n", "  \"\"\"Display svelte components in iPython.\n", "\n", "  Args:\n", "    name: name of svelte component (must match component filename when built)\n", "    path: path to compile svelte .js file or source svelte .html file.\n", "      (If html file, we try to call svelte and build the file.)\n", "\n", "  Returns:\n", "    A function mapping data to a rendered svelte component in ipython.\n", "  \"\"\"\n", "  if path[-3:] == \".js\":\n", "    js_path = path\n", "  elif path[-5:] == \".html\":\n", "    print(\"Trying to build svelte component from html...\")\n", "    js_path = build_svelte(path)\n", "  js_content = read(js_path, mode='r')\n", "  def inner(data):\n", "    id_str = js_id(name)\n", "    html = _template \\\n", "        .replace(\"$js\", js_content) \\\n", "        .replace(\"$name\", name) \\\n", "        .replace(\"$data\", json.dumps(data)) \\\n", "        .replace(\"$id\", id_str)\n", "    _display_html(html)\n", "  return inner\n"], "language": "python", "code": "def SvelteComponent(name, path):\n    \"\"\"\"\"\"\n    if path[-3:] == '.js':\n        js_path = path\n    elif path[-5:] == '.html':\n        print('Trying to build svelte component from html...')\n        js_path = build_svelte(path)\n    js_content = read(js_path, mode='r')\n\n    def inner(data):\n        id_str = js_id(name)\n        html = _template.replace('$js', js_content).replace('$name', name\n            ).replace('$data', json.dumps(data)).replace('$id', id_str)\n        _display_html(html)\n    return inner\n", "code_tokens": ["sveltecomponent", "name", "path", "if", "path", "3", "js", "js", "path", "path", "elif", "path", "5", "html", "print", "trying", "to", "build", "svelte", "component", "from", "html", "js", "path", "build", "svelte", "path", "js", "content", "read", "js", "path", "mode", "def", "inner", "data", "id", "str", "js", "id", "name", "html", "template", "replace", "js", "js", "content", "replace", "name", "name", "replace", "data", "json", "dumps", "data", "replace", "id", "id", "str", "display", "html", "html", "return", "inner"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 491}
{"url": "https://github.com/zenwalker/python-xmltag/blob/5ba900753d939b0f3811c88b0f95ebbbdecd1727/xmltag/nodes.py#L45-L59", "repo": "python-xmltag", "func_name": "render", "original_string": ["    def render(self):\n", "        indent = self.doc.indent\n", "        inner = self.content or ''\n", "        if not self.safe:\n", "            inner = escape(inner, quote=False)\n", "        inner += ''.join([n.render() for n in self.child_nodes])\n", "        html = self.doc.render_tag(self.tag_name, inner, self.attrs)\n", "\n", "        if indent:\n", "            pretty_html = '\\n' + (indent * self.level) + html\n", "            if self._is_last():\n", "                pretty_html += '\\n' + indent * (self.level - 1)\n", "            html = pretty_html\n", "\n", "        return html\n"], "language": "python", "code": "def render(self):\n    indent = self.doc.indent\n    inner = self.content or ''\n    if not self.safe:\n        inner = escape(inner, quote=False)\n    inner += ''.join([n.render() for n in self.child_nodes])\n    html = self.doc.render_tag(self.tag_name, inner, self.attrs)\n    if indent:\n        pretty_html = '\\n' + indent * self.level + html\n        if self._is_last():\n            pretty_html += '\\n' + indent * (self.level - 1)\n        html = pretty_html\n    return html\n", "code_tokens": ["render", "self", "indent", "self", "doc", "indent", "inner", "self", "content", "or", "if", "not", "self", "safe", "inner", "escape", "inner", "quote", "false", "inner", "join", "render", "for", "in", "self", "child", "nodes", "html", "self", "doc", "render", "tag", "self", "tag", "name", "inner", "self", "attrs", "if", "indent", "pretty", "html", "indent", "self", "level", "html", "if", "self", "is", "last", "pretty", "html", "indent", "self", "level", "1", "html", "pretty", "html", "return", "html"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 492}
{"url": "https://github.com/KelSolaar/Umbra/blob/66f45f08d9d723787f1191989f8b0dda84b412ce/umbra/reporter.py#L468-L477", "repo": "Umbra", "func_name": "__set_html", "original_string": ["    def __set_html(self, html=None):\n", "        \"\"\"\n", "        Sets the html content in the View using given body.\n", "\n", "        :param html: Html content.\n", "        :type html: unicode\n", "        \"\"\"\n", "\n", "        self.__html = self.__get_html(html)\n", "        self.__view.setHtml(self.__html)\n"], "language": "python", "code": "def __set_html(self, html=None):\n    \"\"\"\"\"\"\n    self.__html = self.__get_html(html)\n    self.__view.setHtml(self.__html)\n", "code_tokens": ["set", "html", "self", "html", "none", "self", "html", "self", "get", "html", "html", "self", "view", "sethtml", "self", "html"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 493}
{"url": "https://github.com/miyakogi/wdom/blob/a21bcd23e94baceee71161829f6897bee3fd39c1/wdom/tag.py#L155-L159", "repo": "wdom", "func_name": "innerHTML", "original_string": ["    def innerHTML(self) -> str:\n", "        \"\"\"Get innerHTML of the inner node.\"\"\"\n", "        if self._inner_element:\n", "            return self._inner_element.innerHTML\n", "        return super().innerHTML\n"], "language": "python", "code": "def innerHTML(self) ->str:\n    \"\"\"\"\"\"\n    if self._inner_element:\n        return self._inner_element.innerHTML\n    return super().innerHTML\n", "code_tokens": ["innerhtml", "self", "str", "if", "self", "inner", "element", "return", "self", "inner", "element", "innerhtml", "return", "super", "innerhtml"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 494}
{"url": "https://github.com/limodou/uliweb/blob/34472f25e4bc0b954a35346672f94e84ef18b076/uliweb/form/widgets.py#L22-L24", "repo": "uliweb", "func_name": "html", "original_string": ["    def html(self):\n", "        return ''.join([self.pre_html() % self.kwargs] + [self.to_html()] + \n", "            [self.post_html() % self.kwargs])\n"], "language": "python", "code": "def html(self):\n    return ''.join([self.pre_html() % self.kwargs] + [self.to_html()] + [\n        self.post_html() % self.kwargs])\n", "code_tokens": ["html", "self", "return", "join", "self", "pre", "html", "self", "kwargs", "self", "to", "html", "self", "post", "html", "self", "kwargs"], "docstring": "get inner html", "docstring_tokens": ["get", "inner", "html"], "idx": 495}
{"url": "https://github.com/KarchinLab/probabilistic2020/blob/5d70583b0a7c07cfe32e95f3a70e05df412acb84/prob2020/python/permutation.py#L9-L96", "repo": "probabilistic2020", "func_name": "deleterious_permutation", "original_string": ["def deleterious_permutation(obs_del,\n", "                            context_counts,\n", "                            context_to_mut,\n", "                            seq_context,\n", "                            gene_seq,\n", "                            num_permutations=10000,\n", "                            stop_criteria=100,\n", "                            pseudo_count=0,\n", "                            max_batch=25000):\n", "    \"\"\"Performs null-permutations for deleterious mutation statistics\n", "    in a single gene.\n", "\n", "    Parameters\n", "    ----------\n", "    context_counts : pd.Series\n", "        number of mutations for each context\n", "    context_to_mut : dict\n", "        dictionary mapping nucleotide context to a list of observed\n", "        somatic base changes.\n", "    seq_context : SequenceContext\n", "        Sequence context for the entire gene sequence (regardless\n", "        of where mutations occur). The nucleotide contexts are\n", "        identified at positions along the gene.\n", "    gene_seq : GeneSequence\n", "        Sequence of gene of interest\n", "    num_permutations : int, default: 10000\n", "        number of permutations to create for null\n", "    pseudo_count : int, default: 0\n", "        Pseudo-count for number of deleterious mutations for each\n", "        permutation of the null distribution. Increasing pseudo_count\n", "        makes the statistical test more stringent.\n", "\n", "    Returns\n", "    -------\n", "    del_count_list : list\n", "        list of deleterious mutation counts under the null\n", "    \"\"\"\n", "    mycontexts = context_counts.index.tolist()\n", "    somatic_base = [base\n", "                    for one_context in mycontexts\n", "                    for base in context_to_mut[one_context]]\n", "\n", "    # calculate the # of batches for simulations\n", "    max_batch = min(num_permutations, max_batch)\n", "    num_batches = num_permutations // max_batch\n", "    remainder = num_permutations % max_batch\n", "    batch_sizes = [max_batch] * num_batches\n", "    if remainder:\n", "        batch_sizes += [remainder]\n", "\n", "    num_sim = 0\n", "    null_del_ct = 0\n", "    for j, batch_size in enumerate(batch_sizes):\n", "        # stop iterations if reached sufficient precision\n", "        if null_del_ct >= stop_criteria:\n", "            #j = j - 1\n", "            break\n", "\n", "        # get random positions determined by sequence context\n", "        tmp_contxt_pos = seq_context.random_pos(context_counts.iteritems(),\n", "                                                batch_size)\n", "        tmp_mut_pos = np.hstack([pos_array for base, pos_array in tmp_contxt_pos])\n", "\n", "        # determine result of random positions\n", "        for i, row in enumerate(tmp_mut_pos):\n", "            # get info about mutations\n", "            tmp_mut_info = mc.get_aa_mut_info(row,\n", "                                              somatic_base,\n", "                                              gene_seq)\n", "\n", "            # calc deleterious mutation info\n", "            tmp_del_count = cutils.calc_deleterious_info(tmp_mut_info['Reference AA'],\n", "                                                         tmp_mut_info['Somatic AA'],\n", "                                                         tmp_mut_info['Codon Pos'])\n", "\n", "            # update empricial null distribution\n", "            if tmp_del_count >= obs_del: null_del_ct += 1\n", "\n", "            # stop if reach sufficient precision on p-value\n", "            if null_del_ct >= stop_criteria:\n", "                break\n", "        # update number of simulations\n", "        num_sim += i + 1\n", "\n", "    #num_sim = j*max_batch + i+1\n", "    del_pval = float(null_del_ct) / (num_sim)\n", "\n", "    return del_pval\n"], "language": "python", "code": "def deleterious_permutation(obs_del, context_counts, context_to_mut,\n    seq_context, gene_seq, num_permutations=10000, stop_criteria=100,\n    pseudo_count=0, max_batch=25000):\n    \"\"\"\"\"\"\n    mycontexts = context_counts.index.tolist()\n    somatic_base = [base for one_context in mycontexts for base in\n        context_to_mut[one_context]]\n    max_batch = min(num_permutations, max_batch)\n    num_batches = num_permutations // max_batch\n    remainder = num_permutations % max_batch\n    batch_sizes = [max_batch] * num_batches\n    if remainder:\n        batch_sizes += [remainder]\n    num_sim = 0\n    null_del_ct = 0\n    for j, batch_size in enumerate(batch_sizes):\n        if null_del_ct >= stop_criteria:\n            break\n        tmp_contxt_pos = seq_context.random_pos(context_counts.iteritems(),\n            batch_size)\n        tmp_mut_pos = np.hstack([pos_array for base, pos_array in\n            tmp_contxt_pos])\n        for i, row in enumerate(tmp_mut_pos):\n            tmp_mut_info = mc.get_aa_mut_info(row, somatic_base, gene_seq)\n            tmp_del_count = cutils.calc_deleterious_info(tmp_mut_info[\n                'Reference AA'], tmp_mut_info['Somatic AA'], tmp_mut_info[\n                'Codon Pos'])\n            if tmp_del_count >= obs_del:\n                null_del_ct += 1\n            if null_del_ct >= stop_criteria:\n                break\n        num_sim += i + 1\n    del_pval = float(null_del_ct) / num_sim\n    return del_pval\n", "code_tokens": ["deleterious", "permutation", "obs", "del", "context", "counts", "context", "to", "mut", "seq", "context", "gene", "seq", "num", "permutations", "10000", "stop", "criteria", "100", "pseudo", "count", "0", "max", "batch", "25000", "mycontexts", "context", "counts", "index", "tolist", "somatic", "base", "base", "for", "one", "context", "in", "mycontexts", "for", "base", "in", "context", "to", "mut", "one", "context", "max", "batch", "min", "num", "permutations", "max", "batch", "num", "batches", "num", "permutations", "max", "batch", "remainder", "num", "permutations", "max", "batch", "batch", "sizes", "max", "batch", "num", "batches", "if", "remainder", "batch", "sizes", "remainder", "num", "sim", "0", "null", "del", "ct", "0", "for", "batch", "size", "in", "enumerate", "batch", "sizes", "if", "null", "del", "ct", "stop", "criteria", "break", "tmp", "contxt", "pos", "seq", "context", "random", "pos", "context", "counts", "iteritems", "batch", "size", "tmp", "mut", "pos", "np", "hstack", "pos", "array", "for", "base", "pos", "array", "in", "tmp", "contxt", "pos", "for", "row", "in", "enumerate", "tmp", "mut", "pos", "tmp", "mut", "info", "mc", "get", "aa", "mut", "info", "row", "somatic", "base", "gene", "seq", "tmp", "del", "count", "cutils", "calc", "deleterious", "info", "tmp", "mut", "info", "reference", "aa", "tmp", "mut", "info", "somatic", "aa", "tmp", "mut", "info", "codon", "pos", "if", "tmp", "del", "count", "obs", "del", "null", "del", "ct", "1", "if", "null", "del", "ct", "stop", "criteria", "break", "num", "sim", "1", "del", "pval", "float", "null", "del", "ct", "num", "sim", "return", "del", "pval"], "docstring": "all permutations of a list", "docstring_tokens": ["all", "permutations", "of", "a", "list"], "idx": 496}
{"url": "https://github.com/GetmeUK/MongoFrames/blob/7d2bd792235dfa77a9deecab5366f5f73480823d/mongoframes/factory/makers/selections.py#L231-L283", "repo": "MongoFrames", "func_name": "p", "original_string": ["    def p(i, sample_size, weights):\n", "        \"\"\"\n", "        Given a weighted set and sample size return the probabilty that the\n", "        weight `i` will be present in the sample.\n", "\n", "        Created to test the output of the `SomeOf` maker class. The math was\n", "        provided by Andy Blackshaw - thank you dad :)\n", "        \"\"\"\n", "\n", "        # Determine the initial pick values\n", "        weight_i = weights[i]\n", "        weights_sum = sum(weights)\n", "\n", "        # Build a list of weights that don't contain the weight `i`. This list will\n", "        # be used to build the possible picks before weight `i`.\n", "        other_weights = list(weights)\n", "        del other_weights[i]\n", "\n", "        # Calculate the probability\n", "        probability_of_i = 0\n", "        for picks in range(0, sample_size):\n", "\n", "            # Build the list of possible permutations for this pick in the sample\n", "            permutations = list(itertools.permutations(other_weights, picks))\n", "\n", "            # Calculate the probability for this permutation\n", "            permutation_probabilities = []\n", "            for permutation in permutations:\n", "\n", "                # Calculate the probability for each pick in the permutation\n", "                pick_probabilities = []\n", "                pick_weight_sum = weights_sum\n", "\n", "                for pick in permutation:\n", "                    pick_probabilities.append(pick / pick_weight_sum)\n", "\n", "                    # Each time we pick we update the sum of the weight the next\n", "                    # pick is from.\n", "                    pick_weight_sum -= pick\n", "\n", "                # Add the probability of picking i as the last pick\n", "                pick_probabilities += [weight_i / pick_weight_sum]\n", "\n", "                # Multiply all the probabilities for the permutation together\n", "                permutation_probability = reduce(\n", "                    lambda x, y: x * y, pick_probabilities\n", "                    )\n", "                permutation_probabilities.append(permutation_probability)\n", "\n", "            # Add together all the probabilities for all permutations together\n", "            probability_of_i += sum(permutation_probabilities)\n", "\n", "        return probability_of_i\n"], "language": "python", "code": "def p(i, sample_size, weights):\n    \"\"\"\"\"\"\n    weight_i = weights[i]\n    weights_sum = sum(weights)\n    other_weights = list(weights)\n    del other_weights[i]\n    probability_of_i = 0\n    for picks in range(0, sample_size):\n        permutations = list(itertools.permutations(other_weights, picks))\n        permutation_probabilities = []\n        for permutation in permutations:\n            pick_probabilities = []\n            pick_weight_sum = weights_sum\n            for pick in permutation:\n                pick_probabilities.append(pick / pick_weight_sum)\n                pick_weight_sum -= pick\n            pick_probabilities += [weight_i / pick_weight_sum]\n            permutation_probability = reduce(lambda x, y: x * y,\n                pick_probabilities)\n            permutation_probabilities.append(permutation_probability)\n        probability_of_i += sum(permutation_probabilities)\n    return probability_of_i\n", "code_tokens": ["sample", "size", "weights", "weight", "weights", "weights", "sum", "sum", "weights", "other", "weights", "list", "weights", "del", "other", "weights", "probability", "of", "0", "for", "picks", "in", "range", "0", "sample", "size", "permutations", "list", "itertools", "permutations", "other", "weights", "picks", "permutation", "probabilities", "for", "permutation", "in", "permutations", "pick", "probabilities", "pick", "weight", "sum", "weights", "sum", "for", "pick", "in", "permutation", "pick", "probabilities", "append", "pick", "pick", "weight", "sum", "pick", "weight", "sum", "pick", "pick", "probabilities", "weight", "pick", "weight", "sum", "permutation", "probability", "reduce", "lambda", "pick", "probabilities", "permutation", "probabilities", "append", "permutation", "probability", "probability", "of", "sum", "permutation", "probabilities", "return", "probability", "of"], "docstring": "all permutations of a list", "docstring_tokens": ["all", "permutations", "of", "a", "list"], "idx": 497}
{"url": "https://github.com/mabuchilab/QNET/blob/cc20d26dad78691d34c67173e5cd67dcac94208a/src/qnet/algebra/core/circuit_algebra.py#L822-L834", "repo": "QNET", "func_name": "series_with_permutation", "original_string": ["    def series_with_permutation(self, other):\n", "        \"\"\"Compute the series product with another channel permutation circuit\n", "\n", "        Args:\n", "            other (CPermutation):\n", "\n", "        Returns:\n", "            Circuit: The composite permutation circuit (could also be the\n", "                identity circuit for n channels)\n", "        \"\"\"\n", "        combined_permutation = tuple([self.permutation[p]\n", "                                      for p in other.permutation])\n", "        return CPermutation.create(combined_permutation)\n"], "language": "python", "code": "def series_with_permutation(self, other):\n    \"\"\"\"\"\"\n    combined_permutation = tuple([self.permutation[p] for p in other.\n        permutation])\n    return CPermutation.create(combined_permutation)\n", "code_tokens": ["series", "with", "permutation", "self", "other", "combined", "permutation", "tuple", "self", "permutation", "for", "in", "other", "permutation", "return", "cpermutation", "create", "combined", "permutation"], "docstring": "all permutations of a list", "docstring_tokens": ["all", "permutations", "of", "a", "list"], "idx": 498}
{"url": "https://github.com/numenta/nupic/blob/5922fafffdccc8812e72b3324965ad2f7d4bbdad/src/nupic/math/cross.py#L96-L102", "repo": "nupic", "func_name": "permutations", "original_string": ["def permutations(x):\n", "  if len(x) > 1:\n", "    for permutation in permutations(x[1:]):\n", "      # Stick the first digit in every position.\n", "      for i in xrange(len(permutation)+1):\n", "        yield permutation[:i] + x[0:1] + permutation[i:]\n", "  else: yield x\n"], "language": "python", "code": "def permutations(x):\n    if len(x) > 1:\n        for permutation in permutations(x[1:]):\n            for i in xrange(len(permutation) + 1):\n                yield permutation[:i] + x[0:1] + permutation[i:]\n    else:\n        yield x\n", "code_tokens": ["permutations", "if", "len", "1", "for", "permutation", "in", "permutations", "1", "for", "in", "xrange", "len", "permutation", "1", "yield", "permutation", "0", "1", "permutation", "else", "yield"], "docstring": "all permutations of a list", "docstring_tokens": ["all", "permutations", "of", "a", "list"], "idx": 499}
{"url": "https://github.com/mabuchilab/QNET/blob/cc20d26dad78691d34c67173e5cd67dcac94208a/src/qnet/utils/permutations.py#L166-L184", "repo": "QNET", "func_name": "permutation_from_block_permutations", "original_string": ["def permutation_from_block_permutations(permutations):\n", "    \"\"\"Reverse operation to :py:func:`permutation_to_block_permutations`\n", "    Compute the concatenation of permutations\n", "\n", "        ``(1,2,0) [+] (0,2,1) --> (1,2,0,3,5,4)``\n", "\n", "    :param permutations: A list of permutation tuples\n", "                                 ``[t = (t_0,...,t_n1), u = (u_0,...,u_n2),..., z = (z_0,...,z_nm)]``\n", "    :type permutations: list of tuples\n", "    :return: permutation image tuple\n", "                    ``s = t [+] u [+] ... [+] z``\n", "    :rtype: tuple\n", "    \"\"\"\n", "    offset = 0\n", "    new_perm = []\n", "    for p in permutations:\n", "        new_perm[offset: offset +len(p)] = [p_i + offset for p_i in p]\n", "        offset += len(p)\n", "    return tuple(new_perm)\n"], "language": "python", "code": "def permutation_from_block_permutations(permutations):\n    \"\"\"\"\"\"\n    offset = 0\n    new_perm = []\n    for p in permutations:\n        new_perm[offset:offset + len(p)] = [(p_i + offset) for p_i in p]\n        offset += len(p)\n    return tuple(new_perm)\n", "code_tokens": ["permutation", "from", "block", "permutations", "permutations", "offset", "0", "new", "perm", "for", "in", "permutations", "new", "perm", "offset", "offset", "len", "offset", "for", "in", "offset", "len", "return", "tuple", "new", "perm"], "docstring": "all permutations of a list", "docstring_tokens": ["all", "permutations", "of", "a", "list"], "idx": 500}
{"url": "https://github.com/hollenstein/maspy/blob/f15fcfd24df306d8420540460d902aa3073ec133/maspy/mit_stats.py#L48-L88", "repo": "maspy", "func_name": "runningMedian", "original_string": ["def runningMedian(seq, M):\n", "    \"\"\"\n", "     Purpose: Find the median for the points in a sliding window (odd number in size)\n", "              as it is moved from left to right by one point at a time.\n", "      Inputs:\n", "            seq -- list containing items for which a running median (in a sliding window)\n", "                   is to be calculated\n", "              M -- number of items in window (window size) -- must be an integer > 1\n", "      Otputs:\n", "         medians -- list of medians with size N - M + 1\n", "       Note:\n", "         1. The median of a finite list of numbers is the \"center\" value when this list\n", "            is sorted in ascending order.\n", "         2. If M is an even number the two elements in the window that\n", "            are close to the center are averaged to give the median (this\n", "            is not by definition)\n", "    \"\"\"\n", "    seq = iter(seq)\n", "    s = []\n", "    m = M // 2 #// does a truncated division like integer division in Python 2\n", "\n", "    # Set up list s (to be sorted) and load deque with first window of seq\n", "    s = [item for item in islice(seq,M)]\n", "    d = deque(s)\n", "\n", "    # Simple lambda function to handle even/odd window sizes\n", "    median = lambda : s[m] if bool(M&1) else (s[m-1]+s[m])*0.5\n", "\n", "    # Sort it in increasing order and extract the median (\"center\" of the sorted window)\n", "    s.sort()\n", "    medians = [median()]\n", "\n", "    # Now slide the window by one point to the right for each new position (each pass through\n", "    # the loop). Stop when the item in the right end of the deque contains the last item in seq\n", "    for item in seq:\n", "        old = d.popleft()          # pop oldest from left\n", "        d.append(item)             # push newest in from right\n", "        del s[bisect_left(s, old)] # locate insertion point and then remove old\n", "        insort(s, item)            # insert newest such that new sort is not required\n", "        medians.append(median())\n", "    return medians\n"], "language": "python", "code": "def runningMedian(seq, M):\n    \"\"\"\"\"\"\n    seq = iter(seq)\n    s = []\n    m = M // 2\n    s = [item for item in islice(seq, M)]\n    d = deque(s)\n    median = lambda : s[m] if bool(M & 1) else (s[m - 1] + s[m]) * 0.5\n    s.sort()\n    medians = [median()]\n    for item in seq:\n        old = d.popleft()\n        d.append(item)\n        del s[bisect_left(s, old)]\n        insort(s, item)\n        medians.append(median())\n    return medians\n", "code_tokens": ["runningmedian", "seq", "seq", "iter", "seq", "2", "item", "for", "item", "in", "islice", "seq", "deque", "median", "lambda", "if", "bool", "1", "else", "1", "0", "5", "sort", "medians", "median", "for", "item", "in", "seq", "old", "popleft", "append", "item", "del", "bisect", "left", "old", "insort", "item", "medians", "append", "median", "return", "medians"], "docstring": "deducting the median from each column", "docstring_tokens": ["deducting", "the", "median", "from", "each", "column"], "idx": 501}
{"url": "https://github.com/EelcoHoogendoorn/Numpy_arraysetops_EP/blob/84dc8114bf8a79c3acb3f7f59128247b9fc97243/numpy_indexed/grouping.py#L343-L382", "repo": "Numpy_arraysetops_EP", "func_name": "median", "original_string": ["    def median(self, values, axis=0, average=True):\n", "        \"\"\"compute the median value over each group.\n", "\n", "        Parameters\n", "        ----------\n", "        values : array_like, [keys, ...]\n", "            values to compute the median of per group\n", "        axis : int, optional\n", "            alternative reduction axis for values\n", "        average : bool, optional\n", "            when average is true, the average of the two central values is taken for groups with an even key-count\n", "\n", "        Returns\n", "        -------\n", "        unique: ndarray, [groups]\n", "            unique keys\n", "        reduced : ndarray, [groups, ...]\n", "            value array, reduced over groups\n", "        \"\"\"\n", "        mid_2 = self.index.start + self.index.stop\n", "        hi = (mid_2    ) // 2\n", "        lo = (mid_2 - 1) // 2\n", "\n", "        #need this indirection for lex-index compatibility\n", "        sorted_group_rank_per_key = self.index.sorted_group_rank_per_key\n", "\n", "        def median1d(slc):\n", "            #place values at correct keys; preconditions the upcoming lexsort\n", "            slc    = slc[self.index.sorter]\n", "            #refine value sorting within each keygroup\n", "            sorter = np.lexsort((slc, sorted_group_rank_per_key))\n", "            slc    = slc[sorter]\n", "            return (slc[lo]+slc[hi]) / 2 if average else slc[hi]\n", "\n", "        values = np.asarray(values)\n", "        if values.ndim>1:   #is trying to skip apply_along_axis somewhat premature optimization?\n", "            values = np.apply_along_axis(median1d, axis, values)\n", "        else:\n", "            values = median1d(values)\n", "        return self.unique, values\n"], "language": "python", "code": "def median(self, values, axis=0, average=True):\n    \"\"\"\"\"\"\n    mid_2 = self.index.start + self.index.stop\n    hi = mid_2 // 2\n    lo = (mid_2 - 1) // 2\n    sorted_group_rank_per_key = self.index.sorted_group_rank_per_key\n\n    def median1d(slc):\n        slc = slc[self.index.sorter]\n        sorter = np.lexsort((slc, sorted_group_rank_per_key))\n        slc = slc[sorter]\n        return (slc[lo] + slc[hi]) / 2 if average else slc[hi]\n    values = np.asarray(values)\n    if values.ndim > 1:\n        values = np.apply_along_axis(median1d, axis, values)\n    else:\n        values = median1d(values)\n    return self.unique, values\n", "code_tokens": ["median", "self", "values", "axis", "0", "average", "true", "mid", "2", "self", "index", "start", "self", "index", "stop", "hi", "mid", "2", "2", "lo", "mid", "2", "1", "2", "sorted", "group", "rank", "per", "key", "self", "index", "sorted", "group", "rank", "per", "key", "def", "slc", "slc", "slc", "self", "index", "sorter", "sorter", "np", "lexsort", "slc", "sorted", "group", "rank", "per", "key", "slc", "slc", "sorter", "return", "slc", "lo", "slc", "hi", "2", "if", "average", "else", "slc", "hi", "values", "np", "asarray", "values", "if", "values", "ndim", "1", "values", "np", "apply", "along", "axis", "axis", "values", "else", "values", "values", "return", "self", "unique", "values"], "docstring": "deducting the median from each column", "docstring_tokens": ["deducting", "the", "median", "from", "each", "column"], "idx": 502}
{"url": "https://github.com/adaptive-learning/proso-apps/blob/8278c72e498d6ef8d392cc47b48473f4ec037142/proso/models/option_selection.py#L195-L206", "repo": "proso-apps", "func_name": "adjust_to_level", "original_string": ["    def adjust_to_level(self, level, x, op, median):\n", "        if x > median:\n", "            if level > 0.5:\n", "                result = median + (x - median) * ((level - 0.5) / 0.5)\n", "            else:\n", "                result = op + (median - op) * (level / 0.5)\n", "        else:\n", "            if level > 0.5:\n", "                result = x + (median - x) * ((level - 0.5) / 0.5)\n", "            else:\n", "                result = median + (op - median) * (level / 0.5)\n", "        return result\n"], "language": "python", "code": "def adjust_to_level(self, level, x, op, median):\n    if x > median:\n        if level > 0.5:\n            result = median + (x - median) * ((level - 0.5) / 0.5)\n        else:\n            result = op + (median - op) * (level / 0.5)\n    elif level > 0.5:\n        result = x + (median - x) * ((level - 0.5) / 0.5)\n    else:\n        result = median + (op - median) * (level / 0.5)\n    return result\n", "code_tokens": ["adjust", "to", "level", "self", "level", "op", "median", "if", "median", "if", "level", "0", "5", "result", "median", "median", "level", "0", "5", "0", "5", "else", "result", "op", "median", "op", "level", "0", "5", "elif", "level", "0", "5", "result", "median", "level", "0", "5", "0", "5", "else", "result", "median", "op", "median", "level", "0", "5", "return", "result"], "docstring": "deducting the median from each column", "docstring_tokens": ["deducting", "the", "median", "from", "each", "column"], "idx": 503}
{"url": "https://github.com/rhenanbartels/hrv/blob/cd4c7e6e508299d943930886d20413f63845f60f/hrv/rri.py#L123-L124", "repo": "hrv", "func_name": "_mem_usage", "original_string": ["        def _mem_usage(nbytes):\n", "            mem_val = nbytes / 1024\n"], "language": "python", "code": "def _mem_usage(nbytes):\n    mem_val = nbytes / 1024\n", "code_tokens": ["mem", "usage", "nbytes", "mem", "val", "nbytes", "1024"], "docstring": "deducting the median from each column", "docstring_tokens": ["deducting", "the", "median", "from", "each", "column"], "idx": 504}
{"url": "https://github.com/neherlab/treetime/blob/f6cdb58d19243a18ffdaa2b2ec71872fa00e65c0/treetime/utils.py#L129-L139", "repo": "treetime", "func_name": "median_interp", "original_string": ["        raise e\n", "\n", "\n", "def median_interp(interp_object):\n", "    \"\"\"\n", "    Find the median of the function represented as an interpolation object.\n", "    \"\"\"\n", "    new_grid = np.sort(np.concatenate([interp_object.x[:-1] + 0.1*ii*np.diff(interp_object.x)\n", "                                       for ii in range(10)]).flatten())\n", "\n", "    tmp_prop = np.exp(-(interp_object(new_grid)-interp_object.y.min()))\n"], "language": "python", "code": "def median_interp(interp_object):\n    \"\"\"\"\"\"\n    new_grid = np.sort(np.concatenate([(interp_object.x[:-1] + 0.1 * ii *\n        np.diff(interp_object.x)) for ii in range(10)]).flatten())\n    tmp_prop = np.exp(-(interp_object(new_grid) - interp_object.y.min()))\n", "code_tokens": ["median", "interp", "interp", "object", "new", "grid", "np", "sort", "np", "concatenate", "interp", "object", "1", "0", "1", "ii", "np", "diff", "interp", "object", "for", "ii", "in", "range", "10", "flatten", "tmp", "prop", "np", "exp", "interp", "object", "new", "grid", "interp", "object", "min"], "docstring": "deducting the median from each column", "docstring_tokens": ["deducting", "the", "median", "from", "each", "column"], "idx": 505}
{"url": "https://github.com/bitesofcode/projexui/blob/f18a73bec84df90b034ca69b9deea118dbedfc4d/projexui/widgets/xpushbutton.py#L72-L90", "repo": "projexui", "func_name": "setShowRichText", "original_string": ["    def setShowRichText(self, state):\n", "        \"\"\"\n", "        Sets whether or not to display rich text for this button.\n", "        \n", "        :param      state | <bool>\n", "        \"\"\"\n", "        self._showRichText = state\n", "        text = self.text()\n", "        \n", "        if state:\n", "            label = self.richTextLabel()\n", "            label.setText(text)\n", "            label.show()\n", "            super(XPushButton, self).setText('')\n", "        else:\n", "            if self._richTextLabel:\n", "                self._richTextLabel.hide()\n", "            \n", "            super(XPushButton, self).setText(text)\n"], "language": "python", "code": "def setShowRichText(self, state):\n    \"\"\"\"\"\"\n    self._showRichText = state\n    text = self.text()\n    if state:\n        label = self.richTextLabel()\n        label.setText(text)\n        label.show()\n        super(XPushButton, self).setText('')\n    else:\n        if self._richTextLabel:\n            self._richTextLabel.hide()\n        super(XPushButton, self).setText(text)\n", "code_tokens": ["setshowrichtext", "self", "state", "self", "showrichtext", "state", "text", "self", "text", "if", "state", "label", "self", "richtextlabel", "label", "settext", "text", "label", "show", "super", "xpushbutton", "self", "settext", "else", "if", "self", "richtextlabel", "self", "richtextlabel", "hide", "super", "xpushbutton", "self", "settext", "text"], "docstring": "underline text in label widget", "docstring_tokens": ["underline", "text", "in", "label", "widget"], "idx": 506}
{"url": "https://github.com/limodou/uliweb/blob/34472f25e4bc0b954a35346672f94e84ef18b076/uliweb/form/template_layout.py#L90-L108", "repo": "uliweb", "func_name": "do_td_field", "original_string": ["    def do_td_field(self, indent, value, **kwargs):\n", "        field_name = kwargs.pop('name', None)\n", "        field = getattr(self.form, field_name)\n", "        obj = self.form.fields[field_name]\n", "        if 'label' in kwargs:\n", "            label = kwargs.pop('label')\n", "        else:\n", "            label = obj.label\n", "        if label:\n", "            obj.label = label\n", "            label_text = obj.get_label(_class='field')\n", "        else:\n", "            label_text = ''\n", "            \n", "        display = field.data or '&nbsp;'\n", "        if 'width' not in kwargs:\n", "            kwargs['width'] = 200\n", "        td = begin_tag('td', **kwargs) + u_str(display) + end_tag('td')\n", "        return indent * ' ' + '<th align=right width=200>%s</th>%s' % (label_text, td)\n"], "language": "python", "code": "def do_td_field(self, indent, value, **kwargs):\n    field_name = kwargs.pop('name', None)\n    field = getattr(self.form, field_name)\n    obj = self.form.fields[field_name]\n    if 'label' in kwargs:\n        label = kwargs.pop('label')\n    else:\n        label = obj.label\n    if label:\n        obj.label = label\n        label_text = obj.get_label(_class='field')\n    else:\n        label_text = ''\n    display = field.data or '&nbsp;'\n    if 'width' not in kwargs:\n        kwargs['width'] = 200\n    td = begin_tag('td', **kwargs) + u_str(display) + end_tag('td')\n    return indent * ' ' + '<th align=right width=200>%s</th>%s' % (label_text,\n        td)\n", "code_tokens": ["do", "td", "field", "self", "indent", "value", "kwargs", "field", "name", "kwargs", "pop", "name", "none", "field", "getattr", "self", "form", "field", "name", "obj", "self", "form", "fields", "field", "name", "if", "label", "in", "kwargs", "label", "kwargs", "pop", "label", "else", "label", "obj", "label", "if", "label", "obj", "label", "label", "label", "text", "obj", "get", "label", "class", "field", "else", "label", "text", "display", "field", "data", "or", "nbsp", "if", "width", "not", "in", "kwargs", "kwargs", "width", "200", "td", "begin", "tag", "td", "kwargs", "str", "display", "end", "tag", "td", "return", "indent", "th", "align", "right", "width", "200", "th", "label", "text", "td"], "docstring": "underline text in label widget", "docstring_tokens": ["underline", "text", "in", "label", "widget"], "idx": 507}
{"url": "https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdfobjects/pdftext.py#L165-L172", "repo": "pypdflite", "func_name": "_underline", "original_string": ["    def _underline(self):\n", "        # Underline text\n", "        up = self.font.underline_position\n", "        ut = self.font.underline_thickness\n", "        w = self.font._string_width(self.text)\n", "        s = '%.2f %.2f %.2f %.2f re f' % (self.cursor.x,\n", "            self.cursor.y_prime - up, w, ut)\n", "        return s\n"], "language": "python", "code": "def _underline(self):\n    up = self.font.underline_position\n    ut = self.font.underline_thickness\n    w = self.font._string_width(self.text)\n    s = '%.2f %.2f %.2f %.2f re f' % (self.cursor.x, self.cursor.y_prime -\n        up, w, ut)\n    return s\n", "code_tokens": ["underline", "self", "up", "self", "font", "underline", "position", "ut", "self", "font", "underline", "thickness", "self", "font", "string", "width", "self", "text", "re", "self", "cursor", "self", "cursor", "prime", "up", "ut", "return"], "docstring": "underline text in label widget", "docstring_tokens": ["underline", "text", "in", "label", "widget"], "idx": 508}
{"url": "https://github.com/django-leonardo/django-leonardo/blob/4b933e1792221a13b4028753d5f1d3499b0816d4/leonardo/module/web/widgets/forms.py#L55-L144", "repo": "django-leonardo", "func_name": "__init__", "original_string": ["    def __init__(self, *args, **kwargs):\n", "        request = kwargs.pop('request', None)\n", "        model = kwargs.pop('model', None)\n", "\n", "        super(WidgetForm, self).__init__(*args, **kwargs)\n", "\n", "        if isinstance(model, Page):\n", "            self.fields['parent'] = PageSelectField(\n", "                label=_(\"Parent\"), help_text=_(\"Parent Page\"))\n", "        else:\n", "            self.fields['parent'].widget = forms.widgets.HiddenInput()\n", "\n", "        initial = kwargs.get('initial', None)\n", "\n", "        if initial and initial.get('id', None):\n", "            widget = self._meta.model.objects.get(\n", "                id=initial['id'])\n", "            data = widget.dimensions\n", "\n", "            self.init_content_themes()\n", "\n", "        elif 'instance' in kwargs:\n", "            widget = kwargs['instance']\n", "            data = widget.dimensions\n", "\n", "            self.init_content_themes()\n", "        else:\n", "            data = []\n", "            widget = None\n", "\n", "            # set defaults and delete id field\n", "            self.init_themes()\n", "            del self.fields['id']\n", "\n", "        # get all fields for widget\n", "        main_fields = self._meta.model.fields()\n", "        main_fields.update({'label': 'label'})\n", "        main_fields.pop(\"parent\", None)\n", "\n", "        self.helper.layout = Layout(\n", "            TabHolder(\n", "                Tab(self._meta.model._meta.verbose_name.capitalize(),\n", "                    *self.get_main_fields(main_fields),\n", "                    css_id='field-{}'.format(slugify(self._meta.model))\n", "                    ),\n", "                Tab(_('Styles'),\n", "                    'base_theme', 'content_theme', 'color_scheme',\n", "                    'prerendered_content',\n", "                    Fieldset(_('Positions'), 'layout', 'align',\n", "                             'vertical_align', 'parent'),\n", "                    *self.get_id_field(),\n", "                    css_id='theme-widget-settings'\n", "                    ),\n", "                Tab(_('Effects'),\n", "                    'enter_effect_style', 'enter_effect_duration',\n", "                    'enter_effect_delay', 'enter_effect_offset',\n", "                    'enter_effect_iteration',\n", "                    css_id='theme-widget-effects'\n", "                    ),\n", "            ),\n", "            HTML(render_to_string('widget/_update_preview.html',\n", "                                  {'class_name': \".\".join([\n", "                                      self._meta.model._meta.app_label,\n", "                                      self._meta.model._meta.model_name])\n", "                                   }))\n", "\n", "        )\n", "\n", "        self.fields['label'].widget = forms.TextInput(\n", "            attrs={'placeholder': self._meta.model._meta.verbose_name})\n", "\n", "        if request:\n", "            _request = copy.copy(request)\n", "            _request.POST = {}\n", "            _request.method = 'GET'\n", "            from .tables import WidgetDimensionTable\n", "            dimensions = Tab(_('Dimensions'),\n", "                             HTML(\n", "                WidgetDimensionTable(_request,\n", "                                     widget=widget,\n", "                                     data=data).render()),\n", "                             )\n", "            self.helper.layout[0].append(dimensions)\n", "\n", "        # hide label\n", "        if 'text' in self.fields:\n", "            self.fields['text'].label = ''\n", "\n", "        # finally add custom tabs\n", "        self.init_custom_tabs()\n"], "language": "python", "code": "def __init__(self, *args, **kwargs):\n    request = kwargs.pop('request', None)\n    model = kwargs.pop('model', None)\n    super(WidgetForm, self).__init__(*args, **kwargs)\n    if isinstance(model, Page):\n        self.fields['parent'] = PageSelectField(label=_('Parent'),\n            help_text=_('Parent Page'))\n    else:\n        self.fields['parent'].widget = forms.widgets.HiddenInput()\n    initial = kwargs.get('initial', None)\n    if initial and initial.get('id', None):\n        widget = self._meta.model.objects.get(id=initial['id'])\n        data = widget.dimensions\n        self.init_content_themes()\n    elif 'instance' in kwargs:\n        widget = kwargs['instance']\n        data = widget.dimensions\n        self.init_content_themes()\n    else:\n        data = []\n        widget = None\n        self.init_themes()\n        del self.fields['id']\n    main_fields = self._meta.model.fields()\n    main_fields.update({'label': 'label'})\n    main_fields.pop('parent', None)\n    self.helper.layout = Layout(TabHolder(Tab(self._meta.model._meta.\n        verbose_name.capitalize(), *self.get_main_fields(main_fields),\n        css_id='field-{}'.format(slugify(self._meta.model))), Tab(_(\n        'Styles'), 'base_theme', 'content_theme', 'color_scheme',\n        'prerendered_content', Fieldset(_('Positions'), 'layout', 'align',\n        'vertical_align', 'parent'), *self.get_id_field(), css_id=\n        'theme-widget-settings'), Tab(_('Effects'), 'enter_effect_style',\n        'enter_effect_duration', 'enter_effect_delay',\n        'enter_effect_offset', 'enter_effect_iteration', css_id=\n        'theme-widget-effects')), HTML(render_to_string(\n        'widget/_update_preview.html', {'class_name': '.'.join([self._meta.\n        model._meta.app_label, self._meta.model._meta.model_name])})))\n    self.fields['label'].widget = forms.TextInput(attrs={'placeholder':\n        self._meta.model._meta.verbose_name})\n    if request:\n        _request = copy.copy(request)\n        _request.POST = {}\n        _request.method = 'GET'\n        from .tables import WidgetDimensionTable\n        dimensions = Tab(_('Dimensions'), HTML(WidgetDimensionTable(\n            _request, widget=widget, data=data).render()))\n        self.helper.layout[0].append(dimensions)\n    if 'text' in self.fields:\n        self.fields['text'].label = ''\n    self.init_custom_tabs()\n", "code_tokens": ["init", "self", "args", "kwargs", "request", "kwargs", "pop", "request", "none", "model", "kwargs", "pop", "model", "none", "super", "widgetform", "self", "init", "args", "kwargs", "if", "isinstance", "model", "page", "self", "fields", "parent", "pageselectfield", "label", "parent", "help", "text", "parent", "page", "else", "self", "fields", "parent", "widget", "forms", "widgets", "hiddeninput", "initial", "kwargs", "get", "initial", "none", "if", "initial", "and", "initial", "get", "id", "none", "widget", "self", "meta", "model", "objects", "get", "id", "initial", "id", "data", "widget", "dimensions", "self", "init", "content", "themes", "elif", "instance", "in", "kwargs", "widget", "kwargs", "instance", "data", "widget", "dimensions", "self", "init", "content", "themes", "else", "data", "widget", "none", "self", "init", "themes", "del", "self", "fields", "id", "main", "fields", "self", "meta", "model", "fields", "main", "fields", "update", "label", "label", "main", "fields", "pop", "parent", "none", "self", "helper", "layout", "layout", "tabholder", "tab", "self", "meta", "model", "meta", "verbose", "name", "capitalize", "self", "get", "main", "fields", "main", "fields", "css", "id", "field", "format", "slugify", "self", "meta", "model", "tab", "styles", "base", "theme", "content", "theme", "color", "scheme", "prerendered", "content", "fieldset", "positions", "layout", "align", "vertical", "align", "parent", "self", "get", "id", "field", "css", "id", "theme", "widget", "settings", "tab", "effects", "enter", "effect", "style", "enter", "effect", "duration", "enter", "effect", "delay", "enter", "effect", "offset", "enter", "effect", "iteration", "css", "id", "theme", "widget", "effects", "html", "render", "to", "string", "widget", "update", "preview", "html", "class", "name", "join", "self", "meta", "model", "meta", "app", "label", "self", "meta", "model", "meta", "model", "name", "self", "fields", "label", "widget", "forms", "textinput", "attrs", "placeholder", "self", "meta", "model", "meta", "verbose", "name", "if", "request", "request", "copy", "copy", "request", "request", "post", "request", "method", "get", "from", "tables", "import", "widgetdimensiontable", "dimensions", "tab", "dimensions", "html", "widgetdimensiontable", "request", "widget", "widget", "data", "data", "render", "self", "helper", "layout", "0", "append", "dimensions", "if", "text", "in", "self", "fields", "self", "fields", "text", "label", "self", "init", "custom", "tabs"], "docstring": "underline text in label widget", "docstring_tokens": ["underline", "text", "in", "label", "widget"], "idx": 509}
{"url": "https://github.com/dendory/menu3/blob/350414966e8f5c7737cd527369c8087f4f8f600b/menu3/menu3.py#L45-L49", "repo": "menu3", "func_name": "underline", "original_string": ["\tdef underline(self, text): # Print an underline text\n", "\t\tif self._windows():\n", "\t\t\treturn text\n", "\t\telse:\n", "\t\t\treturn self.UNDERLINE + text + self.NORMAL\n"], "language": "python", "code": "def underline(self, text):\n    if self._windows():\n        return text\n    else:\n        return self.UNDERLINE + text + self.NORMAL\n", "code_tokens": ["underline", "self", "text", "if", "self", "windows", "return", "text", "else", "return", "self", "underline", "text", "self", "normal"], "docstring": "underline text in label widget", "docstring_tokens": ["underline", "text", "in", "label", "widget"], "idx": 510}
{"url": "https://github.com/MillionIntegrals/vel/blob/e0726e1f63742b728966ccae0c8b825ea0ba491a/vel/util/summary.py#L11-L86", "repo": "vel", "func_name": "summary", "original_string": ["def summary(model, input_size):\n", "    \"\"\" Print summary of the model \"\"\"\n", "    def register_hook(module):\n", "        def hook(module, input, output):\n", "            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n", "            module_idx = len(summary)\n", "\n", "            m_key = '%s-%i' % (class_name, module_idx + 1)\n", "            summary[m_key] = OrderedDict()\n", "            summary[m_key]['input_shape'] = list(input[0].size())\n", "            summary[m_key]['input_shape'][0] = -1\n", "            if isinstance(output, (list, tuple)):\n", "                summary[m_key]['output_shape'] = [[-1] + list(o.size())[1:] for o in output]\n", "            else:\n", "                summary[m_key]['output_shape'] = list(output.size())\n", "                summary[m_key]['output_shape'][0] = -1\n", "\n", "            params = 0\n", "            if hasattr(module, 'weight') and hasattr(module.weight, 'size'):\n", "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n", "                summary[m_key]['trainable'] = module.weight.requires_grad\n", "            if hasattr(module, 'bias') and hasattr(module.bias, 'size'):\n", "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n", "            summary[m_key]['nb_params'] = params\n", "\n", "        if (not isinstance(module, nn.Sequential) and\n", "                not isinstance(module, nn.ModuleList) and\n", "                not (module == model)):\n", "            hooks.append(module.register_forward_hook(hook))\n", "\n", "    if torch.cuda.is_available():\n", "        dtype = torch.cuda.FloatTensor\n", "        model = model.cuda()\n", "    else:\n", "        dtype = torch.FloatTensor\n", "        model = model.cpu()\n", "\n", "    # check if there are multiple inputs to the network\n", "    if isinstance(input_size[0], (list, tuple)):\n", "        x = [Variable(torch.rand(2, *in_size)).type(dtype) for in_size in input_size]\n", "    else:\n", "        x = Variable(torch.rand(2, *input_size)).type(dtype)\n", "\n", "    # print(type(x[0]))\n", "    # create properties\n", "    summary = OrderedDict()\n", "    hooks = []\n", "    # register hook\n", "    model.apply(register_hook)\n", "    # make a forward pass\n", "    # print(x.shape)\n", "    model(x)\n", "    # remove these hooks\n", "    for h in hooks:\n", "        h.remove()\n", "\n", "    print('----------------------------------------------------------------')\n", "    line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)', 'Output Shape', 'Param #')\n", "    print(line_new)\n", "    print('================================================================')\n", "    total_params = 0\n", "    trainable_params = 0\n", "    for layer in summary:\n", "        # input_shape, output_shape, trainable, nb_params\n", "        line_new = '{:>20}  {:>25} {:>15}'.format(layer, str(summary[layer]['output_shape']),\n", "                                                  '{0:,}'.format(summary[layer]['nb_params']))\n", "        total_params += summary[layer]['nb_params']\n", "        if 'trainable' in summary[layer]:\n", "            if summary[layer]['trainable'] == True:\n", "                trainable_params += summary[layer]['nb_params']\n", "        print(line_new)\n", "    print('================================================================')\n", "    print('Total params: {0:,}'.format(total_params))\n", "    print('Trainable params: {0:,}'.format(trainable_params))\n", "    print('Non-trainable params: {0:,}'.format(total_params - trainable_params))\n", "    print('----------------------------------------------------------------')\n"], "language": "python", "code": "def summary(model, input_size):\n    \"\"\"\"\"\"\n\n    def register_hook(module):\n\n        def hook(module, input, output):\n            class_name = str(module.__class__).split('.')[-1].split(\"'\")[0]\n            module_idx = len(summary)\n            m_key = '%s-%i' % (class_name, module_idx + 1)\n            summary[m_key] = OrderedDict()\n            summary[m_key]['input_shape'] = list(input[0].size())\n            summary[m_key]['input_shape'][0] = -1\n            if isinstance(output, (list, tuple)):\n                summary[m_key]['output_shape'] = [([-1] + list(o.size())[1:\n                    ]) for o in output]\n            else:\n                summary[m_key]['output_shape'] = list(output.size())\n                summary[m_key]['output_shape'][0] = -1\n            params = 0\n            if hasattr(module, 'weight') and hasattr(module.weight, 'size'):\n                params += torch.prod(torch.LongTensor(list(module.weight.\n                    size())))\n                summary[m_key]['trainable'] = module.weight.requires_grad\n            if hasattr(module, 'bias') and hasattr(module.bias, 'size'):\n                params += torch.prod(torch.LongTensor(list(module.bias.size()))\n                    )\n            summary[m_key]['nb_params'] = params\n        if not isinstance(module, nn.Sequential) and not isinstance(module,\n            nn.ModuleList) and not module == model:\n            hooks.append(module.register_forward_hook(hook))\n    if torch.cuda.is_available():\n        dtype = torch.cuda.FloatTensor\n        model = model.cuda()\n    else:\n        dtype = torch.FloatTensor\n        model = model.cpu()\n    if isinstance(input_size[0], (list, tuple)):\n        x = [Variable(torch.rand(2, *in_size)).type(dtype) for in_size in\n            input_size]\n    else:\n        x = Variable(torch.rand(2, *input_size)).type(dtype)\n    summary = OrderedDict()\n    hooks = []\n    model.apply(register_hook)\n    model(x)\n    for h in hooks:\n        h.remove()\n    print('----------------------------------------------------------------')\n    line_new = '{:>20}  {:>25} {:>15}'.format('Layer (type)',\n        'Output Shape', 'Param #')\n    print(line_new)\n    print('================================================================')\n    total_params = 0\n    trainable_params = 0\n    for layer in summary:\n        line_new = '{:>20}  {:>25} {:>15}'.format(layer, str(summary[layer]\n            ['output_shape']), '{0:,}'.format(summary[layer]['nb_params']))\n        total_params += summary[layer]['nb_params']\n        if 'trainable' in summary[layer]:\n            if summary[layer]['trainable'] == True:\n                trainable_params += summary[layer]['nb_params']\n        print(line_new)\n    print('================================================================')\n    print('Total params: {0:,}'.format(total_params))\n    print('Trainable params: {0:,}'.format(trainable_params))\n    print('Non-trainable params: {0:,}'.format(total_params - trainable_params)\n        )\n    print('----------------------------------------------------------------')\n", "code_tokens": ["summary", "model", "input", "size", "def", "register", "hook", "module", "def", "hook", "module", "input", "output", "class", "name", "str", "module", "class", "split", "1", "split", "0", "module", "idx", "len", "summary", "key", "class", "name", "module", "idx", "1", "summary", "key", "ordereddict", "summary", "key", "input", "shape", "list", "input", "0", "size", "summary", "key", "input", "shape", "0", "1", "if", "isinstance", "output", "list", "tuple", "summary", "key", "output", "shape", "1", "list", "size", "1", "for", "in", "output", "else", "summary", "key", "output", "shape", "list", "output", "size", "summary", "key", "output", "shape", "0", "1", "params", "0", "if", "hasattr", "module", "weight", "and", "hasattr", "module", "weight", "size", "params", "torch", "prod", "torch", "longtensor", "list", "module", "weight", "size", "summary", "key", "trainable", "module", "weight", "requires", "grad", "if", "hasattr", "module", "bias", "and", "hasattr", "module", "bias", "size", "params", "torch", "prod", "torch", "longtensor", "list", "module", "bias", "size", "summary", "key", "nb", "params", "params", "if", "not", "isinstance", "module", "nn", "sequential", "and", "not", "isinstance", "module", "nn", "modulelist", "and", "not", "module", "model", "hooks", "append", "module", "register", "forward", "hook", "hook", "if", "torch", "cuda", "is", "available", "dtype", "torch", "cuda", "floattensor", "model", "model", "cuda", "else", "dtype", "torch", "floattensor", "model", "model", "cpu", "if", "isinstance", "input", "size", "0", "list", "tuple", "variable", "torch", "rand", "2", "in", "size", "type", "dtype", "for", "in", "size", "in", "input", "size", "else", "variable", "torch", "rand", "2", "input", "size", "type", "dtype", "summary", "ordereddict", "hooks", "model", "apply", "register", "hook", "model", "for", "in", "hooks", "remove", "print", "line", "new", "20", "25", "15", "format", "layer", "type", "output", "shape", "param", "print", "line", "new", "print", "total", "params", "0", "trainable", "params", "0", "for", "layer", "in", "summary", "line", "new", "20", "25", "15", "format", "layer", "str", "summary", "layer", "output", "shape", "0", "format", "summary", "layer", "nb", "params", "total", "params", "summary", "layer", "nb", "params", "if", "trainable", "in", "summary", "layer", "if", "summary", "layer", "trainable", "true", "trainable", "params", "summary", "layer", "nb", "params", "print", "line", "new", "print", "print", "total", "params", "0", "format", "total", "params", "print", "trainable", "params", "0", "format", "trainable", "params", "print", "non", "trainable", "params", "0", "format", "total", "params", "trainable", "params", "print"], "docstring": "print model summary", "docstring_tokens": ["print", "model", "summary"], "idx": 511}
{"url": "https://github.com/MillionIntegrals/vel/blob/e0726e1f63742b728966ccae0c8b825ea0ba491a/vel/api/model.py#L37-L51", "repo": "vel", "func_name": "summary", "original_string": ["    def summary(self, input_size=None, hashsummary=False):\n", "        \"\"\" Print a model summary \"\"\"\n", "\n", "        if input_size is None:\n", "            print(self)\n", "            print(\"-\" * 120)\n", "            number = sum(p.numel() for p in self.model.parameters())\n", "            print(\"Number of model parameters: {:,}\".format(number))\n", "            print(\"-\" * 120)\n", "        else:\n", "            summary(self, input_size)\n", "\n", "        if hashsummary:\n", "            for idx, hashvalue in enumerate(self.hashsummary()):\n", "                print(f\"{idx}: {hashvalue}\")\n"], "language": "python", "code": "def summary(self, input_size=None, hashsummary=False):\n    \"\"\"\"\"\"\n    if input_size is None:\n        print(self)\n        print('-' * 120)\n        number = sum(p.numel() for p in self.model.parameters())\n        print('Number of model parameters: {:,}'.format(number))\n        print('-' * 120)\n    else:\n        summary(self, input_size)\n    if hashsummary:\n        for idx, hashvalue in enumerate(self.hashsummary()):\n            print(f'{idx}: {hashvalue}')\n", "code_tokens": ["summary", "self", "input", "size", "none", "hashsummary", "false", "if", "input", "size", "is", "none", "print", "self", "print", "120", "number", "sum", "numel", "for", "in", "self", "model", "parameters", "print", "number", "of", "model", "parameters", "format", "number", "print", "120", "else", "summary", "self", "input", "size", "if", "hashsummary", "for", "idx", "hashvalue", "in", "enumerate", "self", "hashsummary", "print", "idx", "hashvalue"], "docstring": "print model summary", "docstring_tokens": ["print", "model", "summary"], "idx": 512}
{"url": "https://github.com/ioam/lancet/blob/1fbbf88fa0e8974ff9ed462e3cb11722ddebdd6e/lancet/dynamic.py#L257-L265", "repo": "lancet", "func_name": "summary", "original_string": ["    def summary(self):\n", "        print('Varying Keys: %r' % self.key)\n", "        print('Maximum steps allowed: %d' % self.max_steps)\n", "        self._trace_summary()\n", "        (val, arg) = (self.trace[-1])\n", "        if self._termination_info:\n", "            (success, best_val, arg) = self._termination_info\n", "            condition =  'Successfully converged.' if success else 'Maximum step limit reached.'\n", "            print(\"%s Minimum value of %r at %s=%r.\" % (condition, best_val, self.key, arg))\n"], "language": "python", "code": "def summary(self):\n    print('Varying Keys: %r' % self.key)\n    print('Maximum steps allowed: %d' % self.max_steps)\n    self._trace_summary()\n    val, arg = self.trace[-1]\n    if self._termination_info:\n        success, best_val, arg = self._termination_info\n        condition = ('Successfully converged.' if success else\n            'Maximum step limit reached.')\n        print('%s Minimum value of %r at %s=%r.' % (condition, best_val,\n            self.key, arg))\n", "code_tokens": ["summary", "self", "print", "varying", "keys", "self", "key", "print", "maximum", "steps", "allowed", "self", "max", "steps", "self", "trace", "summary", "val", "arg", "self", "trace", "1", "if", "self", "termination", "info", "success", "best", "val", "arg", "self", "termination", "info", "condition", "successfully", "converged", "if", "success", "else", "maximum", "step", "limit", "reached", "print", "minimum", "value", "of", "at", "condition", "best", "val", "self", "key", "arg"], "docstring": "print model summary", "docstring_tokens": ["print", "model", "summary"], "idx": 513}
{"url": "https://github.com/lrq3000/pyFileFixity/blob/fd5ef23bb13835faf1e3baa773619b86a1cc9bdf/pyFileFixity/lib/profilers/visual/pympler/tracker.py#L126-L134", "repo": "pyFileFixity", "func_name": "print_diff", "original_string": ["    def print_diff(self, summary1=None, summary2=None):\n", "        \"\"\"Compute diff between to summaries and print it.\n", "\n", "        If no summary is provided, the diff from the last to the current\n", "        summary is used. If summary1 is provided the diff from summary1\n", "        to the current summary is used. If summary1 and summary2 are\n", "        provided, the diff between these two is used.\n", "        \"\"\"\n", "        summary.print_(self.diff(summary1=summary1, summary2=summary2))\n"], "language": "python", "code": "def print_diff(self, summary1=None, summary2=None):\n    \"\"\"\"\"\"\n    summary.print_(self.diff(summary1=summary1, summary2=summary2))\n", "code_tokens": ["print", "diff", "self", "none", "none", "summary", "print", "self", "diff"], "docstring": "print model summary", "docstring_tokens": ["print", "model", "summary"], "idx": 514}
{"url": "https://github.com/Shapeways/coyote_framework/blob/cb29899b984a21d56bf65d0b1d907073948fe16c/coyote_framework/webdriver/webdriverwrapper/WebElementWrapper.py#L662-L667", "repo": "coyote_framework", "func_name": "checkbox_uncheck", "original_string": ["    def checkbox_uncheck(self, force_check=False):\n", "        \"\"\"\n", "        Wrapper to uncheck a checkbox\n", "        \"\"\"\n", "        if self.get_attribute('checked'):\n", "            self.click(force_click=force_check)\n"], "language": "python", "code": "def checkbox_uncheck(self, force_check=False):\n    \"\"\"\"\"\"\n    if self.get_attribute('checked'):\n        self.click(force_click=force_check)\n", "code_tokens": ["checkbox", "uncheck", "self", "force", "check", "false", "if", "self", "get", "attribute", "checked", "self", "click", "force", "click", "force", "check"], "docstring": "how to make the checkbox checked", "docstring_tokens": ["how", "to", "make", "the", "checkbox", "checked"], "idx": 515}
{"url": "https://github.com/nion-software/nionswift/blob/d43693eaf057b8683b9638e575000f055fede452/nion/swift/Facade.py#L612-L615", "repo": "nionswift", "func_name": "create_line_edit_widget", "original_string": ["    def create_line_edit_widget(self, text: typing.Optional[str] = None) -> LineEditWidget:\n", "        line_edit_widget = LineEditWidget(self.__ui)\n", "        line_edit_widget.text = text\n", "        return line_edit_widget\n"], "language": "python", "code": "def create_line_edit_widget(self, text: typing.Optional[str]=None\n    ) ->LineEditWidget:\n    line_edit_widget = LineEditWidget(self.__ui)\n    line_edit_widget.text = text\n    return line_edit_widget\n", "code_tokens": ["create", "line", "edit", "widget", "self", "text", "typing", "optional", "str", "none", "lineeditwidget", "line", "edit", "widget", "lineeditwidget", "self", "ui", "line", "edit", "widget", "text", "text", "return", "line", "edit", "widget"], "docstring": "how to make the checkbox checked", "docstring_tokens": ["how", "to", "make", "the", "checkbox", "checked"], "idx": 516}
{"url": "https://github.com/mcs07/ChemDataExtractor/blob/349a3bea965f2073141d62043b89319222e46af1/chemdataextractor/text/__init__.py#L232-L258", "repo": "ChemDataExtractor", "func_name": "levenshtein", "original_string": ["def levenshtein(s1, s2, allow_substring=False):\n", "    \"\"\"Return the Levenshtein distance between two strings.\n", "\n", "    The Levenshtein distance (a.k.a \"edit difference\") is the number of characters that need to be substituted,\n", "    inserted or deleted to transform s1 into s2.\n", "\n", "    Setting the `allow_substring` parameter to True allows s1 to be a\n", "    substring of s2, so that, for example, \"hello\" and \"hello there\" would have a distance of zero.\n", "\n", "    :param string s1: The first string\n", "    :param string s2: The second string\n", "    :param bool allow_substring: Whether to allow s1 to be a substring of s2\n", "    :returns: Levenshtein distance.\n", "    :rtype int\n", "    \"\"\"\n", "    len1, len2 = len(s1), len(s2)\n", "    lev = []\n", "    for i in range(len1 + 1):\n", "        lev.append([0] * (len2 + 1))\n", "    for i in range(len1 + 1):\n", "        lev[i][0] = i\n", "    for j in range(len2 + 1):\n", "        lev[0][j] = 0 if allow_substring else j\n", "    for i in range(len1):\n", "        for j in range(len2):\n", "            lev[i + 1][j + 1] = min(lev[i][j + 1] + 1, lev[i + 1][j] + 1, lev[i][j] + (s1[i] != s2[j]))\n", "    return min(lev[len1]) if allow_substring else lev[len1][len2]\n"], "language": "python", "code": "def levenshtein(s1, s2, allow_substring=False):\n    \"\"\"\"\"\"\n    len1, len2 = len(s1), len(s2)\n    lev = []\n    for i in range(len1 + 1):\n        lev.append([0] * (len2 + 1))\n    for i in range(len1 + 1):\n        lev[i][0] = i\n    for j in range(len2 + 1):\n        lev[0][j] = 0 if allow_substring else j\n    for i in range(len1):\n        for j in range(len2):\n            lev[i + 1][j + 1] = min(lev[i][j + 1] + 1, lev[i + 1][j] + 1, \n                lev[i][j] + (s1[i] != s2[j]))\n    return min(lev[len1]) if allow_substring else lev[len1][len2]\n", "code_tokens": ["levenshtein", "allow", "substring", "false", "len", "len", "lev", "for", "in", "range", "1", "lev", "append", "0", "1", "for", "in", "range", "1", "lev", "0", "for", "in", "range", "1", "lev", "0", "0", "if", "allow", "substring", "else", "for", "in", "range", "for", "in", "range", "lev", "1", "1", "min", "lev", "1", "1", "lev", "1", "1", "lev", "return", "min", "lev", "if", "allow", "substring", "else", "lev"], "docstring": "string similarity levenshtein", "docstring_tokens": ["string", "similarity", "levenshtein"], "idx": 517}
{"url": "https://github.com/EventTeam/beliefs/blob/c07d22b61bebeede74a72800030dde770bf64208/src/beliefs/belief_utils.py#L143-L145", "repo": "beliefs", "func_name": "levenshtein_distance_metric", "original_string": ["def levenshtein_distance_metric(a, b):\n", "    \"\"\" 1 - farthest apart (same number of words, all diff). 0 - same\"\"\"\n", "    return (levenshtein_distance(a, b) / (2.0 * max(len(a), len(b), 1)))\n"], "language": "python", "code": "def levenshtein_distance_metric(a, b):\n    \"\"\"\"\"\"\n    return levenshtein_distance(a, b) / (2.0 * max(len(a), len(b), 1))\n", "code_tokens": ["levenshtein", "distance", "metric", "return", "levenshtein", "distance", "2", "0", "max", "len", "len", "1"], "docstring": "string similarity levenshtein", "docstring_tokens": ["string", "similarity", "levenshtein"], "idx": 518}
{"url": "https://github.com/SignalN/language/blob/5c50c78f65bcc2c999b44d530e7412185248352d/language/ngrams.py#L150-L151", "repo": "language", "func_name": "word_similarity", "original_string": ["def word_similarity(s1, s2, n=3):\n", "    return __similarity(s1, s2, word_ngrams, n=n)\n"], "language": "python", "code": "def word_similarity(s1, s2, n=3):\n    return __similarity(s1, s2, word_ngrams, n=n)\n", "code_tokens": ["word", "similarity", "3", "return", "similarity", "word", "ngrams"], "docstring": "string similarity levenshtein", "docstring_tokens": ["string", "similarity", "levenshtein"], "idx": 519}
{"url": "https://github.com/Games-and-Simulations/sc-docker/blob/1d7adb9b5839783655564afc4bbcd204a0055dcb/scbw/utils.py#L18-L37", "repo": "sc-docker", "func_name": "levenshtein_dist", "original_string": ["def levenshtein_dist(s1: str, s2: str) -> int:\n", "    if len(s1) < len(s2):\n", "        return levenshtein_dist(s2, s1)\n", "\n", "    # len(s1) >= len(s2)\n", "    if len(s2) == 0:\n", "        return len(s1)\n", "\n", "    previous_row = range(len(s2) + 1)\n", "    for i, c1 in enumerate(s1):\n", "        current_row = [i + 1]\n", "        for j, c2 in enumerate(s2):\n", "            # j+1 instead of j since previous_row and current_row are one character longer\n", "            insertions = previous_row[j + 1] + 1\n", "            deletions = current_row[j] + 1  # than s2\n", "            substitutions = previous_row[j] + (c1 != c2)\n", "            current_row.append(min(insertions, deletions, substitutions))\n", "        previous_row = current_row\n", "\n", "    return previous_row[-1]\n"], "language": "python", "code": "def levenshtein_dist(s1: str, s2: str) ->int:\n    if len(s1) < len(s2):\n        return levenshtein_dist(s2, s1)\n    if len(s2) == 0:\n        return len(s1)\n    previous_row = range(len(s2) + 1)\n    for i, c1 in enumerate(s1):\n        current_row = [i + 1]\n        for j, c2 in enumerate(s2):\n            insertions = previous_row[j + 1] + 1\n            deletions = current_row[j] + 1\n            substitutions = previous_row[j] + (c1 != c2)\n            current_row.append(min(insertions, deletions, substitutions))\n        previous_row = current_row\n    return previous_row[-1]\n", "code_tokens": ["levenshtein", "dist", "str", "str", "int", "if", "len", "len", "return", "levenshtein", "dist", "if", "len", "0", "return", "len", "previous", "row", "range", "len", "1", "for", "in", "enumerate", "current", "row", "1", "for", "in", "enumerate", "insertions", "previous", "row", "1", "1", "deletions", "current", "row", "1", "substitutions", "previous", "row", "current", "row", "append", "min", "insertions", "deletions", "substitutions", "previous", "row", "current", "row", "return", "previous", "row", "1"], "docstring": "string similarity levenshtein", "docstring_tokens": ["string", "similarity", "levenshtein"], "idx": 520}
{"url": "https://github.com/Lilykos/pyphonetics/blob/7f55cccc1135e6015520a895eb6859318a4b6111/pyphonetics/distance_metrics/levenshtein.py#L1-L29", "repo": "pyphonetics", "func_name": "levenshtein_distance", "original_string": ["def levenshtein_distance(word1, word2):\n", "    \"\"\"\n", "    Computes the Levenshtein distance.\n", "\n", "    [Reference]: https://en.wikipedia.org/wiki/Levenshtein_distance\n", "    [Article]: Levenshtein, Vladimir I. (February 1966). \"Binary codes capable of correcting deletions,\n", "        insertions,and reversals\". Soviet Physics Doklady 10 (8): 707\u2013710.\n", "    [Implementation]: https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python\n", "    \"\"\"\n", "    if len(word1) < len(word2):\n", "        return levenshtein_distance(word2, word1)\n", "\n", "    if len(word2) == 0:\n", "        return len(word1)\n", "\n", "    previous_row = list(range(len(word2) + 1))\n", "\n", "    for i, char1 in enumerate(word1):\n", "        current_row = [i + 1]\n", "\n", "        for j, char2 in enumerate(word2):\n", "            insertions = previous_row[j + 1] + 1\n", "            deletions = current_row[j] + 1\n", "            substitutions = previous_row[j] + (char1 != char2)\n", "\n", "            current_row.append(min(insertions, deletions, substitutions))\n", "\n", "        previous_row = current_row\n", "    return previous_row[-1]\n"], "language": "python", "code": "def levenshtein_distance(word1, word2):\n    \"\"\"\"\"\"\n    if len(word1) < len(word2):\n        return levenshtein_distance(word2, word1)\n    if len(word2) == 0:\n        return len(word1)\n    previous_row = list(range(len(word2) + 1))\n    for i, char1 in enumerate(word1):\n        current_row = [i + 1]\n        for j, char2 in enumerate(word2):\n            insertions = previous_row[j + 1] + 1\n            deletions = current_row[j] + 1\n            substitutions = previous_row[j] + (char1 != char2)\n            current_row.append(min(insertions, deletions, substitutions))\n        previous_row = current_row\n    return previous_row[-1]\n", "code_tokens": ["levenshtein", "distance", "if", "len", "len", "return", "levenshtein", "distance", "if", "len", "0", "return", "len", "previous", "row", "list", "range", "len", "1", "for", "in", "enumerate", "current", "row", "1", "for", "in", "enumerate", "insertions", "previous", "row", "1", "1", "deletions", "current", "row", "1", "substitutions", "previous", "row", "current", "row", "append", "min", "insertions", "deletions", "substitutions", "previous", "row", "current", "row", "return", "previous", "row", "1"], "docstring": "string similarity levenshtein", "docstring_tokens": ["string", "similarity", "levenshtein"], "idx": 521}
