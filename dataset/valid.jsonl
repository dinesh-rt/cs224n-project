{"url": "https://github.com/rberrelleza/511-transit/blob/ab676d6e3b57a073405cbfa2ffe1a57b85808fd1/fiveoneone/model.py#L18-L27", "repo": "511-transit", "func_name": "to_bool", "original_string": ["    def to_bool(self, value):\n", "         if value == None:\n", "             return False\n", "         elif isinstance(value, bool):\n", "             return value\n", "         else:\n", "             if str(value).lower() in [\"true\", \"1\", \"yes\"]:\n", "                 return True\n", "             else:\n", "                 return False\n"], "language": "python", "code": "def to_bool(self, value):\n    if value == None:\n        return False\n    elif isinstance(value, bool):\n        return value\n    elif str(value).lower() in ['true', '1', 'yes']:\n        return True\n    else:\n        return False\n", "code_tokens": ["to", "bool", "self", "value", "if", "value", "none", "return", "false", "elif", "isinstance", "value", "bool", "return", "value", "elif", "str", "value", "lower", "in", "true", "1", "yes", "return", "true", "else", "return", "false"], "docstring": "convert int to bool", "docstring_tokens": ["convert", "int", "to", "bool"], "idx": 356}
{"url": "https://github.com/RudolfCardinal/pythonlib/blob/0b84cb35f38bd7d8723958dae51b480a829b7227/cardinal_pythonlib/convert.py#L43-L73", "repo": "pythonlib", "func_name": "convert_to_bool", "original_string": ["\n", "def convert_to_bool(x: Any, default: bool = None) -> bool:\n", "    \"\"\"\n", "    Transforms its input to a ``bool`` (or returns ``default`` if ``x`` is\n", "    falsy but not itself a boolean). Accepts various common string versions.\n", "    \"\"\"\n", "    if isinstance(x, bool):\n", "        return x\n", "\n", "    if not x:  # None, zero, blank string...\n", "        return default\n", "\n", "    try:\n", "        return int(x) != 0\n", "    except (TypeError, ValueError):\n", "        pass\n", "\n", "    try:\n", "        return float(x) != 0\n", "    except (TypeError, ValueError):\n", "        pass\n", "\n", "    if not isinstance(x, str):\n", "        raise Exception(f\"Unknown thing being converted to bool: {x!r}\")\n", "\n", "    x = x.upper()\n", "    if x in [\"Y\", \"YES\", \"T\", \"TRUE\"]:\n", "        return True\n", "    if x in [\"N\", \"NO\", \"F\", \"FALSE\"]:\n", "        return False\n", "\n"], "language": "python", "code": "def convert_to_bool(x: Any, default: bool=None) ->bool:\n    \"\"\"\"\"\"\n    if isinstance(x, bool):\n        return x\n    if not x:\n        return default\n    try:\n        return int(x) != 0\n    except (TypeError, ValueError):\n        pass\n    try:\n        return float(x) != 0\n    except (TypeError, ValueError):\n        pass\n    if not isinstance(x, str):\n        raise Exception(f'Unknown thing being converted to bool: {x!r}')\n    x = x.upper()\n    if x in ['Y', 'YES', 'T', 'TRUE']:\n        return True\n    if x in ['N', 'NO', 'F', 'FALSE']:\n        return False\n", "code_tokens": ["convert", "to", "bool", "any", "default", "bool", "none", "bool", "if", "isinstance", "bool", "return", "if", "not", "return", "default", "try", "return", "int", "0", "except", "typeerror", "valueerror", "pass", "try", "return", "float", "0", "except", "typeerror", "valueerror", "pass", "if", "not", "isinstance", "str", "raise", "exception", "unknown", "thing", "being", "converted", "to", "bool", "upper", "if", "in", "yes", "true", "return", "true", "if", "in", "no", "false", "return", "false"], "docstring": "convert int to bool", "docstring_tokens": ["convert", "int", "to", "bool"], "idx": 357}
{"url": "https://github.com/AustralianSynchrotron/lightflow/blob/dc53dbc1d961e20fb144273baca258060705c03e/lightflow/models/parameters.py#L62-L93", "repo": "lightflow", "func_name": "convert", "original_string": ["    def convert(self, value):\n", "        \"\"\" Convert the specified value to the type of the option.\n", "\n", "        Args:\n", "            value: The value that should be converted.\n", "\n", "        Returns:\n", "            The value with the type given by the option.\n", "        \"\"\"\n", "        if self._type is str:\n", "            return str(value)\n", "        elif self._type is int:\n", "            try:\n", "                return int(value)\n", "            except (UnicodeError, ValueError):\n", "                raise WorkflowArgumentError('Cannot convert {} to int'.format(value))\n", "        elif self._type is float:\n", "            try:\n", "                return float(value)\n", "            except (UnicodeError, ValueError):\n", "                raise WorkflowArgumentError('Cannot convert {} to float'.format(value))\n", "        elif self._type is bool:\n", "            if isinstance(value, bool):\n", "                return bool(value)\n", "            value = value.lower()\n", "            if value in ('true', '1', 'yes', 'y'):\n", "                return True\n", "            elif value in ('false', '0', 'no', 'n'):\n", "                return False\n", "            raise WorkflowArgumentError('Cannot convert {} to bool'.format(value))\n", "        else:\n", "            return value\n"], "language": "python", "code": "def convert(self, value):\n    \"\"\"\"\"\"\n    if self._type is str:\n        return str(value)\n    elif self._type is int:\n        try:\n            return int(value)\n        except (UnicodeError, ValueError):\n            raise WorkflowArgumentError('Cannot convert {} to int'.format(\n                value))\n    elif self._type is float:\n        try:\n            return float(value)\n        except (UnicodeError, ValueError):\n            raise WorkflowArgumentError('Cannot convert {} to float'.format\n                (value))\n    elif self._type is bool:\n        if isinstance(value, bool):\n            return bool(value)\n        value = value.lower()\n        if value in ('true', '1', 'yes', 'y'):\n            return True\n        elif value in ('false', '0', 'no', 'n'):\n            return False\n        raise WorkflowArgumentError('Cannot convert {} to bool'.format(value))\n    else:\n        return value\n", "code_tokens": ["convert", "self", "value", "if", "self", "type", "is", "str", "return", "str", "value", "elif", "self", "type", "is", "int", "try", "return", "int", "value", "except", "unicodeerror", "valueerror", "raise", "workflowargumenterror", "cannot", "convert", "to", "int", "format", "value", "elif", "self", "type", "is", "float", "try", "return", "float", "value", "except", "unicodeerror", "valueerror", "raise", "workflowargumenterror", "cannot", "convert", "to", "float", "format", "value", "elif", "self", "type", "is", "bool", "if", "isinstance", "value", "bool", "return", "bool", "value", "value", "value", "lower", "if", "value", "in", "true", "1", "yes", "return", "true", "elif", "value", "in", "false", "0", "no", "return", "false", "raise", "workflowargumenterror", "cannot", "convert", "to", "bool", "format", "value", "else", "return", "value"], "docstring": "convert int to bool", "docstring_tokens": ["convert", "int", "to", "bool"], "idx": 358}
{"url": "https://github.com/thebjorn/pydeps/blob/1e6715b7bea47a40e8042821b57937deaaa0fdc3/pydeps/arguments.py#L20-L31", "repo": "pydeps", "func_name": "boolval", "original_string": ["def boolval(v):\n", "    if isinstance(v, bool):\n", "        return v\n", "    if isinstance(v, int):\n", "        return bool(v)\n", "    if is_string(v):\n", "        v = v.lower()\n", "        if v in {'j', 'y', 'ja', 'yes', '1', 'true'}:\n", "            return True\n", "        if v in {'n', 'nei', 'no', '0', 'false'}:\n", "            return False\n", "    raise ValueError(\"Don't know how to convert %r to bool\" % v)\n"], "language": "python", "code": "def boolval(v):\n    if isinstance(v, bool):\n        return v\n    if isinstance(v, int):\n        return bool(v)\n    if is_string(v):\n        v = v.lower()\n        if v in {'j', 'y', 'ja', 'yes', '1', 'true'}:\n            return True\n        if v in {'n', 'nei', 'no', '0', 'false'}:\n            return False\n    raise ValueError(\"Don't know how to convert %r to bool\" % v)\n", "code_tokens": ["boolval", "if", "isinstance", "bool", "return", "if", "isinstance", "int", "return", "bool", "if", "is", "string", "lower", "if", "in", "ja", "yes", "1", "true", "return", "true", "if", "in", "nei", "no", "0", "false", "return", "false", "raise", "valueerror", "don", "know", "how", "to", "convert", "to", "bool"], "docstring": "convert int to bool", "docstring_tokens": ["convert", "int", "to", "bool"], "idx": 359}
{"url": "https://github.com/yaybu/callsign/blob/e70e5368bfe4fd3ae3fdd1ed43944b53ffa1e100/callsign/config.py#L54-L60", "repo": "callsign", "func_name": "to_bool", "original_string": ["def to_bool(x):\n", "    if x.lower() in (\"true\", \"yes\", \"on\", \"1\"):\n", "        return True\n", "    elif x.lower() in (\"false\", \"no\", \"off\", \"0\"):\n", "        return False\n", "    else:\n", "        raise ValueError(\"%r in config file is not boolean\" % x)\n"], "language": "python", "code": "def to_bool(x):\n    if x.lower() in ('true', 'yes', 'on', '1'):\n        return True\n    elif x.lower() in ('false', 'no', 'off', '0'):\n        return False\n    else:\n        raise ValueError('%r in config file is not boolean' % x)\n", "code_tokens": ["to", "bool", "if", "lower", "in", "true", "yes", "on", "1", "return", "true", "elif", "lower", "in", "false", "no", "off", "0", "return", "false", "else", "raise", "valueerror", "in", "config", "file", "is", "not", "boolean"], "docstring": "convert int to bool", "docstring_tokens": ["convert", "int", "to", "bool"], "idx": 360}
{"url": "https://github.com/bjmorgan/vasppy/blob/cc2d1449697b17ee1c43715a02cddcb1139a6834/vasppy/scripts/rotate_poscar.py#L7-L13", "repo": "vasppy", "func_name": "parse_command_line_arguments", "original_string": ["def parse_command_line_arguments():\n", "    parser = argparse.ArgumentParser( description='Rotates the cell lattice in VASP POSCAR files' )\n", "    parser.add_argument( 'poscar', help=\"filename of the VASP POSCAR to be processed\" )\n", "    parser.add_argument( '-a', '--axis', nargs=3, type=float, help=\"vector for rotation axis\", required=True )\n", "    parser.add_argument( '-d', '--degrees', type=int, help=\"rotation angle in degrees\", required=True )\n", "    args = parser.parse_args()\n", "    return( args )\n"], "language": "python", "code": "def parse_command_line_arguments():\n    parser = argparse.ArgumentParser(description=\n        'Rotates the cell lattice in VASP POSCAR files')\n    parser.add_argument('poscar', help=\n        'filename of the VASP POSCAR to be processed')\n    parser.add_argument('-a', '--axis', nargs=3, type=float, help=\n        'vector for rotation axis', required=True)\n    parser.add_argument('-d', '--degrees', type=int, help=\n        'rotation angle in degrees', required=True)\n    args = parser.parse_args()\n    return args\n", "code_tokens": ["parse", "command", "line", "arguments", "parser", "argparse", "argumentparser", "description", "rotates", "the", "cell", "lattice", "in", "vasp", "poscar", "files", "parser", "add", "argument", "poscar", "help", "filename", "of", "the", "vasp", "poscar", "to", "be", "processed", "parser", "add", "argument", "axis", "nargs", "3", "type", "float", "help", "vector", "for", "rotation", "axis", "required", "true", "parser", "add", "argument", "degrees", "type", "int", "help", "rotation", "angle", "in", "degrees", "required", "true", "args", "parser", "parse", "args", "return", "args"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 361}
{"url": "https://github.com/mozilla/Marketplace.Python/blob/88176b12201f766b6b96bccc1e4c3e82f0676283/example/main.py#L29-L61", "repo": "Marketplace.Python", "func_name": "main", "original_string": ["def main():\n", "    parser = argparse.ArgumentParser(\n", "        description='Command line Marketplace client')\n", "    parser.add_argument('method', type=str,\n", "                        help='command to be run on arguments',\n", "                        choices=COMMANDS.keys())\n", "    parser.add_argument('attrs', metavar='attr', type=str, nargs='*',\n", "                        help='command arguments')\n", "    parser.add_argument('-v', action='store_true', default=False,\n", "                        dest='verbose',\n", "                        help='Switch to verbose mode')\n", "\n", "    args = parser.parse_args()\n", "\n", "    client = marketplace.Client(\n", "        domain=config.MARKETPLACE_DOMAIN,\n", "        protocol=config.MARKETPLACE_PROTOCOL,\n", "        port=config.MARKETPLACE_PORT,\n", "        consumer_key=config.CONSUMER_KEY,\n", "        consumer_secret=config.CONSUMER_SECRET)\n", "\n", "    if args.verbose:\n", "        logger.setLevel(logging.DEBUG)\n", "    if args.attrs:\n", "        result = COMMANDS[args.method](client, *args.attrs)\n", "    else:\n", "        result = COMMANDS[args.method](client)\n", "\n", "    if result['success']:\n", "        sys.stdout.write('%s\\n' % result['message'])\n", "    else:\n", "        sys.stderr.write('%s\\n' % result['message'])\n", "        sys.exit(1)\n"], "language": "python", "code": "def main():\n    parser = argparse.ArgumentParser(description=\n        'Command line Marketplace client')\n    parser.add_argument('method', type=str, help=\n        'command to be run on arguments', choices=COMMANDS.keys())\n    parser.add_argument('attrs', metavar='attr', type=str, nargs='*', help=\n        'command arguments')\n    parser.add_argument('-v', action='store_true', default=False, dest=\n        'verbose', help='Switch to verbose mode')\n    args = parser.parse_args()\n    client = marketplace.Client(domain=config.MARKETPLACE_DOMAIN, protocol=\n        config.MARKETPLACE_PROTOCOL, port=config.MARKETPLACE_PORT,\n        consumer_key=config.CONSUMER_KEY, consumer_secret=config.\n        CONSUMER_SECRET)\n    if args.verbose:\n        logger.setLevel(logging.DEBUG)\n    if args.attrs:\n        result = COMMANDS[args.method](client, *args.attrs)\n    else:\n        result = COMMANDS[args.method](client)\n    if result['success']:\n        sys.stdout.write('%s\\n' % result['message'])\n    else:\n        sys.stderr.write('%s\\n' % result['message'])\n        sys.exit(1)\n", "code_tokens": ["main", "parser", "argparse", "argumentparser", "description", "command", "line", "marketplace", "client", "parser", "add", "argument", "method", "type", "str", "help", "command", "to", "be", "run", "on", "arguments", "choices", "commands", "keys", "parser", "add", "argument", "attrs", "metavar", "attr", "type", "str", "nargs", "help", "command", "arguments", "parser", "add", "argument", "action", "store", "true", "default", "false", "dest", "verbose", "help", "switch", "to", "verbose", "mode", "args", "parser", "parse", "args", "client", "marketplace", "client", "domain", "config", "marketplace", "domain", "protocol", "config", "marketplace", "protocol", "port", "config", "marketplace", "port", "consumer", "key", "config", "consumer", "key", "consumer", "secret", "config", "consumer", "secret", "if", "args", "verbose", "logger", "setlevel", "logging", "debug", "if", "args", "attrs", "result", "commands", "args", "method", "client", "args", "attrs", "else", "result", "commands", "args", "method", "client", "if", "result", "success", "sys", "stdout", "write", "result", "message", "else", "sys", "stderr", "write", "result", "message", "sys", "exit", "1"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 362}
{"url": "https://github.com/bjmorgan/vasppy/blob/cc2d1449697b17ee1c43715a02cddcb1139a6834/vasppy/scripts/check_species.py#L14-L19", "repo": "vasppy", "func_name": "parse_command_line_arguments", "original_string": ["def parse_command_line_arguments():\n", "    parser = argparse.ArgumentParser( description='Check species consistency between a VASP POSCAR file and a POTCAR file.' )\n", "    parser.add_argument( 'poscar', help=\"filename of the VASP POSCAR to be processed\", nargs='?', default='POSCAR' )\n", "    parser.add_argument( 'potcar', help=\"filename of the VASP POTCAR to be processed\", nargs='?', default='POTCAR' )\n", "    parser.add_argument( '-p', '--ppset', help=\"check whether the POTCAR pseudopotentials belong to a specific pseudopotential set\", choices=potcar_sets )\n", "    return parser.parse_args()\n"], "language": "python", "code": "def parse_command_line_arguments():\n    parser = argparse.ArgumentParser(description=\n        'Check species consistency between a VASP POSCAR file and a POTCAR file.'\n        )\n    parser.add_argument('poscar', help=\n        'filename of the VASP POSCAR to be processed', nargs='?', default=\n        'POSCAR')\n    parser.add_argument('potcar', help=\n        'filename of the VASP POTCAR to be processed', nargs='?', default=\n        'POTCAR')\n    parser.add_argument('-p', '--ppset', help=\n        'check whether the POTCAR pseudopotentials belong to a specific pseudopotential set'\n        , choices=potcar_sets)\n    return parser.parse_args()\n", "code_tokens": ["parse", "command", "line", "arguments", "parser", "argparse", "argumentparser", "description", "check", "species", "consistency", "between", "vasp", "poscar", "file", "and", "potcar", "file", "parser", "add", "argument", "poscar", "help", "filename", "of", "the", "vasp", "poscar", "to", "be", "processed", "nargs", "default", "poscar", "parser", "add", "argument", "potcar", "help", "filename", "of", "the", "vasp", "potcar", "to", "be", "processed", "nargs", "default", "potcar", "parser", "add", "argument", "ppset", "help", "check", "whether", "the", "potcar", "pseudopotentials", "belong", "to", "specific", "pseudopotential", "set", "choices", "potcar", "sets", "return", "parser", "parse", "args"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 363}
{"url": "https://github.com/intuition-io/intuition/blob/cd517e6b3b315a743eb4d0d0dc294e264ab913ce/intuition/core/configuration.py#L28-L56", "repo": "intuition", "func_name": "parse_commandline", "original_string": ["def parse_commandline():\n", "    parser = argparse.ArgumentParser(\n", "        description='Intuition, the terrific trading system')\n", "    parser.add_argument('-V', '--version',\n", "                        action='version',\n", "                        version='%(prog)s v{} Licence {}'.format(\n", "                            __version__, __licence__),\n", "                        help='Print program version')\n", "    parser.add_argument('-v', '--showlog',\n", "                        action='store_true',\n", "                        help='Print logs on stdout')\n", "    parser.add_argument('-b', '--bot',\n", "                        action='store_true',\n", "                        help='Allows the algorithm to process orders')\n", "    parser.add_argument('-c', '--context',\n", "                        action='store', default='file::conf.yaml',\n", "                        help='Provides the way to build context')\n", "    parser.add_argument('-i', '--id',\n", "                        action='store', default='gekko',\n", "                        help='Customize the session id')\n", "    args = parser.parse_args()\n", "\n", "    # Dict will be more generic to process than args namespace\n", "    return {\n", "        'session': args.id,\n", "        'context': args.context,\n", "        'showlog': args.showlog,\n", "        'bot': args.bot\n", "    }\n"], "language": "python", "code": "def parse_commandline():\n    parser = argparse.ArgumentParser(description=\n        'Intuition, the terrific trading system')\n    parser.add_argument('-V', '--version', action='version', version=\n        '%(prog)s v{} Licence {}'.format(__version__, __licence__), help=\n        'Print program version')\n    parser.add_argument('-v', '--showlog', action='store_true', help=\n        'Print logs on stdout')\n    parser.add_argument('-b', '--bot', action='store_true', help=\n        'Allows the algorithm to process orders')\n    parser.add_argument('-c', '--context', action='store', default=\n        'file::conf.yaml', help='Provides the way to build context')\n    parser.add_argument('-i', '--id', action='store', default='gekko', help\n        ='Customize the session id')\n    args = parser.parse_args()\n    return {'session': args.id, 'context': args.context, 'showlog': args.\n        showlog, 'bot': args.bot}\n", "code_tokens": ["parse", "commandline", "parser", "argparse", "argumentparser", "description", "intuition", "the", "terrific", "trading", "system", "parser", "add", "argument", "version", "action", "version", "version", "prog", "licence", "format", "version", "licence", "help", "print", "program", "version", "parser", "add", "argument", "showlog", "action", "store", "true", "help", "print", "logs", "on", "stdout", "parser", "add", "argument", "bot", "action", "store", "true", "help", "allows", "the", "algorithm", "to", "process", "orders", "parser", "add", "argument", "context", "action", "store", "default", "file", "conf", "yaml", "help", "provides", "the", "way", "to", "build", "context", "parser", "add", "argument", "id", "action", "store", "default", "gekko", "help", "customize", "the", "session", "id", "args", "parser", "parse", "args", "return", "session", "args", "id", "context", "args", "context", "showlog", "args", "showlog", "bot", "args", "bot"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 364}
{"url": "https://github.com/bjmorgan/vasppy/blob/cc2d1449697b17ee1c43715a02cddcb1139a6834/vasppy/scripts/proc_poscar.py#L7-L21", "repo": "vasppy", "func_name": "parse_command_line_arguments", "original_string": ["def parse_command_line_arguments():\n", "    # command line arguments\n", "    parser = argparse.ArgumentParser( description='Manipulates VASP POSCAR files' )\n", "    parser.add_argument( 'poscar', help=\"filename of the VASP POSCAR to be processed\" )\n", "    parser.add_argument( '-l', '--label', type=int, choices=[ 1, 4 ], help=\"label coordinates with atom name at position {1,4}\" )\n", "    parser.add_argument( '-c', '--coordinates-only', help='only output coordinates', action='store_true' )\n", "    parser.add_argument( '-t', '--coordinate-type', type=str, choices=[ 'c', 'cartesian', 'd', 'direct' ], default='direct', help=\"specify coordinate type for output {(c)artesian|(d)irect} [default = (d)irect]\" )\n", "    parser.add_argument( '-g', '--group', help='group atoms within supercell', action='store_true' )\n", "    parser.add_argument( '-s', '--supercell', type=int, nargs=3, metavar=( 'h', 'k', 'l' ), help='construct supercell by replicating (h,k,l) times along [a b c]' )\n", "    parser.add_argument( '-b', '--bohr', action='store_true', help='assumes the input file is in Angstrom, and converts everything to bohr')\n", "    parser.add_argument( '-n', '--number-atoms', action='store_true', help='label coordinates with atom number' )\n", "    parser.add_argument( '--scale', action='store_true', help='scale the lattice parameters by the scaling factor' )\n", "    parser.add_argument( '--selective', choices=[ 'T', 'F' ], help='generate Selective Dynamics POSCAR with all values set to T / F' )\n", "    args = parser.parse_args()\n", "    return( args )\n"], "language": "python", "code": "def parse_command_line_arguments():\n    parser = argparse.ArgumentParser(description=\n        'Manipulates VASP POSCAR files')\n    parser.add_argument('poscar', help=\n        'filename of the VASP POSCAR to be processed')\n    parser.add_argument('-l', '--label', type=int, choices=[1, 4], help=\n        'label coordinates with atom name at position {1,4}')\n    parser.add_argument('-c', '--coordinates-only', help=\n        'only output coordinates', action='store_true')\n    parser.add_argument('-t', '--coordinate-type', type=str, choices=['c',\n        'cartesian', 'd', 'direct'], default='direct', help=\n        'specify coordinate type for output {(c)artesian|(d)irect} [default = (d)irect]'\n        )\n    parser.add_argument('-g', '--group', help=\n        'group atoms within supercell', action='store_true')\n    parser.add_argument('-s', '--supercell', type=int, nargs=3, metavar=(\n        'h', 'k', 'l'), help=\n        'construct supercell by replicating (h,k,l) times along [a b c]')\n    parser.add_argument('-b', '--bohr', action='store_true', help=\n        'assumes the input file is in Angstrom, and converts everything to bohr'\n        )\n    parser.add_argument('-n', '--number-atoms', action='store_true', help=\n        'label coordinates with atom number')\n    parser.add_argument('--scale', action='store_true', help=\n        'scale the lattice parameters by the scaling factor')\n    parser.add_argument('--selective', choices=['T', 'F'], help=\n        'generate Selective Dynamics POSCAR with all values set to T / F')\n    args = parser.parse_args()\n    return args\n", "code_tokens": ["parse", "command", "line", "arguments", "parser", "argparse", "argumentparser", "description", "manipulates", "vasp", "poscar", "files", "parser", "add", "argument", "poscar", "help", "filename", "of", "the", "vasp", "poscar", "to", "be", "processed", "parser", "add", "argument", "label", "type", "int", "choices", "1", "4", "help", "label", "coordinates", "with", "atom", "name", "at", "position", "1", "4", "parser", "add", "argument", "coordinates", "only", "help", "only", "output", "coordinates", "action", "store", "true", "parser", "add", "argument", "coordinate", "type", "type", "str", "choices", "cartesian", "direct", "default", "direct", "help", "specify", "coordinate", "type", "for", "output", "artesian", "irect", "default", "irect", "parser", "add", "argument", "group", "help", "group", "atoms", "within", "supercell", "action", "store", "true", "parser", "add", "argument", "supercell", "type", "int", "nargs", "3", "metavar", "help", "construct", "supercell", "by", "replicating", "times", "along", "parser", "add", "argument", "bohr", "action", "store", "true", "help", "assumes", "the", "input", "file", "is", "in", "angstrom", "and", "converts", "everything", "to", "bohr", "parser", "add", "argument", "number", "atoms", "action", "store", "true", "help", "label", "coordinates", "with", "atom", "number", "parser", "add", "argument", "scale", "action", "store", "true", "help", "scale", "the", "lattice", "parameters", "by", "the", "scaling", "factor", "parser", "add", "argument", "selective", "choices", "help", "generate", "selective", "dynamics", "poscar", "with", "all", "values", "set", "to", "args", "parser", "parse", "args", "return", "args"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 365}
{"url": "https://github.com/bjmorgan/vasppy/blob/cc2d1449697b17ee1c43715a02cddcb1139a6834/vasppy/scripts/xdatcar_to_disp.py#L7-L12", "repo": "vasppy", "func_name": "parse_command_line_arguments", "original_string": ["def parse_command_line_arguments():\n", "    # command line arguments\n", "    parser = argparse.ArgumentParser()\n", "    parser.add_argument( 'xdatcar' )\n", "    args = parser.parse_args()\n", "    return( args )\n"], "language": "python", "code": "def parse_command_line_arguments():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('xdatcar')\n    args = parser.parse_args()\n    return args\n", "code_tokens": ["parse", "command", "line", "arguments", "parser", "argparse", "argumentparser", "parser", "add", "argument", "xdatcar", "args", "parser", "parse", "args", "return", "args"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 366}
{"url": "https://github.com/bjmorgan/vasppy/blob/cc2d1449697b17ee1c43715a02cddcb1139a6834/vasppy/scripts/xdatcar_to_rdf.py#L9-L17", "repo": "vasppy", "func_name": "parse_command_line_arguments", "original_string": ["\n", "def parse_command_line_arguments():\n", "    # command line arguments\n", "    parser = argparse.ArgumentParser()\n", "    parser.add_argument( 'xdatcar' )\n", "    parser.add_argument( 'label', nargs=2 )\n", "    parser.add_argument( 'max_r', type=float )\n", "    parser.add_argument( 'n_bins', type=int )\n", "    args = parser.parse_args()\n"], "language": "python", "code": "def parse_command_line_arguments():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('xdatcar')\n    parser.add_argument('label', nargs=2)\n    parser.add_argument('max_r', type=float)\n    parser.add_argument('n_bins', type=int)\n    args = parser.parse_args()\n", "code_tokens": ["parse", "command", "line", "arguments", "parser", "argparse", "argumentparser", "parser", "add", "argument", "xdatcar", "parser", "add", "argument", "label", "nargs", "2", "parser", "add", "argument", "max", "type", "float", "parser", "add", "argument", "bins", "type", "int", "args", "parser", "parse", "args"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 367}
{"url": "https://github.com/chitamoor/Rester/blob/1865b17f70b7c597aeadde2d0907cb1b59f10c0f/rester/apirunner.py#L9-L18", "repo": "Rester", "func_name": "parse_cmdln_args", "original_string": ["def parse_cmdln_args():\n", "    parser = argparse.ArgumentParser(description='Process command line args')\n", "    parser.add_argument('--log', help='log help', default='INFO')\n", "    parser.add_argument(\n", "        '--tc', help='tc help')\n", "    parser.add_argument(\n", "        '--ts', help='ts help')\n", "\n", "    args = parser.parse_args()\n", "    return (args.log.upper(), args.tc, args.ts)\n"], "language": "python", "code": "def parse_cmdln_args():\n    parser = argparse.ArgumentParser(description='Process command line args')\n    parser.add_argument('--log', help='log help', default='INFO')\n    parser.add_argument('--tc', help='tc help')\n    parser.add_argument('--ts', help='ts help')\n    args = parser.parse_args()\n    return args.log.upper(), args.tc, args.ts\n", "code_tokens": ["parse", "cmdln", "args", "parser", "argparse", "argumentparser", "description", "process", "command", "line", "args", "parser", "add", "argument", "log", "help", "log", "help", "default", "info", "parser", "add", "argument", "tc", "help", "tc", "help", "parser", "add", "argument", "ts", "help", "ts", "help", "args", "parser", "parse", "args", "return", "args", "log", "upper", "args", "tc", "args", "ts"], "docstring": "parse command line argument", "docstring_tokens": ["parse", "command", "line", "argument"], "idx": 368}
{"url": "https://github.com/DeepHorizons/iarm/blob/b913c9fd577b793a6bbced78b78a5d8d7cd88de4/iarm/arm_instructions/_meta.py#L126-L132", "repo": "iarm", "func_name": "convert_to_integer", "original_string": ["    def convert_to_integer(self, str):\n", "        if str.startswith('0x') or str.startswith('0X'):\n", "            return int(str, 16)\n", "        elif str.startswith('2_'):\n", "            return int(str[2:], 2)\n", "        else:\n", "            return int(str)\n"], "language": "python", "code": "def convert_to_integer(self, str):\n    if str.startswith('0x') or str.startswith('0X'):\n        return int(str, 16)\n    elif str.startswith('2_'):\n        return int(str[2:], 2)\n    else:\n        return int(str)\n", "code_tokens": ["convert", "to", "integer", "self", "str", "if", "str", "startswith", "or", "str", "startswith", "return", "int", "str", "16", "elif", "str", "startswith", "2", "return", "int", "str", "2", "2", "else", "return", "int", "str"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 369}
{"url": "https://github.com/osrg/ryu/blob/6f906e72c92e10bd0264c9b91a2f7bb85b97780c/ryu/lib/ofctl_utils.py#L198-L203", "repo": "ryu", "func_name": "to_match_masked_int", "original_string": ["def to_match_masked_int(value):\n", "    if isinstance(value, str) and '/' in value:\n", "        value = value.split('/')\n", "        return str_to_int(value[0]), str_to_int(value[1])\n", "\n", "    return str_to_int(value)\n"], "language": "python", "code": "def to_match_masked_int(value):\n    if isinstance(value, str) and '/' in value:\n        value = value.split('/')\n        return str_to_int(value[0]), str_to_int(value[1])\n    return str_to_int(value)\n", "code_tokens": ["to", "match", "masked", "int", "value", "if", "isinstance", "value", "str", "and", "in", "value", "value", "value", "split", "return", "str", "to", "int", "value", "0", "str", "to", "int", "value", "1", "return", "str", "to", "int", "value"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 370}
{"url": "https://github.com/kpdyer/regex2dfa/blob/109f877e60ef0dfcb430f11516d215930b7b9936/third_party/re2/re2/unicode.py#L26-L45", "repo": "regex2dfa", "func_name": "_UInt", "original_string": ["def _UInt(s):\n", "  \"\"\"Converts string to Unicode code point ('263A' => 0x263a).\n", "\n", "  Args:\n", "    s: string to convert\n", "\n", "  Returns:\n", "    Unicode code point\n", "\n", "  Raises:\n", "    InputError: the string is not a valid Unicode value.\n", "  \"\"\"\n", "\n", "  try:\n", "    v = int(s, 16)\n", "  except ValueError:\n", "    v = -1\n", "  if len(s) < 4 or len(s) > 6 or v < 0 or v > _RUNE_MAX:\n", "    raise InputError(\"invalid Unicode value %s\" % (s,))\n", "  return v\n"], "language": "python", "code": "def _UInt(s):\n    \"\"\"\"\"\"\n    try:\n        v = int(s, 16)\n    except ValueError:\n        v = -1\n    if len(s) < 4 or len(s) > 6 or v < 0 or v > _RUNE_MAX:\n        raise InputError('invalid Unicode value %s' % (s,))\n    return v\n", "code_tokens": ["uint", "try", "int", "16", "except", "valueerror", "1", "if", "len", "4", "or", "len", "6", "or", "0", "or", "rune", "max", "raise", "inputerror", "invalid", "unicode", "value", "return"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 371}
{"url": "https://github.com/bcbio/bcbio-nextgen/blob/6a9348c0054ccd5baffd22f1bb7d0422f6978b20/bcbio/pipeline/disambiguate/run.py#L35-L39", "repo": "bcbio-nextgen", "func_name": "nat_cmp", "original_string": ["def nat_cmp(a, b):\n", "    convert = lambda text: int(text) if text.isdigit() else text # lambda function to convert text to int if number present\n", "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] # split string to piecewise strings and string numbers\n", "    #return cmp(alphanum_key(a), alphanum_key(b)) # use internal cmp to compare piecewise strings and numbers\n", "    return (alphanum_key(a) > alphanum_key(b))-(alphanum_key(a) < alphanum_key(b))\n"], "language": "python", "code": "def nat_cmp(a, b):\n    convert = lambda text: int(text) if text.isdigit() else text\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return (alphanum_key(a) > alphanum_key(b)) - (alphanum_key(a) <\n        alphanum_key(b))\n", "code_tokens": ["nat", "cmp", "convert", "lambda", "text", "int", "text", "if", "text", "isdigit", "else", "text", "alphanum", "key", "lambda", "key", "convert", "for", "in", "re", "split", "0", "9", "key", "return", "alphanum", "key", "alphanum", "key", "alphanum", "key", "alphanum", "key"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 372}
{"url": "https://github.com/etingof/pysmi/blob/379a0a384c81875731be51a054bdacced6260fd8/pysmi/codegen/base.py#L290-L303", "repo": "pysmi", "func_name": "str2int", "original_string": ["    def str2int(self, s):\n", "        if self.isBinary(s):\n", "            if s[1:-2]:\n", "                return int(s[1:-2], 2)\n", "            else:\n", "                raise error.PySmiSemanticError('empty binary string to int conversion')\n", "\n", "        elif self.isHex(s):\n", "            if s[1:-2]:\n", "                return int(s[1:-2], 16)\n", "            else:\n", "                raise error.PySmiSemanticError('empty hex string to int conversion')\n", "        else:\n", "            return int(s)\n"], "language": "python", "code": "def str2int(self, s):\n    if self.isBinary(s):\n        if s[1:-2]:\n            return int(s[1:-2], 2)\n        else:\n            raise error.PySmiSemanticError(\n                'empty binary string to int conversion')\n    elif self.isHex(s):\n        if s[1:-2]:\n            return int(s[1:-2], 16)\n        else:\n            raise error.PySmiSemanticError('empty hex string to int conversion'\n                )\n    else:\n        return int(s)\n", "code_tokens": ["self", "if", "self", "isbinary", "if", "1", "2", "return", "int", "1", "2", "2", "else", "raise", "error", "pysmisemanticerror", "empty", "binary", "string", "to", "int", "conversion", "elif", "self", "ishex", "if", "1", "2", "return", "int", "1", "2", "16", "else", "raise", "error", "pysmisemanticerror", "empty", "hex", "string", "to", "int", "conversion", "else", "return", "int"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 373}
{"url": "https://github.com/osrg/ryu/blob/6f906e72c92e10bd0264c9b91a2f7bb85b97780c/ryu/lib/ofctl_utils.py#L206-L210", "repo": "ryu", "func_name": "to_match_packet_type", "original_string": ["def to_match_packet_type(value):\n", "    if isinstance(value, (list, tuple)):\n", "        return str_to_int(value[0]) << 16 | str_to_int(value[1])\n", "    else:\n", "        return str_to_int(value)\n"], "language": "python", "code": "def to_match_packet_type(value):\n    if isinstance(value, (list, tuple)):\n        return str_to_int(value[0]) << 16 | str_to_int(value[1])\n    else:\n        return str_to_int(value)\n", "code_tokens": ["to", "match", "packet", "type", "value", "if", "isinstance", "value", "list", "tuple", "return", "str", "to", "int", "value", "0", "16", "str", "to", "int", "value", "1", "else", "return", "str", "to", "int", "value"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 374}
{"url": "https://github.com/MozillaSecurity/laniakea/blob/7e80adc6ae92c6c1332d4c08473bb271fb3b6833/laniakea/core/userdata.py#L43-L51", "repo": "laniakea", "func_name": "convert_str_to_int", "original_string": ["    def convert_str_to_int(arg):\n", "        \"\"\"\n", "        \"\"\"\n", "        for k, v in list(arg.items()):  # pylint: disable=invalid-name\n", "            try:\n", "                arg[String(k)] = int(v)\n", "            except ValueError:\n", "                pass\n", "        return arg\n"], "language": "python", "code": "def convert_str_to_int(arg):\n    \"\"\"\"\"\"\n    for k, v in list(arg.items()):try:    arg[String(k)] = int(v)except ValueError:    pass\n    return arg\n", "code_tokens": ["convert", "str", "to", "int", "arg", "for", "in", "list", "arg", "items", "try", "arg", "string", "int", "except", "valueerror", "pass", "return", "arg"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 375}
{"url": "https://github.com/commonwealth-of-puerto-rico/libre/blob/5b32f4ab068b515d2ea652b182e161271ba874e8/libre/apps/data_drivers/models.py#L341-L369", "repo": "libre", "func_name": "_convert_value", "original_string": ["    def _convert_value(self, item):\n", "        \"\"\"\n", "        Handle different value types for XLS. Item is a cell object.\n", "        \"\"\"\n", "        # Types:\n", "        # 0 = empty u''\n", "        # 1 = unicode text\n", "        # 2 = float (convert to int if possible, then convert to string)\n", "        # 3 = date (convert to unambiguous date/time string)\n", "        # 4 = boolean (convert to string \"0\" or \"1\")\n", "        # 5 = error (convert from code to error text)\n", "        # 6 = blank u''\n", "\n", "        # Thx to Augusto C Men to point fast solution for XLS/XLSX dates\n", "        if item.ctype == 3:  # XL_CELL_DATE:\n", "            try:\n", "                return datetime.datetime(*xlrd.xldate_as_tuple(item.value, self._book.datemode))\n", "            except ValueError:\n", "                # TODO: make toggable\n", "                # Invalid date\n", "                return item.value\n", "\n", "        if item.ctype == 2:  # XL_CELL_NUMBER:\n", "            if item.value % 1 == 0:  # integers\n", "                return int(item.value)\n", "            else:\n", "                return item.value\n", "\n", "        return item.value\n"], "language": "python", "code": "def _convert_value(self, item):\n    \"\"\"\"\"\"\n    if item.ctype == 3:\n        try:\n            return datetime.datetime(*xlrd.xldate_as_tuple(item.value, self\n                ._book.datemode))\n        except ValueError:\n            return item.value\n    if item.ctype == 2:\n        if item.value % 1 == 0:\n            return int(item.value)\n        else:\n            return item.value\n    return item.value\n", "code_tokens": ["convert", "value", "self", "item", "if", "item", "ctype", "3", "try", "return", "datetime", "datetime", "xlrd", "xldate", "as", "tuple", "item", "value", "self", "book", "datemode", "except", "valueerror", "return", "item", "value", "if", "item", "ctype", "2", "if", "item", "value", "1", "0", "return", "int", "item", "value", "else", "return", "item", "value", "return", "item", "value"], "docstring": "convert int to string", "docstring_tokens": ["convert", "int", "to", "string"], "idx": 376}
{"url": "https://github.com/klahnakoski/pyLibrary/blob/fa2dcbc48fda8d26999baef400e9a98149e0b982/mo_graphs/graph.py#L58-L65", "repo": "pyLibrary", "func_name": "get_edges", "original_string": ["    def get_edges(self, node):\n", "        return [\n", "            (node, child)\n", "            for child in self.get_children(node)\n", "        ] + [\n", "            (parent, node)\n", "            for parent in self.get_parents(node)\n", "        ]\n"], "language": "python", "code": "def get_edges(self, node):\n    return [(node, child) for child in self.get_children(node)] + [(parent,\n        node) for parent in self.get_parents(node)]\n", "code_tokens": ["get", "edges", "self", "node", "return", "node", "child", "for", "child", "in", "self", "get", "children", "node", "parent", "node", "for", "parent", "in", "self", "get", "parents", "node"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 377}
{"url": "https://github.com/mfitzp/biocyc/blob/2fe81971687e4dcf1fcf869af0e7b3549be535b1/biocyc/biocyc.py#L566-L571", "repo": "biocyc", "func_name": "_import_parents_from_xml", "original_string": ["    def _import_parents_from_xml(self, xml):\n", "        parents = xml.iterfind('parent')\n", "        for p in parents:\n", "            for o in p:\n", "                # Store a tuple of orgid, identifier\n", "                self._parents.append( o.attrib['frameid'] ) #( o.attrib['orgid'],  ) )\n"], "language": "python", "code": "def _import_parents_from_xml(self, xml):\n    parents = xml.iterfind('parent')\n    for p in parents:\n        for o in p:\n            self._parents.append(o.attrib['frameid'])\n", "code_tokens": ["import", "parents", "from", "xml", "self", "xml", "parents", "xml", "iterfind", "parent", "for", "in", "parents", "for", "in", "self", "parents", "append", "attrib", "frameid"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 378}
{"url": "https://github.com/klahnakoski/pyLibrary/blob/fa2dcbc48fda8d26999baef400e9a98149e0b982/mo_graphs/tree_graph.py#L39-L44", "repo": "pyLibrary", "func_name": "get_parents", "original_string": ["    def get_parents(self, node):\n", "        parent = self.parents.get(node)\n", "        if parent == None:\n", "            return set()\n", "        else:\n", "            return {parent}\n"], "language": "python", "code": "def get_parents(self, node):\n    parent = self.parents.get(node)\n    if parent == None:\n        return set()\n    else:\n        return {parent}\n", "code_tokens": ["get", "parents", "self", "node", "parent", "self", "parents", "get", "node", "if", "parent", "none", "return", "set", "else", "return", "parent"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 379}
{"url": "https://github.com/incf-nidash/nidmresults/blob/438f7cce6abc4a4379b629bd76f4d427891e033f/nidmresults/owl/owl_reader.py#L85-L93", "repo": "nidmresults", "func_name": "get_nidm_parent", "original_string": ["    def get_nidm_parent(self, term):\n", "        # Find direct nidm parent of 'term'\n", "        parents = self.get_direct_parents(term)\n", "\n", "        for parent in parents:\n", "            if not self.is_external_namespace(parent):\n", "                return parent\n", "\n", "        return None\n"], "language": "python", "code": "def get_nidm_parent(self, term):\n    parents = self.get_direct_parents(term)\n    for parent in parents:\n        if not self.is_external_namespace(parent):\n            return parent\n    return None\n", "code_tokens": ["get", "nidm", "parent", "self", "term", "parents", "self", "get", "direct", "parents", "term", "for", "parent", "in", "parents", "if", "not", "self", "is", "external", "namespace", "parent", "return", "parent", "return", "none"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 380}
{"url": "https://github.com/inveniosoftware-contrib/json-merger/blob/adc6d372da018427e1db7b92424d3471e01a4118/json_merger/contrib/inspirehep/match.py#L199-L207", "repo": "json-merger", "func_name": "_find", "original_string": ["    def _find(self, node):\n", "        root = node\n", "        while root in self.parents:\n", "            root = self.parents[root]\n", "        while node in self.parents:\n", "            prev_node = node\n", "            node = self.parents[node]\n", "            self.parents[prev_node] = root\n", "        return root\n"], "language": "python", "code": "def _find(self, node):\n    root = node\n    while root in self.parents:\n        root = self.parents[root]\n    while node in self.parents:\n        prev_node = node\n        node = self.parents[node]\n        self.parents[prev_node] = root\n    return root\n", "code_tokens": ["find", "self", "node", "root", "node", "while", "root", "in", "self", "parents", "root", "self", "parents", "root", "while", "node", "in", "self", "parents", "prev", "node", "node", "node", "self", "parents", "node", "self", "parents", "prev", "node", "root", "return", "root"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 381}
{"url": "https://github.com/klahnakoski/pyLibrary/blob/fa2dcbc48fda8d26999baef400e9a98149e0b982/mo_graphs/algorithms.py#L115-L202", "repo": "pyLibrary", "func_name": "dominator_tree", "original_string": ["def dominator_tree(graph):\n", "    \"\"\"\n", "    RETURN DOMINATOR FOREST\n", "    THERE ARE TWO TREES, \"ROOTS\" and \"LOOPS\"\n", "    ROOTS HAVE NO PARENTS\n", "    LOOPS ARE NODES THAT ARE A MEMBER OF A CYCLE THAT HAS NO EXTRNAL PARENT\n", "\n", "    roots = dominator_tree(graph).get_children(ROOTS)\n", "    \"\"\"\n", "    todo = Queue()\n", "    done = set()\n", "    dominator = Tree(None)\n", "    nodes = list(graph.nodes)\n", "\n", "    while True:\n", "        # FIGURE OUT NET ITEM TO WORK ON\n", "        if todo:\n", "            node = todo.pop()\n", "        elif nodes:\n", "            node = nodes.pop()\n", "            if len(nodes) % 1000 == 0:\n", "                Log.note(\"{{num}} nodes remaining\", num=len(nodes))\n", "        else:\n", "            break\n", "        if node in done:\n", "            continue\n", "\n", "        parents = graph.get_parents(node) - {node}\n", "        if not parents:\n", "            # node WITHOUT parents IS A ROOT\n", "            done.add(node)\n", "            dominator.add_edge(Edge(ROOTS, node))\n", "            continue\n", "\n", "        not_done = parents - done\n", "        if not_done:\n", "            # THERE ARE MORE parents TO DO FIRST\n", "            more_todo = not_done - todo\n", "            if not more_todo:\n", "                # ALL PARENTS ARE PART OF A CYCLE, MAKE node A ROOT\n", "                done.add(node)\n", "                dominator.add_edge(Edge(LOOPS, node))\n", "            else:\n", "                # DO THE PARENTS BEFORE node\n", "                todo.push(node)\n", "                for p in more_todo:\n", "                    todo.push(p)\n", "            continue\n", "\n", "        # WE CAN GET THE DOMINATORS FOR ALL parents\n", "        if len(parents) == 1:\n", "            # SHORTCUT\n", "            dominator.add_edge(Edge(list(parents)[0], node))\n", "            done.add(node)\n", "            continue\n", "\n", "        paths_from_roots = [\n", "            list(reversed(dominator.get_path_to_root(p)))\n", "            for p in parents\n", "        ]\n", "\n", "        if any(p[0] is ROOTS for p in paths_from_roots):\n", "            # THIS OBJECT CAN BE REACHED FROM A ROOT, IGNORE PATHS FROM LOOPS\n", "            paths_from_roots = [p for p in paths_from_roots if p[0] is ROOTS]\n", "            if len(paths_from_roots) == 1:\n", "                # SHORTCUT\n", "                dom = paths_from_roots[0][-1]\n", "                dominator.add_edge(Edge(dom, node))\n", "                done.add(node)\n", "                continue\n", "\n", "        # FIND COMMON PATH FROM root\n", "        num_paths = len(paths_from_roots)\n", "        for i, x in enumerate(zip_longest(*paths_from_roots)):\n", "            if x.count(x[0]) != num_paths:\n", "                dom = paths_from_roots[0][i-1]\n", "                if dom is LOOPS:\n", "                    # CAN BE REACHED FROM MORE THAN ONE LOOP, PICK ONE TO BLAME\n", "                    dom = paths_from_roots[0][-1]\n", "                break\n", "        else:\n", "            # ALL PATHS IDENTICAL\n", "            dom = paths_from_roots[0][-1]\n", "\n", "        dominator.add_edge(Edge(dom, node))\n", "        done.add(node)\n", "\n", "    return dominator\n"], "language": "python", "code": "def dominator_tree(graph):\n    \"\"\"\"\"\"\n    todo = Queue()\n    done = set()\n    dominator = Tree(None)\n    nodes = list(graph.nodes)\n    while True:\n        if todo:\n            node = todo.pop()\n        elif nodes:\n            node = nodes.pop()\n            if len(nodes) % 1000 == 0:\n                Log.note('{{num}} nodes remaining', num=len(nodes))\n        else:\n            break\n        if node in done:\n            continue\n        parents = graph.get_parents(node) - {node}\n        if not parents:\n            done.add(node)\n            dominator.add_edge(Edge(ROOTS, node))\n            continue\n        not_done = parents - done\n        if not_done:\n            more_todo = not_done - todo\n            if not more_todo:\n                done.add(node)\n                dominator.add_edge(Edge(LOOPS, node))\n            else:\n                todo.push(node)\n                for p in more_todo:\n                    todo.push(p)\n            continue\n        if len(parents) == 1:\n            dominator.add_edge(Edge(list(parents)[0], node))\n            done.add(node)\n            continue\n        paths_from_roots = [list(reversed(dominator.get_path_to_root(p))) for\n            p in parents]\n        if any(p[0] is ROOTS for p in paths_from_roots):\n            paths_from_roots = [p for p in paths_from_roots if p[0] is ROOTS]\n            if len(paths_from_roots) == 1:\n                dom = paths_from_roots[0][-1]\n                dominator.add_edge(Edge(dom, node))\n                done.add(node)\n                continue\n        num_paths = len(paths_from_roots)\n        for i, x in enumerate(zip_longest(*paths_from_roots)):\n            if x.count(x[0]) != num_paths:\n                dom = paths_from_roots[0][i - 1]\n                if dom is LOOPS:\n                    dom = paths_from_roots[0][-1]\n                break\n        else:\n            dom = paths_from_roots[0][-1]\n        dominator.add_edge(Edge(dom, node))\n        done.add(node)\n    return dominator\n", "code_tokens": ["dominator", "tree", "graph", "todo", "queue", "done", "set", "dominator", "tree", "none", "nodes", "list", "graph", "nodes", "while", "true", "if", "todo", "node", "todo", "pop", "elif", "nodes", "node", "nodes", "pop", "if", "len", "nodes", "1000", "0", "log", "note", "num", "nodes", "remaining", "num", "len", "nodes", "else", "break", "if", "node", "in", "done", "continue", "parents", "graph", "get", "parents", "node", "node", "if", "not", "parents", "done", "add", "node", "dominator", "add", "edge", "edge", "roots", "node", "continue", "not", "done", "parents", "done", "if", "not", "done", "more", "todo", "not", "done", "todo", "if", "not", "more", "todo", "done", "add", "node", "dominator", "add", "edge", "edge", "loops", "node", "else", "todo", "push", "node", "for", "in", "more", "todo", "todo", "push", "continue", "if", "len", "parents", "1", "dominator", "add", "edge", "edge", "list", "parents", "0", "node", "done", "add", "node", "continue", "paths", "from", "roots", "list", "reversed", "dominator", "get", "path", "to", "root", "for", "in", "parents", "if", "any", "0", "is", "roots", "for", "in", "paths", "from", "roots", "paths", "from", "roots", "for", "in", "paths", "from", "roots", "if", "0", "is", "roots", "if", "len", "paths", "from", "roots", "1", "dom", "paths", "from", "roots", "0", "1", "dominator", "add", "edge", "edge", "dom", "node", "done", "add", "node", "continue", "num", "paths", "len", "paths", "from", "roots", "for", "in", "enumerate", "zip", "longest", "paths", "from", "roots", "if", "count", "0", "num", "paths", "dom", "paths", "from", "roots", "0", "1", "if", "dom", "is", "loops", "dom", "paths", "from", "roots", "0", "1", "break", "else", "dom", "paths", "from", "roots", "0", "1", "dominator", "add", "edge", "edge", "dom", "node", "done", "add", "node", "return", "dominator"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 382}
{"url": "https://github.com/emc-openstack/storops/blob/24b4b13bf065c0ef0538dd0b5ebb8f25d24176bd/storops/vnx/resource/nfs_share.py#L38-L50", "repo": "storops", "func_name": "get_xml_node", "original_string": ["    def get_xml_node(self):\n", "        xb = xmlapi.XmlBuilder()\n", "\n", "        ret = []\n", "        if self.access_hosts is not None:\n", "            ret.append(xb.list_elements('AccessHosts', self.access_hosts))\n", "        if self.rw_hosts is not None:\n", "            ret.append(xb.list_elements('RwHosts', self.rw_hosts))\n", "        if self.ro_hosts is not None:\n", "            ret.append(xb.list_elements('RoHosts', self.ro_hosts))\n", "        if self.root_hosts is not None:\n", "            ret.append(xb.list_elements('RootHosts', self.root_hosts))\n", "        return ret\n"], "language": "python", "code": "def get_xml_node(self):\n    xb = xmlapi.XmlBuilder()\n    ret = []\n    if self.access_hosts is not None:\n        ret.append(xb.list_elements('AccessHosts', self.access_hosts))\n    if self.rw_hosts is not None:\n        ret.append(xb.list_elements('RwHosts', self.rw_hosts))\n    if self.ro_hosts is not None:\n        ret.append(xb.list_elements('RoHosts', self.ro_hosts))\n    if self.root_hosts is not None:\n        ret.append(xb.list_elements('RootHosts', self.root_hosts))\n    return ret\n", "code_tokens": ["get", "xml", "node", "self", "xb", "xmlapi", "xmlbuilder", "ret", "if", "self", "access", "hosts", "is", "not", "none", "ret", "append", "xb", "list", "elements", "accesshosts", "self", "access", "hosts", "if", "self", "rw", "hosts", "is", "not", "none", "ret", "append", "xb", "list", "elements", "rwhosts", "self", "rw", "hosts", "if", "self", "ro", "hosts", "is", "not", "none", "ret", "append", "xb", "list", "elements", "rohosts", "self", "ro", "hosts", "if", "self", "root", "hosts", "is", "not", "none", "ret", "append", "xb", "list", "elements", "roothosts", "self", "root", "hosts", "return", "ret"], "docstring": "get all parents of xml node", "docstring_tokens": ["get", "all", "parents", "of", "xml", "node"], "idx": 383}
{"url": "https://github.com/flowersteam/explauto/blob/cf0f81ecb9f6412f7276a95bd27359000e1e26b6/explauto/experiment/log.py#L67-L93", "repo": "explauto", "func_name": "scatter_plot", "original_string": ["    def scatter_plot(self, ax, topic_dims, t=None, ms_limits=True, **kwargs_plot):\n", "        \"\"\" 2D or 3D scatter plot.\n", "\n", "            :param axes ax: matplotlib axes (use Axes3D if 3D data)\n", "\n", "            :param tuple topic_dims: list of (topic, dims) tuples, where topic is a string and dims is a list of dimensions to be plotted for that topic.\n", "\n", "            :param int t: time indexes to be plotted\n", "\n", "            :param dict kwargs_plot: argument to be passed to matplotlib's plot function, e.g. the style of the plotted points 'or'\n", "\n", "            :param bool ms_limits: if set to True, automatically set axes boundaries to the sensorimotor boundaries (default: True)\n", "        \"\"\"\n", "        plot_specs = {'marker': 'o', 'linestyle': 'None'}\n", "        plot_specs.update(kwargs_plot)\n", "\n", "        # t_bound = float('inf')\n", "        # if t is None:\n", "            # for topic, _ in topic_dims:\n", "                # t_bound = min(t_bound, self.counts[topic])\n", "            # t = range(t_bound)\n", "        # data = self.pack(topic_dims, t)\n", "        data = self.data_t(topic_dims, t)\n", "\n", "        ax.plot(*(data.T), **plot_specs)\n", "        if ms_limits:\n", "            ax.axis(self.axes_limits(topic_dims))\n"], "language": "python", "code": "def scatter_plot(self, ax, topic_dims, t=None, ms_limits=True, **kwargs_plot):\n    \"\"\"\"\"\"\n    plot_specs = {'marker': 'o', 'linestyle': 'None'}\n    plot_specs.update(kwargs_plot)\n    data = self.data_t(topic_dims, t)\n    ax.plot(*data.T, **plot_specs)\n    if ms_limits:\n        ax.axis(self.axes_limits(topic_dims))\n", "code_tokens": ["scatter", "plot", "self", "ax", "topic", "dims", "none", "ms", "limits", "true", "kwargs", "plot", "plot", "specs", "marker", "linestyle", "none", "plot", "specs", "update", "kwargs", "plot", "data", "self", "data", "topic", "dims", "ax", "plot", "data", "plot", "specs", "if", "ms", "limits", "ax", "axis", "self", "axes", "limits", "topic", "dims"], "docstring": "scatter plot", "docstring_tokens": ["scatter", "plot"], "idx": 384}
{"url": "https://github.com/bcbio/bcbio-nextgen/blob/6a9348c0054ccd5baffd22f1bb7d0422f6978b20/bcbio/structural/cnvkit.py#L633-L646", "repo": "bcbio-nextgen", "func_name": "_add_plots_to_output", "original_string": ["def _add_plots_to_output(out, data):\n", "    \"\"\"Add CNVkit plots summarizing called copy number values.\n", "    \"\"\"\n", "    out[\"plot\"] = {}\n", "    diagram_plot = _add_diagram_plot(out, data)\n", "    if diagram_plot:\n", "        out[\"plot\"][\"diagram\"] = diagram_plot\n", "    scatter = _add_scatter_plot(out, data)\n", "    if scatter:\n", "        out[\"plot\"][\"scatter\"] = scatter\n", "    scatter_global = _add_global_scatter_plot(out, data)\n", "    if scatter_global:\n", "        out[\"plot\"][\"scatter_global\"] = scatter_global\n", "    return out\n"], "language": "python", "code": "def _add_plots_to_output(out, data):\n    \"\"\"\"\"\"\n    out['plot'] = {}\n    diagram_plot = _add_diagram_plot(out, data)\n    if diagram_plot:\n        out['plot']['diagram'] = diagram_plot\n    scatter = _add_scatter_plot(out, data)\n    if scatter:\n        out['plot']['scatter'] = scatter\n    scatter_global = _add_global_scatter_plot(out, data)\n    if scatter_global:\n        out['plot']['scatter_global'] = scatter_global\n    return out\n", "code_tokens": ["add", "plots", "to", "output", "out", "data", "out", "plot", "diagram", "plot", "add", "diagram", "plot", "out", "data", "if", "diagram", "plot", "out", "plot", "diagram", "diagram", "plot", "scatter", "add", "scatter", "plot", "out", "data", "if", "scatter", "out", "plot", "scatter", "scatter", "scatter", "global", "add", "global", "scatter", "plot", "out", "data", "if", "scatter", "global", "out", "plot", "scatter", "global", "scatter", "global", "return", "out"], "docstring": "scatter plot", "docstring_tokens": ["scatter", "plot"], "idx": 385}
{"url": "https://github.com/totalgood/nlpia/blob/efa01126275e9cd3c3a5151a644f1c798a9ec53f/src/nlpia/book/examples/ch05_sms_spam_linear_regression.py#L161-L173", "repo": "nlpia", "func_name": "sentiment_scatter", "original_string": ["\n", "def sentiment_scatter(sms=sms):\n", "    plt.figure(figsize=(10, 7.5))\n", "    ax = plt.subplot(1, 1, 1)\n", "    ax = sms.plot.scatter(x='topic4', y='line', ax=ax, color='g', marker='+', alpha=.6)\n", "    ax = sms.plot.scatter(x='topic4', y='sgd', ax=ax, color='r', marker='x', alpha=.4)\n", "    ax = sms.plot.scatter(x='topic4', y='vader', ax=ax, color='k', marker='.', alpha=.3)\n", "    ax = sms.plot.scatter(x='topic4', y='sgd', ax=ax, color='c', marker='s', alpha=.6)\n", "    ax = sms.plot.scatter(x='topic4', y='pca_lda_spaminess', ax=ax, color='b', marker='o', alpha=.6)\n", "    plt.ylabel('Sentiment')\n", "    plt.xlabel('Topic 4')\n", "    plt.legend(['LinearRegressor', 'SGDRegressor', 'Vader', 'OneNeuronRegresor', 'PCA->LDA->spaminess'])\n", "    plt.tight_layout()\n"], "language": "python", "code": "def sentiment_scatter(sms=sms):\n    plt.figure(figsize=(10, 7.5))\n    ax = plt.subplot(1, 1, 1)\n    ax = sms.plot.scatter(x='topic4', y='line', ax=ax, color='g', marker=\n        '+', alpha=0.6)\n    ax = sms.plot.scatter(x='topic4', y='sgd', ax=ax, color='r', marker='x',\n        alpha=0.4)\n    ax = sms.plot.scatter(x='topic4', y='vader', ax=ax, color='k', marker=\n        '.', alpha=0.3)\n    ax = sms.plot.scatter(x='topic4', y='sgd', ax=ax, color='c', marker='s',\n        alpha=0.6)\n    ax = sms.plot.scatter(x='topic4', y='pca_lda_spaminess', ax=ax, color=\n        'b', marker='o', alpha=0.6)\n    plt.ylabel('Sentiment')\n    plt.xlabel('Topic 4')\n    plt.legend(['LinearRegressor', 'SGDRegressor', 'Vader',\n        'OneNeuronRegresor', 'PCA->LDA->spaminess'])\n    plt.tight_layout()\n", "code_tokens": ["sentiment", "scatter", "sms", "sms", "plt", "figure", "figsize", "10", "7", "5", "ax", "plt", "subplot", "1", "1", "1", "ax", "sms", "plot", "scatter", "line", "ax", "ax", "color", "marker", "alpha", "0", "6", "ax", "sms", "plot", "scatter", "sgd", "ax", "ax", "color", "marker", "alpha", "0", "4", "ax", "sms", "plot", "scatter", "vader", "ax", "ax", "color", "marker", "alpha", "0", "3", "ax", "sms", "plot", "scatter", "sgd", "ax", "ax", "color", "marker", "alpha", "0", "6", "ax", "sms", "plot", "scatter", "pca", "lda", "spaminess", "ax", "ax", "color", "marker", "alpha", "0", "6", "plt", "ylabel", "sentiment", "plt", "xlabel", "topic", "4", "plt", "legend", "linearregressor", "sgdregressor", "vader", "oneneuronregresor", "pca", "lda", "spaminess", "plt", "tight", "layout"], "docstring": "scatter plot", "docstring_tokens": ["scatter", "plot"], "idx": 386}
{"url": "https://github.com/newville/wxmplot/blob/8e0dc037453e5cdf18c968dc5a3d29efd761edee/wxmplot/plotframe.py#L45-L47", "repo": "wxmplot", "func_name": "scatterplot", "original_string": ["    def scatterplot(self, x, y, **kw):\n", "        \"\"\"plot after clearing current plot \"\"\"\n", "        self.panel.scatterplot(x, y, **kw)\n"], "language": "python", "code": "def scatterplot(self, x, y, **kw):\n    \"\"\"\"\"\"\n    self.panel.scatterplot(x, y, **kw)\n", "code_tokens": ["scatterplot", "self", "kw", "self", "panel", "scatterplot", "kw"], "docstring": "scatter plot", "docstring_tokens": ["scatter", "plot"], "idx": 387}
{"url": "https://github.com/SheffieldML/GPy/blob/54c32d79d289d622fb18b898aee65a2a431d90cf/GPy/plotting/matplot_dep/plot_definitions.py#L99-L102", "repo": "GPy", "func_name": "scatter", "original_string": ["    def scatter(self, ax, X, Y, Z=None, color=Tango.colorsHex['mediumBlue'], label=None, marker='o', **kwargs):\n", "        if Z is not None:\n", "            return ax.scatter(X, Y, c=color, zs=Z, label=label, marker=marker, **kwargs)\n", "        return ax.scatter(X, Y, c=color, label=label, marker=marker, **kwargs)\n"], "language": "python", "code": "def scatter(self, ax, X, Y, Z=None, color=Tango.colorsHex['mediumBlue'],\n    label=None, marker='o', **kwargs):\n    if Z is not None:\n        return ax.scatter(X, Y, c=color, zs=Z, label=label, marker=marker,\n            **kwargs)\n    return ax.scatter(X, Y, c=color, label=label, marker=marker, **kwargs)\n", "code_tokens": ["scatter", "self", "ax", "none", "color", "tango", "colorshex", "mediumblue", "label", "none", "marker", "kwargs", "if", "is", "not", "none", "return", "ax", "scatter", "color", "zs", "label", "label", "marker", "marker", "kwargs", "return", "ax", "scatter", "color", "label", "label", "marker", "marker", "kwargs"], "docstring": "scatter plot", "docstring_tokens": ["scatter", "plot"], "idx": 388}
{"url": "https://github.com/kahowell/sdl2-cffi/blob/8e51d97c7c19ca17d8c2994f54b18e8563310270/sdl2/_cffi.py#L155-L159", "repo": "sdl2-cffi", "func_name": "sanitize_enum", "original_string": ["    def sanitize_enum(self, enum):\n", "        for name, enumeratorlist in enum.children():\n", "            for name, enumerator in enumeratorlist.children():\n", "                enumerator.value = c_ast.Constant('dummy', '...')\n", "        return enum\n"], "language": "python", "code": "def sanitize_enum(self, enum):\n    for name, enumeratorlist in enum.children():\n        for name, enumerator in enumeratorlist.children():\n            enumerator.value = c_ast.Constant('dummy', '...')\n    return enum\n", "code_tokens": ["sanitize", "enum", "self", "enum", "for", "name", "enumeratorlist", "in", "enum", "children", "for", "name", "enumerator", "in", "enumeratorlist", "children", "enumerator", "value", "ast", "constant", "dummy", "return", "enum"], "docstring": "get name of enumerated value", "docstring_tokens": ["get", "name", "of", "enumerated", "value"], "idx": 389}
{"url": "https://github.com/apple/turicreate/blob/74514c3f99e25b46f22c6e02977fe3da69221c2e/src/external/coremltools_wrap/coremltools/deps/protobuf/python/google/protobuf/descriptor.py#L321-L337", "repo": "turicreate", "func_name": "EnumValueName", "original_string": ["  def EnumValueName(self, enum, value):\n", "    \"\"\"Returns the string name of an enum value.\n", "\n", "    This is just a small helper method to simplify a common operation.\n", "\n", "    Args:\n", "      enum: string name of the Enum.\n", "      value: int, value of the enum.\n", "\n", "    Returns:\n", "      string name of the enum value.\n", "\n", "    Raises:\n", "      KeyError if either the Enum doesn't exist or the value is not a valid\n", "        value for the enum.\n", "    \"\"\"\n", "    return self.enum_types_by_name[enum].values_by_number[value].name\n"], "language": "python", "code": "def EnumValueName(self, enum, value):\n    \"\"\"\"\"\"\n    return self.enum_types_by_name[enum].values_by_number[value].name\n", "code_tokens": ["enumvaluename", "self", "enum", "value", "return", "self", "enum", "types", "by", "name", "enum", "values", "by", "number", "value", "name"], "docstring": "get name of enumerated value", "docstring_tokens": ["get", "name", "of", "enumerated", "value"], "idx": 390}
{"url": "https://github.com/iotile/coretools/blob/2d794f5f1346b841b0dcd16c9d284e9bf2f3c6ec/iotilecore/iotile/core/utilities/schema_verify/enum_verify.py#L16-L32", "repo": "coretools", "func_name": "verify", "original_string": ["    def verify(self, obj):\n", "        \"\"\"Verify that the object conforms to this verifier's schema.\n", "\n", "        Args:\n", "            obj (object): A python object to verify\n", "\n", "        Raises:\n", "            ValidationError: If there is a problem verifying the object, a\n", "                ValidationError is thrown with at least the reason key set indicating\n", "                the reason for the lack of validation.\n", "        \"\"\"\n", "\n", "        if obj not in self.options:\n", "            raise ValidationError(\"Object is not in list of enumerated options\",\n", "                                  reason='not in list of enumerated options', object=obj, options=self.options)\n", "\n", "        return obj\n"], "language": "python", "code": "def verify(self, obj):\n    \"\"\"\"\"\"\n    if obj not in self.options:\n        raise ValidationError('Object is not in list of enumerated options',\n            reason='not in list of enumerated options', object=obj, options\n            =self.options)\n    return obj\n", "code_tokens": ["verify", "self", "obj", "if", "obj", "not", "in", "self", "options", "raise", "validationerror", "object", "is", "not", "in", "list", "of", "enumerated", "options", "reason", "not", "in", "list", "of", "enumerated", "options", "object", "obj", "options", "self", "options", "return", "obj"], "docstring": "get name of enumerated value", "docstring_tokens": ["get", "name", "of", "enumerated", "value"], "idx": 391}
{"url": "https://github.com/ibelie/typy/blob/3616845fb91459aacd8df6bf82c5d91f4542bee7/typy/Proto.py#L266-L274", "repo": "typy", "func_name": "Enum", "original_string": ["def Enum(name, *fields):\n", "\tobj = TypeObject()\n", "\tobj.isEnum = True\n", "\tobj.__name__ = name\n", "\tobj.__enum__ = {}\n", "\tfor a, p in fields:\n", "\t\tobj.__enum__[p] = TypeObject()\n", "\t\tobj.__enum__[p].name = a\n", "\treturn obj\n"], "language": "python", "code": "def Enum(name, *fields):\n    obj = TypeObject()\n    obj.isEnum = True\n    obj.__name__ = name\n    obj.__enum__ = {}\n    for a, p in fields:\n        obj.__enum__[p] = TypeObject()\n        obj.__enum__[p].name = a\n    return obj\n", "code_tokens": ["enum", "name", "fields", "obj", "typeobject", "obj", "isenum", "true", "obj", "name", "name", "obj", "enum", "for", "in", "fields", "obj", "enum", "typeobject", "obj", "enum", "name", "return", "obj"], "docstring": "get name of enumerated value", "docstring_tokens": ["get", "name", "of", "enumerated", "value"], "idx": 392}
{"url": "https://github.com/ajyoon/blur/blob/25fcf083af112bb003956a7a7e1c6ff7d8fef279/blur/rand.py#L252-L300", "repo": "blur", "func_name": "normal_distribution", "original_string": ["def normal_distribution(mean, variance,\n", "                        minimum=None, maximum=None, weight_count=23):\n", "    \"\"\"\n", "    Return a list of weights approximating a normal distribution.\n", "\n", "    Args:\n", "        mean (float): The mean of the distribution\n", "        variance (float): The variance of the distribution\n", "        minimum (float): The minimum outcome possible to\n", "            bound the output distribution to\n", "        maximum (float): The maximum outcome possible to\n", "            bound the output distribution to\n", "        weight_count (int): The number of weights that will\n", "            be used to approximate the distribution\n", "\n", "    Returns:\n", "        list: a list of ``(float, float)`` weight tuples\n", "        approximating a normal distribution.\n", "\n", "    Raises:\n", "        ValueError: ``if maximum < minimum``\n", "        TypeError: if both ``minimum`` and ``maximum`` are ``None``\n", "\n", "    Example:\n", "        >>> weights = normal_distribution(10, 3,\n", "        ...                               minimum=0, maximum=20,\n", "        ...                               weight_count=5)\n", "        >>> rounded_weights = [(round(value, 2), round(strength, 2))\n", "        ...                    for value, strength in weights]\n", "        >>> rounded_weights\n", "        [(1.34, 0.0), (4.8, 0.0), (8.27, 0.14), (11.73, 0.14), (15.2, 0.0)]\n", "    \"\"\"\n", "    # Pin 0 to +- 5 sigma as bounds, or minimum and maximum\n", "    # if they cross +/- sigma\n", "    standard_deviation = math.sqrt(variance)\n", "    min_x = (standard_deviation * -5) + mean\n", "    max_x = (standard_deviation * 5) + mean\n", "    step = (max_x - min_x) / weight_count\n", "    current_x = min_x\n", "    weights = []\n", "    while current_x < max_x:\n", "        weights.append(\n", "            (current_x, _normal_function(current_x, mean, variance))\n", "        )\n", "        current_x += step\n", "    if minimum is not None or maximum is not None:\n", "        return bound_weights(weights, minimum, maximum)\n", "    else:\n", "        return weights\n"], "language": "python", "code": "def normal_distribution(mean, variance, minimum=None, maximum=None,\n    weight_count=23):\n    \"\"\"\"\"\"\n    standard_deviation = math.sqrt(variance)\n    min_x = standard_deviation * -5 + mean\n    max_x = standard_deviation * 5 + mean\n    step = (max_x - min_x) / weight_count\n    current_x = min_x\n    weights = []\n    while current_x < max_x:\n        weights.append((current_x, _normal_function(current_x, mean, variance))\n            )\n        current_x += step\n    if minimum is not None or maximum is not None:\n        return bound_weights(weights, minimum, maximum)\n    else:\n        return weights\n", "code_tokens": ["normal", "distribution", "mean", "variance", "minimum", "none", "maximum", "none", "weight", "count", "23", "standard", "deviation", "math", "sqrt", "variance", "min", "standard", "deviation", "5", "mean", "max", "standard", "deviation", "5", "mean", "step", "max", "min", "weight", "count", "current", "min", "weights", "while", "current", "max", "weights", "append", "current", "normal", "function", "current", "mean", "variance", "current", "step", "if", "minimum", "is", "not", "none", "or", "maximum", "is", "not", "none", "return", "bound", "weights", "weights", "minimum", "maximum", "else", "return", "weights"], "docstring": "normal distribution", "docstring_tokens": ["normal", "distribution"], "idx": 393}
{"url": "https://github.com/ceph/ceph-deploy/blob/86943fcc454cd4c99a86e3493e9e93a59c661fef/ceph_deploy/hosts/__init__.py#L112-L132", "repo": "ceph-deploy", "func_name": "_normalized_distro_name", "original_string": ["        return distributions.get(distro) or _get_distro(fallback)\n", "\n", "\n", "def _normalized_distro_name(distro):\n", "    distro = distro.lower()\n", "    if distro.startswith(('redhat', 'red hat')):\n", "        return 'redhat'\n", "    elif distro.startswith(('scientific', 'scientific linux')):\n", "        return 'scientific'\n", "    elif distro.startswith('oracle'):\n", "        return 'oracle'\n", "    elif distro.startswith(('suse', 'opensuse', 'sles')):\n", "        return 'suse'\n", "    elif distro.startswith(('centos', 'euleros', 'openeuler')):\n", "        return 'centos'\n", "    elif distro.startswith(('linuxmint', 'kylin')):\n", "        return 'ubuntu'\n", "    elif distro.startswith('virtuozzo'):\n", "        return 'virtuozzo'\n", "    elif distro.startswith('arch'):\n", "        return 'arch'\n"], "language": "python", "code": "def _normalized_distro_name(distro):\n    distro = distro.lower()\n    if distro.startswith(('redhat', 'red hat')):\n        return 'redhat'\n    elif distro.startswith(('scientific', 'scientific linux')):\n        return 'scientific'\n    elif distro.startswith('oracle'):\n        return 'oracle'\n    elif distro.startswith(('suse', 'opensuse', 'sles')):\n        return 'suse'\n    elif distro.startswith(('centos', 'euleros', 'openeuler')):\n        return 'centos'\n    elif distro.startswith(('linuxmint', 'kylin')):\n        return 'ubuntu'\n    elif distro.startswith('virtuozzo'):\n        return 'virtuozzo'\n    elif distro.startswith('arch'):\n        return 'arch'\n", "code_tokens": ["normalized", "distro", "name", "distro", "distro", "distro", "lower", "if", "distro", "startswith", "redhat", "red", "hat", "return", "redhat", "elif", "distro", "startswith", "scientific", "scientific", "linux", "return", "scientific", "elif", "distro", "startswith", "oracle", "return", "oracle", "elif", "distro", "startswith", "suse", "opensuse", "sles", "return", "suse", "elif", "distro", "startswith", "centos", "euleros", "openeuler", "return", "centos", "elif", "distro", "startswith", "linuxmint", "kylin", "return", "ubuntu", "elif", "distro", "startswith", "virtuozzo", "return", "virtuozzo", "elif", "distro", "startswith", "arch", "return", "arch"], "docstring": "normal distribution", "docstring_tokens": ["normal", "distribution"], "idx": 394}
{"url": "https://github.com/whiteclover/dbpy/blob/3d9ce85f55cfb39cced22081e525f79581b26b3a/db/pymysql/connection.py#L53-L56", "repo": "dbpy", "func_name": "connect", "original_string": ["    def connect(self):\n", "        self.close()\n", "        self._connect = pymysql.connect(**self._db_options)\n", "        self._connect.autocommit(True)\n"], "language": "python", "code": "def connect(self):\n    self.close()\n    self._connect = pymysql.connect(**self._db_options)\n    self._connect.autocommit(True)\n", "code_tokens": ["connect", "self", "self", "close", "self", "connect", "pymysql", "connect", "self", "db", "options", "self", "connect", "autocommit", "true"], "docstring": "connect to sql", "docstring_tokens": ["connect", "to", "sql"], "idx": 395}
{"url": "https://github.com/guilhermechapiewski/simple-db-migrate/blob/7ea6ffd0c58f70079cc344eae348430c7bdaaab3/simple_db_migrate/mysql.py#L30-L40", "repo": "simple-db-migrate", "func_name": "__mysql_connect", "original_string": ["    def __mysql_connect(self, connect_using_database_name=True):\n", "        try:\n", "            conn = self.__mysql_driver.connect(host=self.__mysql_host, port=self.__mysql_port, user=self.__mysql_user, passwd=self.__mysql_passwd)\n", "\n", "            conn.set_character_set(self.__mysql_encoding)\n", "\n", "            if connect_using_database_name:\n", "                conn.select_db(self.__mysql_db)\n", "            return conn\n", "        except Exception as e:\n", "            raise Exception(\"could not connect to database: %s\" % e)\n"], "language": "python", "code": "def __mysql_connect(self, connect_using_database_name=True):\n    try:\n        conn = self.__mysql_driver.connect(host=self.__mysql_host, port=\n            self.__mysql_port, user=self.__mysql_user, passwd=self.\n            __mysql_passwd)\n        conn.set_character_set(self.__mysql_encoding)\n        if connect_using_database_name:\n            conn.select_db(self.__mysql_db)\n        return conn\n    except Exception as e:\n        raise Exception('could not connect to database: %s' % e)\n", "code_tokens": ["mysql", "connect", "self", "connect", "using", "database", "name", "true", "try", "conn", "self", "mysql", "driver", "connect", "host", "self", "mysql", "host", "port", "self", "mysql", "port", "user", "self", "mysql", "user", "passwd", "self", "mysql", "passwd", "conn", "set", "character", "set", "self", "mysql", "encoding", "if", "connect", "using", "database", "name", "conn", "select", "db", "self", "mysql", "db", "return", "conn", "except", "exception", "as", "raise", "exception", "could", "not", "connect", "to", "database"], "docstring": "connect to sql", "docstring_tokens": ["connect", "to", "sql"], "idx": 396}
{"url": "https://github.com/robinandeer/puzzle/blob/9476f05b416d3a5135d25492cb31411fdf831c58/puzzle/plugins/sql/store.py#L62-L86", "repo": "puzzle", "func_name": "connect", "original_string": ["    def connect(self, db_uri, debug=False):\n", "        \"\"\"Configure connection to a SQL database.\n", "\n", "        Args:\n", "            db_uri (str): path/URI to the database to connect to\n", "            debug (Optional[bool]): whether to output logging information\n", "        \"\"\"\n", "        kwargs = {'echo': debug, 'convert_unicode': True}\n", "        # connect to the SQL database\n", "        if 'mysql' in db_uri:\n", "            kwargs['pool_recycle'] = 3600\n", "        elif '://' not in db_uri:\n", "            logger.debug(\"detected sqlite path URI: {}\".format(db_uri))\n", "            db_path = os.path.abspath(os.path.expanduser(db_uri))\n", "            db_uri = \"sqlite:///{}\".format(db_path)\n", "\n", "        self.engine = create_engine(db_uri, **kwargs)\n", "        logger.debug('connection established successfully')\n", "        # make sure the same engine is propagated to the BASE classes\n", "        BASE.metadata.bind = self.engine\n", "        # start a session\n", "        self.session = scoped_session(sessionmaker(bind=self.engine))\n", "        # shortcut to query method\n", "        self.query = self.session.query\n", "        return self\n"], "language": "python", "code": "def connect(self, db_uri, debug=False):\n    \"\"\"\"\"\"\n    kwargs = {'echo': debug, 'convert_unicode': True}\n    if 'mysql' in db_uri:\n        kwargs['pool_recycle'] = 3600\n    elif '://' not in db_uri:\n        logger.debug('detected sqlite path URI: {}'.format(db_uri))\n        db_path = os.path.abspath(os.path.expanduser(db_uri))\n        db_uri = 'sqlite:///{}'.format(db_path)\n    self.engine = create_engine(db_uri, **kwargs)\n    logger.debug('connection established successfully')\n    BASE.metadata.bind = self.engine\n    self.session = scoped_session(sessionmaker(bind=self.engine))\n    self.query = self.session.query\n    return self\n", "code_tokens": ["connect", "self", "db", "uri", "debug", "false", "kwargs", "echo", "debug", "convert", "unicode", "true", "if", "mysql", "in", "db", "uri", "kwargs", "pool", "recycle", "3600", "elif", "not", "in", "db", "uri", "logger", "debug", "detected", "sqlite", "path", "uri", "format", "db", "uri", "db", "path", "os", "path", "abspath", "os", "path", "expanduser", "db", "uri", "db", "uri", "sqlite", "format", "db", "path", "self", "engine", "create", "engine", "db", "uri", "kwargs", "logger", "debug", "connection", "established", "successfully", "base", "metadata", "bind", "self", "engine", "self", "session", "scoped", "session", "sessionmaker", "bind", "self", "engine", "self", "query", "self", "session", "query", "return", "self"], "docstring": "connect to sql", "docstring_tokens": ["connect", "to", "sql"], "idx": 397}
{"url": "https://github.com/aouyar/PyMunin/blob/4f58a64b6b37c85a84cc7e1e07aafaa0321b249d/pysysinfo/mysql.py#L64-L69", "repo": "PyMunin", "func_name": "_connect", "original_string": ["    def _connect(self):\n", "        \"\"\"Establish connection to MySQL Database.\"\"\"\n", "        if self._connParams:\n", "            self._conn = MySQLdb.connect(**self._connParams)\n", "        else:\n", "            self._conn = MySQLdb.connect('')\n"], "language": "python", "code": "def _connect(self):\n    \"\"\"\"\"\"\n    if self._connParams:\n        self._conn = MySQLdb.connect(**self._connParams)\n    else:\n        self._conn = MySQLdb.connect('')\n", "code_tokens": ["connect", "self", "if", "self", "connparams", "self", "conn", "mysqldb", "connect", "self", "connparams", "else", "self", "conn", "mysqldb", "connect"], "docstring": "connect to sql", "docstring_tokens": ["connect", "to", "sql"], "idx": 398}
{"url": "https://github.com/CitrineInformatics/python-citrination-client/blob/409984fc65ce101a620f069263f155303492465c/citrination_client/search/core/query/base_returning_query.py#L9-L40", "repo": "python-citrination-client", "func_name": "__init__", "original_string": ["    def __init__(self, query=None, extraction_sort=None, from_index=None, size=None, random_results=None,\n", "                 random_seed=None, score_relevance=None, return_max_score=None, timeout=None, **kwargs):\n", "        \"\"\"\n", "        Base class for all queries against datasets and the items that they contain on Citrination.\n", "\n", "        :param query: One or more :class:`DataQuery` objects with the queries to run.\n", "        :param extraction_sort: A single :class:`ExtractionSort` object for sorting.\n", "        :param from_index: Index of the first hit that should be returned.\n", "        :param size: Total number of hits the should be returned.\n", "        :param random_results: Whether to return a random set of records.\n", "        :param random_seed: The random seed to use.\n", "        :param score_relevance: Whether to use relevance scoring.\n", "        :param return_max_score: Whether to return the maximum score.\n", "        :param timeout: The number of milliseconds to wait for the query to execute.\n", "        \"\"\"\n", "        super(BaseReturningQuery, self).__init__(query=query, extraction_sort=extraction_sort, **kwargs)\n", "        if 'from' in 'kwargs':\n", "            self.from_index = kwargs['from']\n", "        self._from = None\n", "        self.from_index = from_index\n", "        self._size = None\n", "        self.size = size\n", "        self._random_results = None\n", "        self.random_results = random_results\n", "        self._random_seed = None\n", "        self.random_seed = random_seed\n", "        self._score_relevance = None\n", "        self.score_relevance = score_relevance\n", "        self._return_max_score = None\n", "        self.return_max_score = return_max_score\n", "        self._timeout = None\n", "        self.timeout = timeout\n"], "language": "python", "code": "def __init__(self, query=None, extraction_sort=None, from_index=None, size=\n    None, random_results=None, random_seed=None, score_relevance=None,\n    return_max_score=None, timeout=None, **kwargs):\n    \"\"\"\"\"\"\n    super(BaseReturningQuery, self).__init__(query=query, extraction_sort=\n        extraction_sort, **kwargs)\n    if 'from' in 'kwargs':\n        self.from_index = kwargs['from']\n    self._from = None\n    self.from_index = from_index\n    self._size = None\n    self.size = size\n    self._random_results = None\n    self.random_results = random_results\n    self._random_seed = None\n    self.random_seed = random_seed\n    self._score_relevance = None\n    self.score_relevance = score_relevance\n    self._return_max_score = None\n    self.return_max_score = return_max_score\n    self._timeout = None\n    self.timeout = timeout\n", "code_tokens": ["init", "self", "query", "none", "extraction", "sort", "none", "from", "index", "none", "size", "none", "random", "results", "none", "random", "seed", "none", "score", "relevance", "none", "return", "max", "score", "none", "timeout", "none", "kwargs", "super", "basereturningquery", "self", "init", "query", "query", "extraction", "sort", "extraction", "sort", "kwargs", "if", "from", "in", "kwargs", "self", "from", "index", "kwargs", "from", "self", "from", "none", "self", "from", "index", "from", "index", "self", "size", "none", "self", "size", "size", "self", "random", "results", "none", "self", "random", "results", "random", "results", "self", "random", "seed", "none", "self", "random", "seed", "random", "seed", "self", "score", "relevance", "none", "self", "score", "relevance", "score", "relevance", "self", "return", "max", "score", "none", "self", "return", "max", "score", "return", "max", "score", "self", "timeout", "none", "self", "timeout", "timeout"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 399}
{"url": "https://github.com/rkargon/pixelsorter/blob/0775d1e487fbcb023e411e1818ba3290b0e8665e/pixelsorter/util.py#L72-L84", "repo": "pixelsorter", "func_name": "weighted_random_choice", "original_string": ["def weighted_random_choice(items):\n", "    \"\"\"\n", "    Returns a weighted random choice from a list of items.\n", "    :param items: A list of tuples (object, weight)\n", "    :return: A random object, whose likelihood is proportional to its weight.\n", "    \"\"\"\n", "    l = list(items)\n", "    r = random.random() * sum([i[1] for i in l])\n", "    for x, p in l:\n", "        if p > r:\n", "            return x\n", "        r -= p\n", "    return None\n"], "language": "python", "code": "def weighted_random_choice(items):\n    \"\"\"\"\"\"\n    l = list(items)\n    r = random.random() * sum([i[1] for i in l])\n    for x, p in l:\n        if p > r:\n            return x\n        r -= p\n    return None\n", "code_tokens": ["weighted", "random", "choice", "items", "list", "items", "random", "random", "sum", "1", "for", "in", "for", "in", "if", "return", "return", "none"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 400}
{"url": "https://github.com/callowayproject/Calloway/blob/d22e98d41fbd298ab6393ba7bd84a75528be9f81/calloway/apps/django_ext/markov.py#L51-L64", "repo": "Calloway", "func_name": "random_output", "original_string": ["    def random_output(self, max=100):\n", "        \"\"\" Generate a list of elements from the markov chain.\n", "            The `max` value is in place in order to prevent excessive iteration.\n", "        \"\"\"\n", "        output = []\n", "        item1 = item2 = MarkovChain.START\n", "        for i in range(max-3):\n", "            item3 = self[(item1, item2)].roll()\n", "            if item3 is MarkovChain.END:\n", "                break\n", "            output.append(item3)\n", "            item1 = item2\n", "            item2 = item3\n", "        return output\n"], "language": "python", "code": "def random_output(self, max=100):\n    \"\"\"\"\"\"\n    output = []\n    item1 = item2 = MarkovChain.START\n    for i in range(max - 3):\n        item3 = self[item1, item2].roll()\n        if item3 is MarkovChain.END:\n            break\n        output.append(item3)\n        item1 = item2\n        item2 = item3\n    return output\n", "code_tokens": ["random", "output", "self", "max", "100", "output", "markovchain", "start", "for", "in", "range", "max", "3", "self", "roll", "if", "is", "markovchain", "end", "break", "output", "append", "return", "output"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 401}
{"url": "https://github.com/acutesoftware/AIKIF/blob/fcf1582dc5f884b9a4fa7c6e20e9de9d94d21d03/aikif/toolbox/solve_knapsack.py#L51-L65", "repo": "AIKIF", "func_name": "solve_expensive_items_first", "original_string": ["def solve_expensive_items_first(capacity, items):\n", "    taken = [0]*len(items)\n", "    value = 0\n", "    weight = 0\n", "    taken = [0]*len(items)\n", "    sortedList = sorted(items, key=lambda dens: dens[1], reverse=True)\n", "    for item in sortedList:\n", "        #print ('item [' + str(item.index) + '] value = ' + str(item.value) + ', item.weight = ' + str(item.weight) + ' density = ' + str(item.density))\n", "        if weight + item.weight <= capacity:\n", "            taken[item.index] = 1\n", "            value += item.value\n", "            weight += item.weight\n", "            #print('Adding [' + str(item.index) + '],  value = ' + str(item.value) + ' wght = ' + str(item.weight) )\n", "\n", "    return value, taken\n"], "language": "python", "code": "def solve_expensive_items_first(capacity, items):\n    taken = [0] * len(items)\n    value = 0\n    weight = 0\n    taken = [0] * len(items)\n    sortedList = sorted(items, key=lambda dens: dens[1], reverse=True)\n    for item in sortedList:\n        if weight + item.weight <= capacity:\n            taken[item.index] = 1\n            value += item.value\n            weight += item.weight\n    return value, taken\n", "code_tokens": ["solve", "expensive", "items", "first", "capacity", "items", "taken", "0", "len", "items", "value", "0", "weight", "0", "taken", "0", "len", "items", "sortedlist", "sorted", "items", "key", "lambda", "dens", "dens", "1", "reverse", "true", "for", "item", "in", "sortedlist", "if", "weight", "item", "weight", "capacity", "taken", "item", "index", "1", "value", "item", "value", "weight", "item", "weight", "return", "value", "taken"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 402}
{"url": "https://github.com/mozilla/crontabber/blob/b510be349e71f165c1a9506db95bda0b88728f8b/crontabber/generic_app.py#L178-L184", "repo": "crontabber", "func_name": "tear_down_logger", "original_string": ["def tear_down_logger(app_name):\n", "    logger = logging.getLogger(app_name)\n", "    # must have a copy of the handlers list since we cannot modify the original\n", "    # list while we're deleting items from that list\n", "    handlers = [x for x in logger.handlers]\n", "    for x in handlers:\n", "        logger.removeHandler(x)\n"], "language": "python", "code": "def tear_down_logger(app_name):\n    logger = logging.getLogger(app_name)\n    handlers = [x for x in logger.handlers]\n    for x in handlers:\n        logger.removeHandler(x)\n", "code_tokens": ["tear", "down", "logger", "app", "name", "logger", "logging", "getlogger", "app", "name", "handlers", "for", "in", "logger", "handlers", "for", "in", "handlers", "logger", "removehandler"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 403}
{"url": "https://github.com/lazygunner/xunleipy/blob/cded7598a7bf04495156bae2d747883d1eacb3f4/xunleipy/rsa_lib.py#L167-L177", "repo": "xunleipy", "func_name": "findAPrime", "original_string": ["def findAPrime(a, b, k):\n", "    \"\"\"Return a pseudo prime number roughly between a and b,\n", "    (could be larger than b). Raise ValueError if cannot find a\n", "    pseudo prime after 10 * ln(x) + 3 tries. \"\"\"\n", "    x = random.randint(a, b)\n", "    for i in range(0, int(10 * math.log(x) + 3)):\n", "        if millerRabin(x, k):\n", "            return x\n", "        else:\n", "            x += 1\n", "    raise ValueError\n"], "language": "python", "code": "def findAPrime(a, b, k):\n    \"\"\"\"\"\"\n    x = random.randint(a, b)\n    for i in range(0, int(10 * math.log(x) + 3)):\n        if millerRabin(x, k):\n            return x\n        else:\n            x += 1\n    raise ValueError\n", "code_tokens": ["findaprime", "random", "randint", "for", "in", "range", "0", "int", "10", "math", "log", "3", "if", "millerrabin", "return", "else", "1", "raise", "valueerror"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 404}
{"url": "https://github.com/pereorga/csvshuf/blob/70fdd4f512ef980bffe9cc51bfe59fea116d7c2f/csvshuf/csvshuf.py#L19-L24", "repo": "csvshuf", "func_name": "shuffle_sattolo", "original_string": ["def shuffle_sattolo(items):\n", "    \"\"\"Shuffle items in place using Sattolo's algorithm.\"\"\"\n", "    _randrange = random.randrange\n", "    for i in reversed(range(1, len(items))):\n", "        j = _randrange(i)  # 0 <= j < i\n", "        items[j], items[i] = items[i], items[j]\n"], "language": "python", "code": "def shuffle_sattolo(items):\n    \"\"\"\"\"\"\n    _randrange = random.randrange\n    for i in reversed(range(1, len(items))):\n        j = _randrange(i)\n        items[j], items[i] = items[i], items[j]\n", "code_tokens": ["shuffle", "sattolo", "items", "randrange", "random", "randrange", "for", "in", "reversed", "range", "1", "len", "items", "randrange", "items", "items", "items", "items"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 405}
{"url": "https://github.com/Erotemic/utool/blob/3b27e1f4e6e6fb23cd8744af7b7195b57d99e03a/utool/util_numpy.py#L323-L365", "repo": "utool", "func_name": "random_sample", "original_string": ["def random_sample(list_, nSample, strict=False, rng=None, seed=None):\n", "    \"\"\"\n", "    Grabs data randomly\n", "\n", "    Args:\n", "        list_ (list):\n", "        nSample (?):\n", "        strict (bool): (default = False)\n", "        rng (module):  random number generator(default = numpy.random)\n", "        seed (None): (default = None)\n", "\n", "    Returns:\n", "        list: sample_list\n", "\n", "    CommandLine:\n", "        python -m utool.util_numpy --exec-random_sample\n", "\n", "    Example:\n", "        >>> # DISABLE_DOCTEST\n", "        >>> from utool.util_numpy import *  # NOQA\n", "        >>> list_ = np.arange(10)\n", "        >>> nSample = 4\n", "        >>> strict = False\n", "        >>> rng = np.random.RandomState(0)\n", "        >>> seed = None\n", "        >>> sample_list = random_sample(list_, nSample, strict, rng, seed)\n", "        >>> result = ('sample_list = %s' % (str(sample_list),))\n", "        >>> print(result)\n", "    \"\"\"\n", "    rng = ensure_rng(seed if rng is None else rng)\n", "    if isinstance(list_, list):\n", "        list2_ = list_[:]\n", "    else:\n", "        list2_ = np.copy(list_)\n", "    if len(list2_) == 0 and not strict:\n", "        return list2_\n", "    rng.shuffle(list2_)\n", "    if nSample is None and strict is False:\n", "        return list2_\n", "    if not strict:\n", "        nSample = min(max(0, nSample), len(list2_))\n", "    sample_list = list2_[:nSample]\n", "    return sample_list\n"], "language": "python", "code": "def random_sample(list_, nSample, strict=False, rng=None, seed=None):\n    \"\"\"\"\"\"\n    rng = ensure_rng(seed if rng is None else rng)\n    if isinstance(list_, list):\n        list2_ = list_[:]\n    else:\n        list2_ = np.copy(list_)\n    if len(list2_) == 0 and not strict:\n        return list2_\n    rng.shuffle(list2_)\n    if nSample is None and strict is False:\n        return list2_\n    if not strict:\n        nSample = min(max(0, nSample), len(list2_))\n    sample_list = list2_[:nSample]\n    return sample_list\n", "code_tokens": ["random", "sample", "list", "nsample", "strict", "false", "rng", "none", "seed", "none", "rng", "ensure", "rng", "seed", "if", "rng", "is", "none", "else", "rng", "if", "isinstance", "list", "list", "list", "else", "np", "copy", "list", "if", "len", "0", "and", "not", "strict", "return", "rng", "shuffle", "if", "nsample", "is", "none", "and", "strict", "is", "false", "return", "if", "not", "strict", "nsample", "min", "max", "0", "nsample", "len", "sample", "list", "nsample", "return", "sample", "list"], "docstring": "randomly extract x items from a list", "docstring_tokens": ["randomly", "extract", "x", "items", "from", "a", "list"], "idx": 406}
{"url": "https://github.com/saghul/evergreen/blob/22f22f45892f397c23c3e09e6ea1ad4c00b3add8/evergreen/io/stream.py#L96-L102", "repo": "evergreen", "func_name": "_read_from_buffer", "original_string": ["    def _read_from_buffer(self, delimiter=None, nbytes=None, regex=None):\n", "        if nbytes is not None:\n", "            return self._read_buffer.read(nbytes)\n", "        elif delimiter is not None:\n", "            return self._read_buffer.read_until(delimiter)\n", "        elif regex is not None:\n", "            return self._read_buffer.read_until_regex(regex)\n"], "language": "python", "code": "def _read_from_buffer(self, delimiter=None, nbytes=None, regex=None):\n    if nbytes is not None:\n        return self._read_buffer.read(nbytes)\n    elif delimiter is not None:\n        return self._read_buffer.read_until(delimiter)\n    elif regex is not None:\n        return self._read_buffer.read_until_regex(regex)\n", "code_tokens": ["read", "from", "buffer", "self", "delimiter", "none", "nbytes", "none", "regex", "none", "if", "nbytes", "is", "not", "none", "return", "self", "read", "buffer", "read", "nbytes", "elif", "delimiter", "is", "not", "none", "return", "self", "read", "buffer", "read", "until", "delimiter", "elif", "regex", "is", "not", "none", "return", "self", "read", "buffer", "read", "until", "regex", "regex"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 407}
{"url": "https://github.com/internetarchive/warc/blob/8f05a000a23bbd6501217e37cfd862ffdf19da7f/warc/warc.py#L260-L263", "repo": "warc", "func_name": "reader", "original_string": ["    def reader(self):\n", "        if self._reader is None:\n", "            self._reader = WARCReader(self.fileobj)\n", "        return self._reader\n"], "language": "python", "code": "def reader(self):\n    if self._reader is None:\n        self._reader = WARCReader(self.fileobj)\n    return self._reader\n", "code_tokens": ["reader", "self", "if", "self", "reader", "is", "none", "self", "reader", "warcreader", "self", "fileobj", "return", "self", "reader"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 408}
{"url": "https://github.com/LionelAuroux/pyrser/blob/f153a97ef2b6bf915a1ed468c0252a9a59b754d5/pyrser/parsing/base.py#L314-L327", "repo": "pyrser", "func_name": "read_text", "original_string": ["    def read_text(self, text: str) -> bool:\n", "        \"\"\"\n", "        Consume a strlen(text) text at current position in the stream\n", "        else return False.\n", "        Same as \"\" in BNF\n", "        ex : read_text(\"ls\");.\n", "        \"\"\"\n", "        if self.read_eof():\n", "            return False\n", "        self._stream.save_context()\n", "        if self.peek_text(text):\n", "            self._stream.incpos(len(text))\n", "            return self._stream.validate_context()\n", "        return self._stream.restore_context()\n"], "language": "python", "code": "def read_text(self, text: str) ->bool:\n    \"\"\"\"\"\"\n    if self.read_eof():\n        return False\n    self._stream.save_context()\n    if self.peek_text(text):\n        self._stream.incpos(len(text))\n        return self._stream.validate_context()\n    return self._stream.restore_context()\n", "code_tokens": ["read", "text", "self", "text", "str", "bool", "if", "self", "read", "eof", "return", "false", "self", "stream", "save", "context", "if", "self", "peek", "text", "text", "self", "stream", "incpos", "len", "text", "return", "self", "stream", "validate", "context", "return", "self", "stream", "restore", "context"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 409}
{"url": "https://github.com/hyde/fswrap/blob/41e4ad6f7e9ba73eabe61bd97847cd284e3edbd2/fswrap.py#L282-L289", "repo": "fswrap", "func_name": "read_all", "original_string": ["    def read_all(self, encoding='utf-8'):\n", "        \"\"\"\n", "        Reads from the file and returns the content as a string.\n", "        \"\"\"\n", "        logger.info(\"Reading everything from %s\" % self)\n", "        with codecs.open(self.path, 'r', encoding) as fin:\n", "            read_text = fin.read()\n", "        return read_text\n"], "language": "python", "code": "def read_all(self, encoding='utf-8'):\n    \"\"\"\"\"\"\n    logger.info('Reading everything from %s' % self)\n    with codecs.open(self.path, 'r', encoding) as fin:\n        read_text = fin.read()\n    return read_text\n", "code_tokens": ["read", "all", "self", "encoding", "utf", "8", "logger", "info", "reading", "everything", "from", "self", "with", "codecs", "open", "self", "path", "encoding", "as", "fin", "read", "text", "fin", "read", "return", "read", "text"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 410}
{"url": "https://github.com/aragaer/channels/blob/ba6e4bf8a093deb6224a8b5b63ddb328815d1ae6/channels/channel.py#L13-L21", "repo": "channels", "func_name": "__init__", "original_string": ["    def __init__(self, *, buffering='bytes'):\n", "        self._buffer = b''\n", "        self._lf = 0\n", "\n", "        self._buffering = buffering\n", "        if buffering == 'line':\n", "            self.read = self._readline\n", "        else:\n", "            self.read = self._read\n"], "language": "python", "code": "def __init__(self, *, buffering='bytes'):\n    self._buffer = b''\n    self._lf = 0\n    self._buffering = buffering\n    if buffering == 'line':\n        self.read = self._readline\n    else:\n        self.read = self._read\n", "code_tokens": ["init", "self", "buffering", "bytes", "self", "buffer", "self", "lf", "0", "self", "buffering", "buffering", "if", "buffering", "line", "self", "read", "self", "readline", "else", "self", "read", "self", "read"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 411}
{"url": "https://github.com/waqasbhatti/astrobase/blob/2922a14619d183fb28005fa7d02027ac436f2265/astrobase/hatsurveys/texthatlc.py#L54-L167", "repo": "astrobase", "func_name": "read_original_textlc", "original_string": ["def read_original_textlc(lcpath):\n", "    '''\n", "    Read .epdlc, and .tfalc light curves and return a corresponding labelled\n", "    dict (if LC from <2012) or astropy table (if >=2012). Each has different\n", "    keys that can be accessed via .keys()\n", "\n", "    Input:\n", "    lcpath: path (string) to light curve data, which is a textfile with HAT\n", "    LC data.\n", "\n", "    Example:\n", "    dat = read_original_textlc('HAT-115-0003266.epdlc')\n", "    '''\n", "\n", "    LOGINFO('reading original HAT text LC: {:s}'.format(lcpath))\n", "\n", "    N_lines_to_parse_comments = 50\n", "    with open(lcpath, 'rb') as file:\n", "        head = [next(file) for ind in range(N_lines_to_parse_comments)]\n", "\n", "    N_comment_lines = len([l for l in head if l.decode('UTF-8')[0] == '#'])\n", "\n", "    # if there are too many comment lines, fail out\n", "    if N_comment_lines < N_lines_to_parse_comments:\n", "        LOGERROR(\n", "            'LC file {fpath} has too many comment lines'.format(fpath=lcpath)\n", "        )\n", "        return None\n", "\n", "    first_data_line = list(\n", "        filter(None, head[N_comment_lines].decode('UTF-8').split())\n", "    )\n", "    N_cols = len(first_data_line)\n", "\n", "    # There are different column formats depending on when HAT pipeline was run\n", "    # also different formats for different types of LCs:\n", "    # pre-2012: .epdlc -> 17 columns\n", "    # pre-2012: .tfalc -> 20 columns\n", "    # post-2012: .epdlc or .tfalc -> 32 columns\n", "\n", "    if N_cols == 17:\n", "        colformat = 'pre2012-epdlc'\n", "    elif N_cols == 20:\n", "        colformat = 'pre2012-tfalc'\n", "    elif N_cols == 32:\n", "        colformat = 'post2012-hatlc'\n", "    else:\n", "        LOGERROR(\"can't handle this column format yet, \"\n", "                 \"file: {fpath}, ncols: {ncols}\".format(fpath=lcpath,\n", "                                                        ncols=N_cols))\n", "        return None\n", "\n", "    # deal with pre-2012 column format\n", "    if colformat == 'pre2012-epdlc':\n", "\n", "        col_names = ['framekey','rjd',\n", "                     'aim_000','aie_000','aiq_000',\n", "                     'aim_001','aie_001','aiq_001',\n", "                     'aim_002','aie_002','aiq_002',\n", "                     'arm_000','arm_001','arm_002',\n", "                     'aep_000','aep_001','aep_002']\n", "        col_dtypes = ['U8',float,\n", "                      float,float,'U1',\n", "                      float,float,'U1',\n", "                      float,float,'U1',\n", "                      float,float,float,\n", "                      float,float,float]\n", "        dtype_pairs = [el for el in zip(col_names, col_dtypes)]\n", "        data = np.genfromtxt(lcpath, names=col_names, dtype=col_dtypes,\n", "                             skip_header=N_comment_lines, delimiter=None)\n", "        out = {}\n", "        for ix in range(len(data.dtype.names)):\n", "            out[data.dtype.names[ix]] = data[data.dtype.names[ix]]\n", "\n", "    elif colformat == 'pre2012-tfalc':\n", "\n", "        col_names = ['framekey','rjd',\n", "                     'aim_000','aie_000','aiq_000',\n", "                     'aim_001','aie_001','aiq_001',\n", "                     'aim_002','aie_002','aiq_002',\n", "                     'arm_000','arm_001','arm_002',\n", "                     'aep_000','aep_001','aep_002',\n", "                     'atf_000','atf_001','atf_002']\n", "        col_dtypes = ['U8',float,\n", "                      float,float,'U1',\n", "                      float,float,'U1',\n", "                      float,float,'U1',\n", "                      float,float,float,\n", "                      float,float,float,\n", "                      float,float,float]\n", "        dtype_pairs = [el for el in zip(col_names, col_dtypes)]\n", "        data = np.genfromtxt(lcpath, names=col_names, dtype=col_dtypes,\n", "                             skip_header=N_comment_lines, delimiter=None)\n", "        out = {}\n", "        for ix in range(len(data.dtype.names)):\n", "            out[data.dtype.names[ix]] = data[data.dtype.names[ix]]\n", "\n", "    elif colformat == 'post2012-hatlc':\n", "\n", "        col_names = ['hatid', 'framekey', 'fld', 'bjd',\n", "                     'aim_000', 'aie_000', 'aiq_000',\n", "                     'aim_001', 'aie_001', 'aiq_001',\n", "                     'aim_002', 'aie_002', 'aiq_002',\n", "                     'arm_000', 'arm_001', 'arm_002',\n", "                     'aep_000', 'aep_001', 'aep_002',\n", "                     'atf_000', 'atf_001', 'atf_002',\n", "                     'xcc', 'ycc', 'bgv', 'bge',\n", "                     'fsv', 'fdv', 'fkv',\n", "                     'iha', 'izd', 'rjd']\n", "\n", "        out = astascii.read(lcpath, names=col_names, comment='#')\n", "\n", "    return out\n"], "language": "python", "code": "def read_original_textlc(lcpath):\n    \"\"\"\"\"\"\n    LOGINFO('reading original HAT text LC: {:s}'.format(lcpath))\n    N_lines_to_parse_comments = 50\n    with open(lcpath, 'rb') as file:\n        head = [next(file) for ind in range(N_lines_to_parse_comments)]\n    N_comment_lines = len([l for l in head if l.decode('UTF-8')[0] == '#'])\n    if N_comment_lines < N_lines_to_parse_comments:\n        LOGERROR('LC file {fpath} has too many comment lines'.format(fpath=\n            lcpath))\n        return None\n    first_data_line = list(filter(None, head[N_comment_lines].decode(\n        'UTF-8').split()))\n    N_cols = len(first_data_line)\n    if N_cols == 17:\n        colformat = 'pre2012-epdlc'\n    elif N_cols == 20:\n        colformat = 'pre2012-tfalc'\n    elif N_cols == 32:\n        colformat = 'post2012-hatlc'\n    else:\n        LOGERROR(\n            \"can't handle this column format yet, file: {fpath}, ncols: {ncols}\"\n            .format(fpath=lcpath, ncols=N_cols))\n        return None\n    if colformat == 'pre2012-epdlc':\n        col_names = ['framekey', 'rjd', 'aim_000', 'aie_000', 'aiq_000',\n            'aim_001', 'aie_001', 'aiq_001', 'aim_002', 'aie_002',\n            'aiq_002', 'arm_000', 'arm_001', 'arm_002', 'aep_000',\n            'aep_001', 'aep_002']\n        col_dtypes = ['U8', float, float, float, 'U1', float, float, 'U1',\n            float, float, 'U1', float, float, float, float, float, float]\n        dtype_pairs = [el for el in zip(col_names, col_dtypes)]\n        data = np.genfromtxt(lcpath, names=col_names, dtype=col_dtypes,\n            skip_header=N_comment_lines, delimiter=None)\n        out = {}\n        for ix in range(len(data.dtype.names)):\n            out[data.dtype.names[ix]] = data[data.dtype.names[ix]]\n    elif colformat == 'pre2012-tfalc':\n        col_names = ['framekey', 'rjd', 'aim_000', 'aie_000', 'aiq_000',\n            'aim_001', 'aie_001', 'aiq_001', 'aim_002', 'aie_002',\n            'aiq_002', 'arm_000', 'arm_001', 'arm_002', 'aep_000',\n            'aep_001', 'aep_002', 'atf_000', 'atf_001', 'atf_002']\n        col_dtypes = ['U8', float, float, float, 'U1', float, float, 'U1',\n            float, float, 'U1', float, float, float, float, float, float,\n            float, float, float]\n        dtype_pairs = [el for el in zip(col_names, col_dtypes)]\n        data = np.genfromtxt(lcpath, names=col_names, dtype=col_dtypes,\n            skip_header=N_comment_lines, delimiter=None)\n        out = {}\n        for ix in range(len(data.dtype.names)):\n            out[data.dtype.names[ix]] = data[data.dtype.names[ix]]\n    elif colformat == 'post2012-hatlc':\n        col_names = ['hatid', 'framekey', 'fld', 'bjd', 'aim_000',\n            'aie_000', 'aiq_000', 'aim_001', 'aie_001', 'aiq_001',\n            'aim_002', 'aie_002', 'aiq_002', 'arm_000', 'arm_001',\n            'arm_002', 'aep_000', 'aep_001', 'aep_002', 'atf_000',\n            'atf_001', 'atf_002', 'xcc', 'ycc', 'bgv', 'bge', 'fsv', 'fdv',\n            'fkv', 'iha', 'izd', 'rjd']\n        out = astascii.read(lcpath, names=col_names, comment='#')\n    return out\n", "code_tokens": ["read", "original", "textlc", "lcpath", "loginfo", "reading", "original", "hat", "text", "lc", "format", "lcpath", "lines", "to", "parse", "comments", "50", "with", "open", "lcpath", "rb", "as", "file", "head", "next", "file", "for", "ind", "in", "range", "lines", "to", "parse", "comments", "comment", "lines", "len", "for", "in", "head", "if", "decode", "utf", "8", "0", "if", "comment", "lines", "lines", "to", "parse", "comments", "logerror", "lc", "file", "fpath", "has", "too", "many", "comment", "lines", "format", "fpath", "lcpath", "return", "none", "first", "data", "line", "list", "filter", "none", "head", "comment", "lines", "decode", "utf", "8", "split", "cols", "len", "first", "data", "line", "if", "cols", "17", "colformat", "epdlc", "elif", "cols", "20", "colformat", "tfalc", "elif", "cols", "32", "colformat", "hatlc", "else", "logerror", "can", "handle", "this", "column", "format", "yet", "file", "fpath", "ncols", "ncols", "format", "fpath", "lcpath", "ncols", "cols", "return", "none", "if", "colformat", "epdlc", "col", "names", "framekey", "rjd", "aim", "000", "aie", "000", "aiq", "000", "aim", "001", "aie", "001", "aiq", "001", "aim", "002", "aie", "002", "aiq", "002", "arm", "000", "arm", "001", "arm", "002", "aep", "000", "aep", "001", "aep", "002", "col", "dtypes", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "dtype", "pairs", "el", "for", "el", "in", "zip", "col", "names", "col", "dtypes", "data", "np", "genfromtxt", "lcpath", "names", "col", "names", "dtype", "col", "dtypes", "skip", "header", "comment", "lines", "delimiter", "none", "out", "for", "ix", "in", "range", "len", "data", "dtype", "names", "out", "data", "dtype", "names", "ix", "data", "data", "dtype", "names", "ix", "elif", "colformat", "tfalc", "col", "names", "framekey", "rjd", "aim", "000", "aie", "000", "aiq", "000", "aim", "001", "aie", "001", "aiq", "001", "aim", "002", "aie", "002", "aiq", "002", "arm", "000", "arm", "001", "arm", "002", "aep", "000", "aep", "001", "aep", "002", "atf", "000", "atf", "001", "atf", "002", "col", "dtypes", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "dtype", "pairs", "el", "for", "el", "in", "zip", "col", "names", "col", "dtypes", "data", "np", "genfromtxt", "lcpath", "names", "col", "names", "dtype", "col", "dtypes", "skip", "header", "comment", "lines", "delimiter", "none", "out", "for", "ix", "in", "range", "len", "data", "dtype", "names", "out", "data", "dtype", "names", "ix", "data", "data", "dtype", "names", "ix", "elif", "colformat", "hatlc", "col", "names", "hatid", "framekey", "fld", "bjd", "aim", "000", "aie", "000", "aiq", "000", "aim", "001", "aie", "001", "aiq", "001", "aim", "002", "aie", "002", "aiq", "002", "arm", "000", "arm", "001", "arm", "002", "aep", "000", "aep", "001", "aep", "002", "atf", "000", "atf", "001", "atf", "002", "xcc", "ycc", "bgv", "bge", "fsv", "fdv", "fkv", "iha", "izd", "rjd", "out", "astascii", "read", "lcpath", "names", "col", "names", "comment", "return", "out"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 412}
{"url": "https://github.com/it-geeks-club/pyspectator/blob/356a808b1b29575fd47a85a2611fe50f1afeea8a/pyspectator/temperature_reader.py#L30-L35", "repo": "pyspectator", "func_name": "reader1", "original_string": ["    def reader1(cls, file):\n", "        def reader(file):\n", "            temperature = open(file).read().strip()\n", "            temperature = int(temperature) // 1000\n", "            return temperature\n", "        return partial(reader, file)\n"], "language": "python", "code": "def reader1(cls, file):\n\n    def reader(file):\n        temperature = open(file).read().strip()\n        temperature = int(temperature) // 1000\n        return temperature\n    return partial(reader, file)\n", "code_tokens": ["cls", "file", "def", "reader", "file", "temperature", "open", "file", "read", "strip", "temperature", "int", "temperature", "1000", "return", "temperature", "return", "partial", "reader", "file"], "docstring": "buffered file reader read text", "docstring_tokens": ["buffered", "file", "reader", "read", "text"], "idx": 413}
{"url": "https://github.com/radujica/baloo/blob/f6e05e35b73a75e8a300754c6bdc575e5f2d53b9/baloo/weld/weld_ops.py#L529-L569", "repo": "baloo", "func_name": "weld_unique", "original_string": ["def weld_unique(array, weld_type):\n", "    \"\"\"Return the unique elements of the array.\n", "\n", "    Parameters\n", "    ----------\n", "    array : numpy.ndarray or WeldObject\n", "        Input array.\n", "    weld_type : WeldType\n", "        Type of each element in the input array.\n", "\n", "    Returns\n", "    -------\n", "    WeldObject\n", "        Representation of this computation.\n", "\n", "    \"\"\"\n", "    obj_id, weld_obj = create_weld_object(array)\n", "\n", "    weld_template = \"\"\"map(\n", "    tovec(\n", "        result(\n", "            for(\n", "                map(\n", "                    {array},\n", "                    |e| \n", "                        {{e, 0si}}\n", "                ),\n", "                dictmerger[{type}, i16, +],\n", "                |b: dictmerger[{type}, i16, +], i: i64, e: {{{type}, i16}}| \n", "                    merge(b, e)\n", "            )\n", "        )\n", "    ),\n", "    |e| \n", "        e.$0\n", ")\"\"\"\n", "\n", "    weld_obj.weld_code = weld_template.format(array=obj_id,\n", "                                              type=weld_type)\n", "\n", "    return weld_obj\n"], "language": "python", "code": "def weld_unique(array, weld_type):\n    \"\"\"\"\"\"\n    obj_id, weld_obj = create_weld_object(array)\n    weld_template = \"\"\"map(\n    tovec(\n        result(\n            for(\n                map(\n                    {array},\n                    |e| \n                        {{e, 0si}}\n                ),\n                dictmerger[{type}, i16, +],\n                |b: dictmerger[{type}, i16, +], i: i64, e: {{{type}, i16}}| \n                    merge(b, e)\n            )\n        )\n    ),\n    |e| \n        e.$0\n)\"\"\"\n    weld_obj.weld_code = weld_template.format(array=obj_id, type=weld_type)\n    return weld_obj\n", "code_tokens": ["weld", "unique", "array", "weld", "type", "obj", "id", "weld", "obj", "create", "weld", "object", "array", "weld", "template", "map", "tovec", "result", "for", "map", "array", "dictmerger", "type", "dictmerger", "type", "type", "merge", "0", "weld", "obj", "weld", "code", "weld", "template", "format", "array", "obj", "id", "type", "weld", "type", "return", "weld", "obj"], "docstring": "unique elements", "docstring_tokens": ["unique", "elements"], "idx": 414}
{"url": "https://github.com/shoebot/shoebot/blob/d554c1765c1899fa25727c9fc6805d221585562b/lib/graph/cluster.py#L16-L20", "repo": "shoebot", "func_name": "unique", "original_string": ["def unique(list):\n", "    \"\"\"Returns a copy of the list without duplicates.\"\"\"\n", "    unique = []\n", "    [unique.append(x) for x in list if x not in unique]\n", "    return unique\n"], "language": "python", "code": "def unique(list):\n    \"\"\"\"\"\"\n    unique = []\n    [unique.append(x) for x in list if x not in unique]\n    return unique\n", "code_tokens": ["unique", "list", "unique", "unique", "append", "for", "in", "list", "if", "not", "in", "unique", "return", "unique"], "docstring": "unique elements", "docstring_tokens": ["unique", "elements"], "idx": 415}
{"url": "https://github.com/cloud9ers/gurumate/blob/075dc74d1ee62a8c6b7a8bf2b271364f01629d1e/environment/lib/python2.7/site-packages/IPython/utils/data.py#L22-L42", "repo": "gurumate", "func_name": "uniq_stable", "original_string": ["def uniq_stable(elems):\n", "    \"\"\"uniq_stable(elems) -> list\n", "\n", "    Return from an iterable, a list of all the unique elements in the input,\n", "    but maintaining the order in which they first appear.\n", "\n", "    A naive solution to this problem which just makes a dictionary with the\n", "    elements as keys fails to respect the stability condition, since\n", "    dictionaries are unsorted by nature.\n", "\n", "    Note: All elements in the input must be valid dictionary keys for this\n", "    routine to work, as it internally uses a dictionary for efficiency\n", "    reasons.\"\"\"\n", "\n", "    unique = []\n", "    unique_dict = {}\n", "    for nn in elems:\n", "        if nn not in unique_dict:\n", "            unique.append(nn)\n", "            unique_dict[nn] = None\n", "    return unique\n"], "language": "python", "code": "def uniq_stable(elems):\n    \"\"\"\"\"\"\n    unique = []\n    unique_dict = {}\n    for nn in elems:\n        if nn not in unique_dict:\n            unique.append(nn)\n            unique_dict[nn] = None\n    return unique\n", "code_tokens": ["uniq", "stable", "elems", "unique", "unique", "dict", "for", "nn", "in", "elems", "if", "nn", "not", "in", "unique", "dict", "unique", "append", "nn", "unique", "dict", "nn", "none", "return", "unique"], "docstring": "unique elements", "docstring_tokens": ["unique", "elements"], "idx": 416}
{"url": "https://github.com/sarugaku/virtenv/blob/fc42a9d8dc9f1821d3893899df78e08a081f6ca3/virtenv_cli.py#L20-L28", "repo": "virtenv", "func_name": "which", "original_string": ["def which(name):\n", "    for p in os.environ['PATH'].split(os.pathsep):\n", "        exe = os.path.join(p, name)\n", "        if is_executable(exe):\n", "            return os.path.abspath(exe)\n", "        for ext in [''] + os.environ.get('PATHEXT', '').split(os.pathsep):\n", "            exe = '{}{}'.format(exe, ext.lower())\n", "            if is_executable(exe):\n", "                return os.path.abspath(exe)\n"], "language": "python", "code": "def which(name):\n    for p in os.environ['PATH'].split(os.pathsep):\n        exe = os.path.join(p, name)\n        if is_executable(exe):\n            return os.path.abspath(exe)\n        for ext in ([''] + os.environ.get('PATHEXT', '').split(os.pathsep)):\n            exe = '{}{}'.format(exe, ext.lower())\n            if is_executable(exe):\n                return os.path.abspath(exe)\n", "code_tokens": ["which", "name", "for", "in", "os", "environ", "path", "split", "os", "pathsep", "exe", "os", "path", "join", "name", "if", "is", "executable", "exe", "return", "os", "path", "abspath", "exe", "for", "ext", "in", "os", "environ", "get", "pathext", "split", "os", "pathsep", "exe", "format", "exe", "ext", "lower", "if", "is", "executable", "exe", "return", "os", "path", "abspath", "exe"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 417}
{"url": "https://github.com/calmjs/calmjs/blob/b9b407c2b6a7662da64bccba93bb8d92e7a5fafd/src/calmjs/utils.py#L128-L173", "repo": "calmjs", "func_name": "which", "original_string": ["def which(cmd, mode=os.F_OK | os.X_OK, path=None):\n", "    \"\"\"\n", "    Given cmd, check where it is on PATH.\n", "\n", "    Loosely based on the version in python 3.3.\n", "    \"\"\"\n", "\n", "    if os.path.dirname(cmd):\n", "        if os.path.isfile(cmd) and os.access(cmd, mode):\n", "            return cmd\n", "\n", "    if path is None:\n", "        path = os.environ.get('PATH', defpath)\n", "    if not path:\n", "        return None\n", "\n", "    paths = path.split(pathsep)\n", "\n", "    if sys.platform == 'win32':\n", "        # oh boy\n", "        if curdir not in paths:\n", "            paths = [curdir] + paths\n", "\n", "        # also need to check the fileexts...\n", "        pathext = os.environ.get('PATHEXT', '').split(pathsep)\n", "\n", "        if any(cmd.lower().endswith(ext.lower()) for ext in pathext):\n", "            files = [cmd]\n", "        else:\n", "            files = [cmd + ext for ext in pathext]\n", "    else:\n", "        # sanity\n", "        files = [cmd]\n", "\n", "    seen = set()\n", "    for p in paths:\n", "        normpath = normcase(p)\n", "        if normpath in seen:\n", "            continue\n", "        seen.add(normpath)\n", "        for f in files:\n", "            fn = os.path.join(p, f)\n", "            if os.path.isfile(fn) and os.access(fn, mode):\n", "                return fn\n", "\n", "    return None\n"], "language": "python", "code": "def which(cmd, mode=os.F_OK | os.X_OK, path=None):\n    \"\"\"\"\"\"\n    if os.path.dirname(cmd):\n        if os.path.isfile(cmd) and os.access(cmd, mode):\n            return cmd\n    if path is None:\n        path = os.environ.get('PATH', defpath)\n    if not path:\n        return None\n    paths = path.split(pathsep)\n    if sys.platform == 'win32':\n        if curdir not in paths:\n            paths = [curdir] + paths\n        pathext = os.environ.get('PATHEXT', '').split(pathsep)\n        if any(cmd.lower().endswith(ext.lower()) for ext in pathext):\n            files = [cmd]\n        else:\n            files = [(cmd + ext) for ext in pathext]\n    else:\n        files = [cmd]\n    seen = set()\n    for p in paths:\n        normpath = normcase(p)\n        if normpath in seen:\n            continue\n        seen.add(normpath)\n        for f in files:\n            fn = os.path.join(p, f)\n            if os.path.isfile(fn) and os.access(fn, mode):\n                return fn\n    return None\n", "code_tokens": ["which", "cmd", "mode", "os", "ok", "os", "ok", "path", "none", "if", "os", "path", "dirname", "cmd", "if", "os", "path", "isfile", "cmd", "and", "os", "access", "cmd", "mode", "return", "cmd", "if", "path", "is", "none", "path", "os", "environ", "get", "path", "defpath", "if", "not", "path", "return", "none", "paths", "path", "split", "pathsep", "if", "sys", "platform", "if", "curdir", "not", "in", "paths", "paths", "curdir", "paths", "pathext", "os", "environ", "get", "pathext", "split", "pathsep", "if", "any", "cmd", "lower", "endswith", "ext", "lower", "for", "ext", "in", "pathext", "files", "cmd", "else", "files", "cmd", "ext", "for", "ext", "in", "pathext", "else", "files", "cmd", "seen", "set", "for", "in", "paths", "normpath", "normcase", "if", "normpath", "in", "seen", "continue", "seen", "add", "normpath", "for", "in", "files", "fn", "os", "path", "join", "if", "os", "path", "isfile", "fn", "and", "os", "access", "fn", "mode", "return", "fn", "return", "none"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 418}
{"url": "https://github.com/costastf/locationsharinglib/blob/dcd74b0cdb59b951345df84987238763e50ef282/_CI/library/core_library.py#L186-L206", "repo": "locationsharinglib", "func_name": "setup_logging", "original_string": ["            execfile(activation_file, dict(__file__=activation_file))\n", "\n", "\n", "def setup_logging(level):\n", "    try:\n", "        import coloredlogs\n", "        coloredlogs.install(level=level.upper())\n", "    except ImportError:\n", "        LOGGER = logging.getLogger()\n", "        handler = logging.StreamHandler()\n", "        handler.setLevel(level.upper())\n", "        formatter = logging.Formatter(('%(asctime)s - '\n", "                                       '%(name)s - '\n", "                                       '%(levelname)s - '\n", "                                       '%(message)s'))\n", "        handler.setFormatter(formatter)\n", "        LOGGER.addHandler(handler)\n", "        LOGGER.setLevel(level.upper())\n", "    for logger in LOGGERS_TO_DISABLE:\n", "        logging.getLogger(logger).disabled = True\n", "\n"], "language": "python", "code": "def setup_logging(level):\n    try:\n        import coloredlogs\n        coloredlogs.install(level=level.upper())\n    except ImportError:\n        LOGGER = logging.getLogger()\n        handler = logging.StreamHandler()\n        handler.setLevel(level.upper())\n        formatter = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        handler.setFormatter(formatter)\n        LOGGER.addHandler(handler)\n        LOGGER.setLevel(level.upper())\n    for logger in LOGGERS_TO_DISABLE:\n        logging.getLogger(logger).disabled = True\n", "code_tokens": ["setup", "logging", "level", "try", "import", "coloredlogs", "coloredlogs", "install", "level", "level", "upper", "except", "importerror", "logger", "logging", "getlogger", "handler", "logging", "streamhandler", "handler", "setlevel", "level", "upper", "formatter", "logging", "formatter", "asctime", "name", "levelname", "message", "handler", "setformatter", "formatter", "logger", "addhandler", "handler", "logger", "setlevel", "level", "upper", "for", "logger", "in", "loggers", "to", "disable", "logging", "getlogger", "logger", "disabled", "true"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 419}
{"url": "https://github.com/nikcub/paths/blob/2200b85273d07d7a3c8b15ceb3b03cbb5c11439a/paths/__init__.py#L85-L107", "repo": "paths", "func_name": "find_executable", "original_string": ["def find_executable(executable, path=None):\n", "  \"\"\"Tries to find 'executable' in the directories listed in 'path'.\n", "\n", "  A string listing directories separated by 'os.pathsep'; defaults to\n", "  os.environ['PATH'].  Returns the complete filename or None if not found.\n", "  \"\"\"\n", "  if path is None:\n", "    path = os.environ['PATH']\n", "  paths = path.split(os.pathsep)\n", "  base, ext = os.path.splitext(executable)\n", "\n", "  if (sys.platform == 'win32' or os.name == 'os2') and (ext != '.exe'):\n", "    executable = executable + '.exe'\n", "\n", "  if not os.path.isfile(executable):\n", "    for p in paths:\n", "      f = os.path.join(p, executable)\n", "      if os.path.isfile(f):\n", "        # the file exists, we have a shot at spawn working\n", "        return f\n", "    return None\n", "  else:\n", "    return executable\n"], "language": "python", "code": "def find_executable(executable, path=None):\n    \"\"\"\"\"\"\n    if path is None:\n        path = os.environ['PATH']\n    paths = path.split(os.pathsep)\n    base, ext = os.path.splitext(executable)\n    if (sys.platform == 'win32' or os.name == 'os2') and ext != '.exe':\n        executable = executable + '.exe'\n    if not os.path.isfile(executable):\n        for p in paths:\n            f = os.path.join(p, executable)\n            if os.path.isfile(f):\n                return f\n        return None\n    else:\n        return executable\n", "code_tokens": ["find", "executable", "executable", "path", "none", "if", "path", "is", "none", "path", "os", "environ", "path", "paths", "path", "split", "os", "pathsep", "base", "ext", "os", "path", "splitext", "executable", "if", "sys", "platform", "or", "os", "name", "and", "ext", "exe", "executable", "executable", "exe", "if", "not", "os", "path", "isfile", "executable", "for", "in", "paths", "os", "path", "join", "executable", "if", "os", "path", "isfile", "return", "return", "none", "else", "return", "executable"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 420}
{"url": "https://github.com/etcher-be/elib_run/blob/c9d8ba9f067ab90c5baa27375a92b23f1b97cdde/elib_run/_find_exe.py#L18-L62", "repo": "elib_run", "func_name": "find_executable", "original_string": ["def find_executable(executable: str, *paths: str) -> typing.Optional[Path]:\n", "    \"\"\"\n", "    Based on: https://gist.github.com/4368898\n", "\n", "    Public domain code by anatoly techtonik <techtonik@gmail.com>\n", "\n", "    Programmatic equivalent to Linux `which` and Windows `where`\n", "\n", "    Find if \u00b4executable\u00b4 can be run. Looks for it in 'path'\n", "    (string that lists directories separated by 'os.pathsep';\n", "    defaults to os.environ['PATH']). Checks for all executable\n", "    extensions. Returns full path or None if no command is found.\n", "\n", "    Args:\n", "        executable: executable name to look for\n", "        paths: root paths to examine (defaults to system PATH)\n", "\n", "    Returns: executable path as string or None\n", "\n", "    \"\"\"\n", "\n", "    if not executable.endswith('.exe'):\n", "        executable = f'{executable}.exe'\n", "\n", "    if executable in _KNOWN_EXECUTABLES:\n", "        return _KNOWN_EXECUTABLES[executable]\n", "\n", "    output = f'{executable}'\n", "\n", "    if not paths:\n", "        path = os.environ['PATH']\n", "        paths = tuple([str(Path(sys.exec_prefix, 'Scripts').absolute())] + path.split(os.pathsep))\n", "    executable_path = Path(executable).absolute()\n", "    if not executable_path.is_file():\n", "        for path_ in paths:\n", "            executable_path = Path(path_, executable).absolute()\n", "            if executable_path.is_file():\n", "                break\n", "        else:\n", "            _LOGGER.error('%s -> not found', output)\n", "            return None\n", "\n", "    _KNOWN_EXECUTABLES[executable] = executable_path\n", "    _LOGGER.info('%s -> %s', output, str(executable_path))\n", "    return executable_path\n"], "language": "python", "code": "def find_executable(executable: str, *paths: str) ->typing.Optional[Path]:\n    \"\"\"\"\"\"\n    if not executable.endswith('.exe'):\n        executable = f'{executable}.exe'\n    if executable in _KNOWN_EXECUTABLES:\n        return _KNOWN_EXECUTABLES[executable]\n    output = f'{executable}'\n    if not paths:\n        path = os.environ['PATH']\n        paths = tuple([str(Path(sys.exec_prefix, 'Scripts').absolute())] +\n            path.split(os.pathsep))\n    executable_path = Path(executable).absolute()\n    if not executable_path.is_file():\n        for path_ in paths:\n            executable_path = Path(path_, executable).absolute()\n            if executable_path.is_file():\n                break\n        else:\n            _LOGGER.error('%s -> not found', output)\n            return None\n    _KNOWN_EXECUTABLES[executable] = executable_path\n    _LOGGER.info('%s -> %s', output, str(executable_path))\n    return executable_path\n", "code_tokens": ["find", "executable", "executable", "str", "paths", "str", "typing", "optional", "path", "if", "not", "executable", "endswith", "exe", "executable", "executable", "exe", "if", "executable", "in", "known", "executables", "return", "known", "executables", "executable", "output", "executable", "if", "not", "paths", "path", "os", "environ", "path", "paths", "tuple", "str", "path", "sys", "exec", "prefix", "scripts", "absolute", "path", "split", "os", "pathsep", "executable", "path", "path", "executable", "absolute", "if", "not", "executable", "path", "is", "file", "for", "path", "in", "paths", "executable", "path", "path", "path", "executable", "absolute", "if", "executable", "path", "is", "file", "break", "else", "logger", "error", "not", "found", "output", "return", "none", "known", "executables", "executable", "executable", "path", "logger", "info", "output", "str", "executable", "path", "return", "executable", "path"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 421}
{"url": "https://github.com/ga4gh/ga4gh-common/blob/ea1b562dce5bf088ac4577b838cfac7745f08346/ga4gh/common/utils.py#L30-L40", "repo": "ga4gh-common", "func_name": "getPathOfExecutable", "original_string": ["def getPathOfExecutable(executable):\n", "    \"\"\"\n", "    Returns the full path of the executable, or None if the executable\n", "    can not be found.\n", "    \"\"\"\n", "    exe_paths = os.environ['PATH'].split(':')\n", "    for exe_path in exe_paths:\n", "        exe_file = os.path.join(exe_path, executable)\n", "        if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):\n", "            return exe_file\n", "    return None\n"], "language": "python", "code": "def getPathOfExecutable(executable):\n    \"\"\"\"\"\"\n    exe_paths = os.environ['PATH'].split(':')\n    for exe_path in exe_paths:\n        exe_file = os.path.join(exe_path, executable)\n        if os.path.isfile(exe_file) and os.access(exe_file, os.X_OK):\n            return exe_file\n    return None\n", "code_tokens": ["getpathofexecutable", "executable", "exe", "paths", "os", "environ", "path", "split", "for", "exe", "path", "in", "exe", "paths", "exe", "file", "os", "path", "join", "exe", "path", "executable", "if", "os", "path", "isfile", "exe", "file", "and", "os", "access", "exe", "file", "os", "ok", "return", "exe", "file", "return", "none"], "docstring": "get executable path", "docstring_tokens": ["get", "executable", "path"], "idx": 422}
{"url": "https://github.com/sods/paramz/blob/ae6fc6274b70fb723d91e48fc5026a9bc5a06508/paramz/optimization/scg.py#L44-L174", "repo": "paramz", "func_name": "SCG", "original_string": ["def SCG(f, gradf, x, optargs=(), maxiters=500, max_f_eval=np.inf, xtol=None, ftol=None, gtol=None):\n", "    \"\"\"\n", "    Optimisation through Scaled Conjugate Gradients (SCG)\n", "\n", "    f: the objective function\n", "    gradf : the gradient function (should return a 1D np.ndarray)\n", "    x : the initial condition\n", "\n", "    Returns\n", "    x the optimal value for x\n", "    flog : a list of all the objective values\n", "    function_eval number of fn evaluations\n", "    status: string describing convergence status\n", "    \"\"\"\n", "    if xtol is None:\n", "        xtol = 1e-6\n", "    if ftol is None:\n", "        ftol = 1e-6\n", "    if gtol is None:\n", "        gtol = 1e-5\n", "\n", "    sigma0 = 1.0e-7\n", "    fold = f(x, *optargs) # Initial function value.\n", "    function_eval = 1\n", "    fnow = fold\n", "    gradnew = gradf(x, *optargs) # Initial gradient.\n", "    function_eval += 1\n", "    #if any(np.isnan(gradnew)):\n", "    #    raise UnexpectedInfOrNan, \"Gradient contribution resulted in a NaN value\"\n", "    current_grad = np.dot(gradnew, gradnew)\n", "    gradold = gradnew.copy()\n", "    d = -gradnew # Initial search direction.\n", "    success = True # Force calculation of directional derivs.\n", "    nsuccess = 0 # nsuccess counts number of successes.\n", "    beta = 1.0 # Initial scale parameter.\n", "    betamin = 1.0e-15 # Lower bound on scale.\n", "    betamax = 1.0e15 # Upper bound on scale.\n", "    status = \"Not converged\"\n", "\n", "    flog = [fold]\n", "\n", "    iteration = 0\n", "\n", "    # Main optimization loop.\n", "    while iteration < maxiters:\n", "\n", "        # Calculate first and second directional derivatives.\n", "        if success:\n", "            mu = np.dot(d, gradnew)\n", "            if mu >= 0:  # pragma: no cover\n", "                d = -gradnew\n", "                mu = np.dot(d, gradnew)\n", "            kappa = np.dot(d, d)\n", "            sigma = sigma0 / np.sqrt(kappa)\n", "            xplus = x + sigma * d\n", "            gplus = gradf(xplus, *optargs)\n", "            function_eval += 1\n", "            theta = np.dot(d, (gplus - gradnew)) / sigma\n", "\n", "        # Increase effective curvature and evaluate step size alpha.\n", "        delta = theta + beta * kappa\n", "        if delta <= 0: # pragma: no cover\n", "            delta = beta * kappa\n", "            beta = beta - theta / kappa\n", "\n", "        alpha = -mu / delta\n", "\n", "        # Calculate the comparison ratio.\n", "        xnew = x + alpha * d\n", "        fnew = f(xnew, *optargs)\n", "        function_eval += 1\n", "\n", "        Delta = 2.*(fnew - fold) / (alpha * mu)\n", "        if Delta >= 0.:\n", "            success = True\n", "            nsuccess += 1\n", "            x = xnew\n", "            fnow = fnew\n", "        else:\n", "            success = False\n", "            fnow = fold\n", "\n", "        # Store relevant variables\n", "        flog.append(fnow) # Current function value\n", "\n", "        iteration += 1\n", "\n", "        if success:\n", "            # Test for termination\n", "\n", "            if (np.abs(fnew - fold) < ftol):\n", "                status = 'converged - relative reduction in objective'\n", "                break\n", "#                 return x, flog, function_eval, status\n", "            elif (np.max(np.abs(alpha * d)) < xtol):\n", "                status = 'converged - relative stepsize'\n", "                break\n", "            else:\n", "                # Update variables for new position\n", "                gradold = gradnew\n", "                gradnew = gradf(x, *optargs)\n", "                function_eval += 1\n", "                current_grad = np.dot(gradnew, gradnew)\n", "                fold = fnew\n", "                # If the gradient is zero then we are done.\n", "                if current_grad <= gtol:\n", "                    status = 'converged - relative reduction in gradient'\n", "                    break\n", "                    # return x, flog, function_eval, status\n", "\n", "        # Adjust beta according to comparison ratio.\n", "        if Delta < 0.25:\n", "            beta = min(4.0 * beta, betamax)\n", "        if Delta > 0.75:\n", "            beta = max(0.25 * beta, betamin)\n", "\n", "        # Update search direction using Polak-Ribiere formula, or re-start\n", "        # in direction of negative gradient after nparams steps.\n", "        if nsuccess == x.size:\n", "            d = -gradnew\n", "            beta = 1. # This is not in the original paper\n", "            nsuccess = 0\n", "        elif success:\n", "            Gamma = np.dot(gradold - gradnew, gradnew) / (mu)\n", "            d = Gamma * d - gradnew\n", "    else:\n", "        # If we get here, then we haven't terminated in the given number of\n", "        # iterations.\n", "        status = \"maxiter exceeded\"\n", "\n", "    return x, flog, function_eval, status\n"], "language": "python", "code": "def SCG(f, gradf, x, optargs=(), maxiters=500, max_f_eval=np.inf, xtol=None,\n    ftol=None, gtol=None):\n    \"\"\"\"\"\"\n    if xtol is None:\n        xtol = 1e-06\n    if ftol is None:\n        ftol = 1e-06\n    if gtol is None:\n        gtol = 1e-05\n    sigma0 = 1e-07\n    fold = f(x, *optargs)\n    function_eval = 1\n    fnow = fold\n    gradnew = gradf(x, *optargs)\n    function_eval += 1\n    current_grad = np.dot(gradnew, gradnew)\n    gradold = gradnew.copy()\n    d = -gradnew\n    success = True\n    nsuccess = 0\n    beta = 1.0\n    betamin = 1e-15\n    betamax = 1000000000000000.0\n    status = 'Not converged'\n    flog = [fold]\n    iteration = 0\n    while iteration < maxiters:\n        if success:\n            mu = np.dot(d, gradnew)\n            if mu >= 0:\n                d = -gradnew\n                mu = np.dot(d, gradnew)\n            kappa = np.dot(d, d)\n            sigma = sigma0 / np.sqrt(kappa)\n            xplus = x + sigma * d\n            gplus = gradf(xplus, *optargs)\n            function_eval += 1\n            theta = np.dot(d, gplus - gradnew) / sigma\n        delta = theta + beta * kappa\n        if delta <= 0:\n            delta = beta * kappa\n            beta = beta - theta / kappa\n        alpha = -mu / delta\n        xnew = x + alpha * d\n        fnew = f(xnew, *optargs)\n        function_eval += 1\n        Delta = 2.0 * (fnew - fold) / (alpha * mu)\n        if Delta >= 0.0:\n            success = True\n            nsuccess += 1\n            x = xnew\n            fnow = fnew\n        else:\n            success = False\n            fnow = fold\n        flog.append(fnow)\n        iteration += 1\n        if success:\n            if np.abs(fnew - fold) < ftol:\n                status = 'converged - relative reduction in objective'\n                break\n            elif np.max(np.abs(alpha * d)) < xtol:\n                status = 'converged - relative stepsize'\n                break\n            else:\n                gradold = gradnew\n                gradnew = gradf(x, *optargs)\n                function_eval += 1\n                current_grad = np.dot(gradnew, gradnew)\n                fold = fnew\n                if current_grad <= gtol:\n                    status = 'converged - relative reduction in gradient'\n                    break\n        if Delta < 0.25:\n            beta = min(4.0 * beta, betamax)\n        if Delta > 0.75:\n            beta = max(0.25 * beta, betamin)\n        if nsuccess == x.size:\n            d = -gradnew\n            beta = 1.0\n            nsuccess = 0\n        elif success:\n            Gamma = np.dot(gradold - gradnew, gradnew) / mu\n            d = Gamma * d - gradnew\n    else:\n        status = 'maxiter exceeded'\n    return x, flog, function_eval, status\n", "code_tokens": ["scg", "gradf", "optargs", "maxiters", "500", "max", "eval", "np", "inf", "xtol", "none", "ftol", "none", "gtol", "none", "if", "xtol", "is", "none", "xtol", "06", "if", "ftol", "is", "none", "ftol", "06", "if", "gtol", "is", "none", "gtol", "05", "07", "fold", "optargs", "function", "eval", "1", "fnow", "fold", "gradnew", "gradf", "optargs", "function", "eval", "1", "current", "grad", "np", "dot", "gradnew", "gradnew", "gradold", "gradnew", "copy", "gradnew", "success", "true", "nsuccess", "0", "beta", "1", "0", "betamin", "15", "betamax", "1000000000000000", "0", "status", "not", "converged", "flog", "fold", "iteration", "0", "while", "iteration", "maxiters", "if", "success", "mu", "np", "dot", "gradnew", "if", "mu", "0", "gradnew", "mu", "np", "dot", "gradnew", "kappa", "np", "dot", "sigma", "np", "sqrt", "kappa", "xplus", "sigma", "gplus", "gradf", "xplus", "optargs", "function", "eval", "1", "theta", "np", "dot", "gplus", "gradnew", "sigma", "delta", "theta", "beta", "kappa", "if", "delta", "0", "delta", "beta", "kappa", "beta", "beta", "theta", "kappa", "alpha", "mu", "delta", "xnew", "alpha", "fnew", "xnew", "optargs", "function", "eval", "1", "delta", "2", "0", "fnew", "fold", "alpha", "mu", "if", "delta", "0", "0", "success", "true", "nsuccess", "1", "xnew", "fnow", "fnew", "else", "success", "false", "fnow", "fold", "flog", "append", "fnow", "iteration", "1", "if", "success", "if", "np", "abs", "fnew", "fold", "ftol", "status", "converged", "relative", "reduction", "in", "objective", "break", "elif", "np", "max", "np", "abs", "alpha", "xtol", "status", "converged", "relative", "stepsize", "break", "else", "gradold", "gradnew", "gradnew", "gradf", "optargs", "function", "eval", "1", "current", "grad", "np", "dot", "gradnew", "gradnew", "fold", "fnew", "if", "current", "grad", "gtol", "status", "converged", "relative", "reduction", "in", "gradient", "break", "if", "delta", "0", "25", "beta", "min", "4", "0", "beta", "betamax", "if", "delta", "0", "75", "beta", "max", "0", "25", "beta", "betamin", "if", "nsuccess", "size", "gradnew", "beta", "1", "0", "nsuccess", "0", "elif", "success", "gamma", "np", "dot", "gradold", "gradnew", "gradnew", "mu", "gamma", "gradnew", "else", "status", "maxiter", "exceeded", "return", "flog", "function", "eval", "status"], "docstring": "nelder mead optimize", "docstring_tokens": ["nelder", "mead", "optimize"], "idx": 423}
{"url": "https://github.com/SheffieldML/GPyOpt/blob/255539dc5927819ca701e44fe3d76cd4864222fa/GPyOpt/optimization/optimizer.py#L36-L61", "repo": "GPyOpt", "func_name": "optimize", "original_string": ["    def optimize(self, x0, f=None, df=None, f_df=None):\n", "        \"\"\"\n", "        :param x0: initial point for a local optimizer.\n", "        :param f: function to optimize.\n", "        :param df: gradient of the function to optimize.\n", "        :param f_df: returns both the function to optimize and its gradient.\n", "        \"\"\"\n", "        import scipy.optimize\n", "        if f_df is None and df is not None: f_df = lambda x: float(f(x)), df(x)\n", "        if f_df is not None:\n", "            def _f_df(x):\n", "                return f(x), f_df(x)[1][0]\n", "        if f_df is None and df is None:\n", "            res = scipy.optimize.fmin_l_bfgs_b(f, x0=x0, bounds=self.bounds,approx_grad=True, maxiter=self.maxiter)\n", "        else:\n", "            res = scipy.optimize.fmin_l_bfgs_b(_f_df, x0=x0, bounds=self.bounds, maxiter=self.maxiter)\n", "\n", "        ### --- We check here if the the optimizer moved. If it didn't we report x0 and f(x0) as scipy can return NaNs\n", "        if res[2]['task'] == b'ABNORMAL_TERMINATION_IN_LNSRCH':\n", "            result_x  = np.atleast_2d(x0)\n", "            result_fx =  np.atleast_2d(f(x0))\n", "        else:\n", "            result_x = np.atleast_2d(res[0])\n", "            result_fx = np.atleast_2d(res[1])\n", "\n", "        return result_x, result_fx\n"], "language": "python", "code": "def optimize(self, x0, f=None, df=None, f_df=None):\n    \"\"\"\"\"\"\n    import scipy.optimize\n    if f_df is None and df is not None:\n        f_df = lambda x: float(f(x)), df(x)\n    if f_df is not None:\n\n        def _f_df(x):\n            return f(x), f_df(x)[1][0]\n    if f_df is None and df is None:\n        res = scipy.optimize.fmin_l_bfgs_b(f, x0=x0, bounds=self.bounds,\n            approx_grad=True, maxiter=self.maxiter)\n    else:\n        res = scipy.optimize.fmin_l_bfgs_b(_f_df, x0=x0, bounds=self.bounds,\n            maxiter=self.maxiter)\n    if res[2]['task'] == b'ABNORMAL_TERMINATION_IN_LNSRCH':\n        result_x = np.atleast_2d(x0)\n        result_fx = np.atleast_2d(f(x0))\n    else:\n        result_x = np.atleast_2d(res[0])\n        result_fx = np.atleast_2d(res[1])\n    return result_x, result_fx\n", "code_tokens": ["optimize", "self", "none", "df", "none", "df", "none", "import", "scipy", "optimize", "if", "df", "is", "none", "and", "df", "is", "not", "none", "df", "lambda", "float", "df", "if", "df", "is", "not", "none", "def", "df", "return", "df", "1", "0", "if", "df", "is", "none", "and", "df", "is", "none", "res", "scipy", "optimize", "fmin", "bfgs", "bounds", "self", "bounds", "approx", "grad", "true", "maxiter", "self", "maxiter", "else", "res", "scipy", "optimize", "fmin", "bfgs", "df", "bounds", "self", "bounds", "maxiter", "self", "maxiter", "if", "res", "2", "task", "abnormal", "termination", "in", "lnsrch", "result", "np", "atleast", "result", "fx", "np", "atleast", "else", "result", "np", "atleast", "res", "0", "result", "fx", "np", "atleast", "res", "1", "return", "result", "result", "fx"], "docstring": "nelder mead optimize", "docstring_tokens": ["nelder", "mead", "optimize"], "idx": 424}
{"url": "https://github.com/SheffieldML/GPyOpt/blob/255539dc5927819ca701e44fe3d76cd4864222fa/GPyOpt/util/epmgp.py#L122-L208", "repo": "GPyOpt", "func_name": "min_faktor", "original_string": ["def min_faktor(Mu, Sigma, k, gamma=1):\n", "\n", "    D = Mu.shape[0]\n", "    logS = np.zeros((D - 1,))\n", "    # mean time first moment\n", "    MP = np.zeros((D - 1,))\n", "\n", "    # precision, second moment\n", "    P = np.zeros((D - 1,))\n", "\n", "    M = np.copy(Mu)\n", "    V = np.copy(Sigma)\n", "    b = False\n", "    d = np.NaN\n", "    for count in range(50):\n", "        diff = 0\n", "        for i in range(D - 1):\n", "            l = i if  i < k else i + 1\n", "            try:\n", "                M, V, P[i], MP[i], logS[i], d = lt_factor(k, l, M, V,\n", "                                                        MP[i], P[i], gamma)\n", "            except Exception as e:\n", "                raise\n", "\n", "            if np.isnan(d):\n", "                break\n", "            diff += np.abs(d)\n", "        if np.isnan(d):\n", "            break\n", "        if np.abs(diff) < 0.001:\n", "            b = True\n", "            break\n", "    if np.isnan(d):\n", "        logZ = -np.Infinity\n", "        yield logZ\n", "        dlogZdMu = np.zeros((D, 1))\n", "        yield dlogZdMu\n", "\n", "        dlogZdMudMu = np.zeros((D, D))\n", "        yield dlogZdMudMu\n", "        dlogZdSigma = np.zeros((int(0.5 * (D * (D + 1))), 1))\n", "        yield dlogZdSigma\n", "        mvmin = [Mu[k], Sigma[k, k]]\n", "        yield mvmin\n", "    else:\n", "        # evaluate log Z:\n", "        C = np.eye(D) / sq2\n", "        C[k, :] = -1 / sq2\n", "        C = np.delete(C, k, 1)\n", "\n", "        R = np.sqrt(P.T) * C\n", "        r = np.sum(MP.T * C, 1)\n", "        mp_not_zero = np.where(MP != 0)\n", "        mpm = MP[mp_not_zero] * MP[mp_not_zero] / P[mp_not_zero]\n", "        mpm = sum(mpm)\n", "\n", "        s = sum(logS)\n", "        IRSR = (np.eye(D - 1) + np.dot(np.dot(R.T, Sigma), R))\n", "        rSr = np.dot(np.dot(r.T, Sigma), r)\n", "        A = np.dot(R, np.linalg.solve(IRSR, R.T))\n", "\n", "        A = 0.5 * (A.T + A)  # ensure symmetry.\n", "        b = (Mu + np.dot(Sigma, r))\n", "        Ab = np.dot(A, b)\n", "        try:\n", "            cIRSR = np.linalg.cholesky(IRSR)\n", "        except np.linalg.LinAlgError:\n", "            try:\n", "                cIRSR = np.linalg.cholesky(IRSR + 1e-10 * np.eye(IRSR.shape[0]))\n", "            except np.linalg.LinAlgError:\n", "                cIRSR = np.linalg.cholesky(IRSR + 1e-6 * np.eye(IRSR.shape[0]))\n", "        dts = 2 * np.sum(np.log(np.diagonal(cIRSR)))\n", "        logZ = 0.5 * (rSr - np.dot(b.T, Ab) - dts) + np.dot(Mu.T, r) + s - 0.5 * mpm\n", "        yield logZ\n", "        btA = np.dot(b.T, A)\n", "\n", "        dlogZdMu = r - Ab\n", "        yield dlogZdMu\n", "        dlogZdMudMu = -A\n", "        yield dlogZdMudMu\n", "        dlogZdSigma = -A - 2 * np.outer(r, Ab.T) + np.outer(r, r.T)\\\n", "                    + np.outer(btA.T, Ab.T)\n", "        dlogZdSigma2 = np.zeros_like(dlogZdSigma)\n", "        np.fill_diagonal(dlogZdSigma2, np.diagonal(dlogZdSigma))\n", "        dlogZdSigma = 0.5 * (dlogZdSigma + dlogZdSigma.T - dlogZdSigma2)\n", "        dlogZdSigma = np.rot90(dlogZdSigma, k=2)[np.triu_indices(D)][::-1]\n", "        yield dlogZdSigma\n"], "language": "python", "code": "def min_faktor(Mu, Sigma, k, gamma=1):\n    D = Mu.shape[0]\n    logS = np.zeros((D - 1,))\n    MP = np.zeros((D - 1,))\n    P = np.zeros((D - 1,))\n    M = np.copy(Mu)\n    V = np.copy(Sigma)\n    b = False\n    d = np.NaN\n    for count in range(50):\n        diff = 0\n        for i in range(D - 1):\n            l = i if i < k else i + 1\n            try:\n                M, V, P[i], MP[i], logS[i], d = lt_factor(k, l, M, V, MP[i],\n                    P[i], gamma)\n            except Exception as e:\n                raise\n            if np.isnan(d):\n                break\n            diff += np.abs(d)\n        if np.isnan(d):\n            break\n        if np.abs(diff) < 0.001:\n            b = True\n            break\n    if np.isnan(d):\n        logZ = -np.Infinity\n        yield logZ\n        dlogZdMu = np.zeros((D, 1))\n        yield dlogZdMu\n        dlogZdMudMu = np.zeros((D, D))\n        yield dlogZdMudMu\n        dlogZdSigma = np.zeros((int(0.5 * (D * (D + 1))), 1))\n        yield dlogZdSigma\n        mvmin = [Mu[k], Sigma[k, k]]\n        yield mvmin\n    else:\n        C = np.eye(D) / sq2\n        C[k, :] = -1 / sq2\n        C = np.delete(C, k, 1)\n        R = np.sqrt(P.T) * C\n        r = np.sum(MP.T * C, 1)\n        mp_not_zero = np.where(MP != 0)\n        mpm = MP[mp_not_zero] * MP[mp_not_zero] / P[mp_not_zero]\n        mpm = sum(mpm)\n        s = sum(logS)\n        IRSR = np.eye(D - 1) + np.dot(np.dot(R.T, Sigma), R)\n        rSr = np.dot(np.dot(r.T, Sigma), r)\n        A = np.dot(R, np.linalg.solve(IRSR, R.T))\n        A = 0.5 * (A.T + A)\n        b = Mu + np.dot(Sigma, r)\n        Ab = np.dot(A, b)\n        try:\n            cIRSR = np.linalg.cholesky(IRSR)\n        except np.linalg.LinAlgError:\n            try:\n                cIRSR = np.linalg.cholesky(IRSR + 1e-10 * np.eye(IRSR.shape[0])\n                    )\n            except np.linalg.LinAlgError:\n                cIRSR = np.linalg.cholesky(IRSR + 1e-06 * np.eye(IRSR.shape[0])\n                    )\n        dts = 2 * np.sum(np.log(np.diagonal(cIRSR)))\n        logZ = 0.5 * (rSr - np.dot(b.T, Ab) - dts) + np.dot(Mu.T, r\n            ) + s - 0.5 * mpm\n        yield logZ\n        btA = np.dot(b.T, A)\n        dlogZdMu = r - Ab\n        yield dlogZdMu\n        dlogZdMudMu = -A\n        yield dlogZdMudMu\n        dlogZdSigma = -A - 2 * np.outer(r, Ab.T) + np.outer(r, r.T) + np.outer(\n            btA.T, Ab.T)\n        dlogZdSigma2 = np.zeros_like(dlogZdSigma)\n        np.fill_diagonal(dlogZdSigma2, np.diagonal(dlogZdSigma))\n        dlogZdSigma = 0.5 * (dlogZdSigma + dlogZdSigma.T - dlogZdSigma2)\n        dlogZdSigma = np.rot90(dlogZdSigma, k=2)[np.triu_indices(D)][::-1]\n        yield dlogZdSigma\n", "code_tokens": ["min", "faktor", "mu", "sigma", "gamma", "1", "mu", "shape", "0", "logs", "np", "zeros", "1", "mp", "np", "zeros", "1", "np", "zeros", "1", "np", "copy", "mu", "np", "copy", "sigma", "false", "np", "nan", "for", "count", "in", "range", "50", "diff", "0", "for", "in", "range", "1", "if", "else", "1", "try", "mp", "logs", "lt", "factor", "mp", "gamma", "except", "exception", "as", "raise", "if", "np", "isnan", "break", "diff", "np", "abs", "if", "np", "isnan", "break", "if", "np", "abs", "diff", "0", "001", "true", "break", "if", "np", "isnan", "logz", "np", "infinity", "yield", "logz", "dlogzdmu", "np", "zeros", "1", "yield", "dlogzdmu", "dlogzdmudmu", "np", "zeros", "yield", "dlogzdmudmu", "dlogzdsigma", "np", "zeros", "int", "0", "5", "1", "1", "yield", "dlogzdsigma", "mvmin", "mu", "sigma", "yield", "mvmin", "else", "np", "eye", "1", "np", "delete", "1", "np", "sqrt", "np", "sum", "mp", "1", "mp", "not", "zero", "np", "where", "mp", "0", "mpm", "mp", "mp", "not", "zero", "mp", "mp", "not", "zero", "mp", "not", "zero", "mpm", "sum", "mpm", "sum", "logs", "irsr", "np", "eye", "1", "np", "dot", "np", "dot", "sigma", "rsr", "np", "dot", "np", "dot", "sigma", "np", "dot", "np", "linalg", "solve", "irsr", "0", "5", "mu", "np", "dot", "sigma", "ab", "np", "dot", "try", "cirsr", "np", "linalg", "cholesky", "irsr", "except", "np", "linalg", "linalgerror", "try", "cirsr", "np", "linalg", "cholesky", "irsr", "10", "np", "eye", "irsr", "shape", "0", "except", "np", "linalg", "linalgerror", "cirsr", "np", "linalg", "cholesky", "irsr", "06", "np", "eye", "irsr", "shape", "0", "dts", "2", "np", "sum", "np", "log", "np", "diagonal", "cirsr", "logz", "0", "5", "rsr", "np", "dot", "ab", "dts", "np", "dot", "mu", "0", "5", "mpm", "yield", "logz", "bta", "np", "dot", "dlogzdmu", "ab", "yield", "dlogzdmu", "dlogzdmudmu", "yield", "dlogzdmudmu", "dlogzdsigma", "2", "np", "outer", "ab", "np", "outer", "np", "outer", "bta", "ab", "np", "zeros", "like", "dlogzdsigma", "np", "fill", "diagonal", "np", "diagonal", "dlogzdsigma", "dlogzdsigma", "0", "5", "dlogzdsigma", "dlogzdsigma", "dlogzdsigma", "np", "dlogzdsigma", "2", "np", "triu", "indices", "1", "yield", "dlogzdsigma"], "docstring": "nelder mead optimize", "docstring_tokens": ["nelder", "mead", "optimize"], "idx": 425}
{"url": "https://github.com/horejsek/python-webdriverwrapper/blob/a492f79ab60ed83d860dd817b6a0961500d7e3f5/webdriverwrapper/forms.py#L133-L138", "repo": "python-webdriverwrapper", "func_name": "fill_input_radio", "original_string": ["    def fill_input_radio(self, value, skip_reset=False):\n", "        elm = self.form_elm.get_elm(xpath='//input[@type=\"radio\"][@name=\"%s\"][@value=\"%s\"]' % (\n", "            self.elm_name,\n", "            self.convert_value(value),\n", "        ))\n", "        self._click_on_elm_or_his_ancestor(elm)\n"], "language": "python", "code": "def fill_input_radio(self, value, skip_reset=False):\n    elm = self.form_elm.get_elm(xpath=\n        '//input[@type=\"radio\"][@name=\"%s\"][@value=\"%s\"]' % (self.elm_name,\n        self.convert_value(value)))\n    self._click_on_elm_or_his_ancestor(elm)\n", "code_tokens": ["fill", "input", "radio", "self", "value", "skip", "reset", "false", "elm", "self", "form", "elm", "get", "elm", "xpath", "input", "type", "radio", "name", "value", "self", "elm", "name", "self", "convert", "value", "value", "self", "click", "on", "elm", "or", "his", "ancestor", "elm"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 426}
{"url": "https://github.com/usc-isi-i2/etk/blob/aab077c984ea20f5e8ae33af622fe11d3c4df866/etk/extractors/readability/htmls.py#L106-L116", "repo": "etk", "func_name": "get_body", "original_string": ["def get_body(doc):\n", "    [ elem.drop_tree() for elem in doc.xpath('.//script | .//link | .//style') ]\n", "    raw_html = tostring(doc.body or doc).decode(\"utf-8\")\n", "    print(raw_html)\n", "    cleaned = clean_attributes(raw_html)\n", "    try:\n", "        #BeautifulSoup(cleaned) #FIXME do we really need to try loading it?\n", "        return cleaned\n", "    except Exception: #FIXME find the equivalent lxml error\n", "        #logging.error(\"cleansing broke html content: %s\\n---------\\n%s\" % (raw_html, cleaned))\n", "        return raw_html\n"], "language": "python", "code": "def get_body(doc):\n    [elem.drop_tree() for elem in doc.xpath('.//script | .//link | .//style')]\n    raw_html = tostring(doc.body or doc).decode('utf-8')\n    print(raw_html)\n    cleaned = clean_attributes(raw_html)\n    try:\n        return cleaned\n    except Exception:\n        return raw_html\n", "code_tokens": ["get", "body", "doc", "elem", "drop", "tree", "for", "elem", "in", "doc", "xpath", "script", "link", "style", "raw", "html", "tostring", "doc", "body", "or", "doc", "decode", "utf", "8", "print", "raw", "html", "cleaned", "clean", "attributes", "raw", "html", "try", "return", "cleaned", "except", "exception", "return", "raw", "html"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 427}
{"url": "https://github.com/katerina7479/pypdflite/blob/ac2501f30d6619eae9dea5644717575ca9263d0a/pypdflite/pdfobjects/pdfhtml.py#L407-L410", "repo": "pypdflite", "func_name": "_parsehtml", "original_string": ["    def _parsehtml(self):\n", "        parser = PDFHTMLParser()\n", "        parser.feed(self.htmltext)\n", "        self.commandlist = parser.get_commandlist()\n"], "language": "python", "code": "def _parsehtml(self):\n    parser = PDFHTMLParser()\n    parser.feed(self.htmltext)\n    self.commandlist = parser.get_commandlist()\n", "code_tokens": ["parsehtml", "self", "parser", "pdfhtmlparser", "parser", "feed", "self", "htmltext", "self", "commandlist", "parser", "get", "commandlist"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 428}
{"url": "https://github.com/lsst-epo/vela/blob/8e17ebec509be5c3cc2063f4645dfe9e26b49c18/astropixie-widgets/astropixie_widgets/visual.py#L39-L53", "repo": "vela", "func_name": "_telescope_pointing_widget", "original_string": ["def _telescope_pointing_widget(cluster_name):\n", "    html = '<table><thead><tr>'\n", "    html += '<td><b>Telescope pointing</b></td>'\n", "    html += '<td><b>Cluster Name</b></td>'\n", "    html += '<td><b>Image number</b></td>'\n", "    html += '<td><b>Right ascension</b></td>'\n", "    html += '<td><b>Declination</b></td>'\n", "    html += '</tr></thead><tbody><tr>'\n", "    html += '<td><img src=\"http://assets.lsst.rocks/data/sphere.png\"></td>'\n", "    html += '<td>%s</td>' % cluster_name\n", "    html += '<td>20221274993</td>'\n", "    html += '<td>05h 32m 37s</td>'\n", "    html += '<td>+00h 11m 18s</td>'\n", "    html += '</tr></tbody></table>'\n", "    return Div(text=html, width=600, height=175)\n"], "language": "python", "code": "def _telescope_pointing_widget(cluster_name):\n    html = '<table><thead><tr>'\n    html += '<td><b>Telescope pointing</b></td>'\n    html += '<td><b>Cluster Name</b></td>'\n    html += '<td><b>Image number</b></td>'\n    html += '<td><b>Right ascension</b></td>'\n    html += '<td><b>Declination</b></td>'\n    html += '</tr></thead><tbody><tr>'\n    html += '<td><img src=\"http://assets.lsst.rocks/data/sphere.png\"></td>'\n    html += '<td>%s</td>' % cluster_name\n    html += '<td>20221274993</td>'\n    html += '<td>05h 32m 37s</td>'\n    html += '<td>+00h 11m 18s</td>'\n    html += '</tr></tbody></table>'\n    return Div(text=html, width=600, height=175)\n", "code_tokens": ["telescope", "pointing", "widget", "cluster", "name", "html", "table", "thead", "tr", "html", "td", "telescope", "pointing", "td", "html", "td", "cluster", "name", "td", "html", "td", "image", "number", "td", "html", "td", "right", "ascension", "td", "html", "td", "declination", "td", "html", "tr", "thead", "tbody", "tr", "html", "td", "img", "src", "http", "assets", "lsst", "rocks", "data", "sphere", "png", "td", "html", "td", "td", "cluster", "name", "html", "td", "20221274993", "td", "html", "td", "td", "html", "td", "td", "html", "tr", "tbody", "table", "return", "div", "text", "html", "width", "600", "height", "175"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 429}
{"url": "https://github.com/toomore/goristock/blob/e61f57f11a626cfbc4afbf66337fd9d1c51e3e71/grs/mobileapi.py#L38-L72", "repo": "goristock", "func_name": "output", "original_string": ["  def output(self):\n", "    #re = \"{%(time)s} %(name)s %(stock_no)s %(c)s %(range)+.2f(%(pp)+.2f%%) %(value)s\" % {\n", "    '''\n", "    re = \"\"\"<table>\n", "            <tr><td>%(name)s</td><td>%(c)s</td><td>%(range)+.2f(%(pp)+.2f%%)</td></tr>\n", "            <tr><td>%(stock_no)s</td><td>%(value)s</td><td>%(time)s</td></tr></table>\"\"\" % {\n", "    '''\n", "    if covstr(self.g['range']) > 0:\n", "      css = \"red\"\n", "    elif covstr(self.g['range']) < 0:\n", "      css = \"green\"\n", "    else:\n", "      css = \"gray\"\n", "\n", "    re = {\n", "      'name': self.g['name'],\n", "      'stock_no': self.g['no'],\n", "      'time': self.g['time'],\n", "      'open': self.g['open'],\n", "      'h': self.g['h'],\n", "      'l': self.g['l'],\n", "      'c': self.g['c'],\n", "      'max': self.g['max'],\n", "      'min': self.g['min'],\n", "      'range': covstr(self.g['range']),\n", "      'ranges': self.g['ranges'],\n", "      'value': self.g['value'],\n", "      'pvalue': self.g['pvalue'],\n", "      'pp': covstr(self.g['pp']),\n", "      'top5buy': self.g['top5buy'],\n", "      'top5sell': self.g['top5sell'],\n", "      'crosspic': self.g['crosspic'],\n", "      'css': css\n", "    }\n", "    return re\n"], "language": "python", "code": "def output(self):\n    \"\"\"\n    re = \"\"\\\"<table>\n            <tr><td>%(name)s</td><td>%(c)s</td><td>%(range)+.2f(%(pp)+.2f%%)</td></tr>\n            <tr><td>%(stock_no)s</td><td>%(value)s</td><td>%(time)s</td></tr></table>\"\"\\\" % {\n    \"\"\"\n    if covstr(self.g['range']) > 0:\n        css = 'red'\n    elif covstr(self.g['range']) < 0:\n        css = 'green'\n    else:\n        css = 'gray'\n    re = {'name': self.g['name'], 'stock_no': self.g['no'], 'time': self.g[\n        'time'], 'open': self.g['open'], 'h': self.g['h'], 'l': self.g['l'],\n        'c': self.g['c'], 'max': self.g['max'], 'min': self.g['min'],\n        'range': covstr(self.g['range']), 'ranges': self.g['ranges'],\n        'value': self.g['value'], 'pvalue': self.g['pvalue'], 'pp': covstr(\n        self.g['pp']), 'top5buy': self.g['top5buy'], 'top5sell': self.g[\n        'top5sell'], 'crosspic': self.g['crosspic'], 'css': css}\n    return re\n", "code_tokens": ["output", "self", "re", "table", "tr", "td", "name", "td", "td", "td", "td", "range", "pp", "td", "tr", "tr", "td", "stock", "no", "td", "td", "value", "td", "td", "time", "td", "tr", "table", "if", "covstr", "self", "range", "0", "css", "red", "elif", "covstr", "self", "range", "0", "css", "green", "else", "css", "gray", "re", "name", "self", "name", "stock", "no", "self", "no", "time", "self", "time", "open", "self", "open", "self", "self", "self", "max", "self", "max", "min", "self", "min", "range", "covstr", "self", "range", "ranges", "self", "ranges", "value", "self", "value", "pvalue", "self", "pvalue", "pp", "covstr", "self", "pp", "self", "self", "crosspic", "self", "crosspic", "css", "css", "return", "re"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 430}
{"url": "https://github.com/danidee10/Staticfy/blob/ebc555b00377394b0f714e4a173d37833fec90cb/staticfy/staticfy.py#L71-L89", "repo": "Staticfy", "func_name": "get_elements", "original_string": ["def get_elements(html_file, tags):\n", "    \"\"\"\n", "    Extract all the elements we're interested in.\n", "\n", "    Returns a list of tuples with the attribute as first item\n", "    and the list of elements as the second item.\n", "    \"\"\"\n", "    with open(html_file) as f:\n", "        document = BeautifulSoup(f, 'html.parser')\n", "\n", "        def condition(tag, attr):\n", "            # Don't include external links\n", "            return lambda x: x.name == tag \\\n", "                and not x.get(attr, 'http').startswith(('http', '//'))\n", "\n", "        all_tags = [(attr, document.find_all(condition(tag, attr)))\n", "                    for tag, attr in tags]\n", "\n", "        return all_tags\n"], "language": "python", "code": "def get_elements(html_file, tags):\n    \"\"\"\"\"\"\n    with open(html_file) as f:\n        document = BeautifulSoup(f, 'html.parser')\n\n        def condition(tag, attr):\n            return lambda x: x.name == tag and not x.get(attr, 'http'\n                ).startswith(('http', '//'))\n        all_tags = [(attr, document.find_all(condition(tag, attr))) for tag,\n            attr in tags]\n        return all_tags\n", "code_tokens": ["get", "elements", "html", "file", "tags", "with", "open", "html", "file", "as", "document", "beautifulsoup", "html", "parser", "def", "condition", "tag", "attr", "return", "lambda", "name", "tag", "and", "not", "get", "attr", "http", "startswith", "http", "all", "tags", "attr", "document", "find", "all", "condition", "tag", "attr", "for", "tag", "attr", "in", "tags", "return", "all", "tags"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 431}
{"url": "https://github.com/alvinwan/md2py/blob/7f28a008367d7d9b5b3c8bbf7baf17985271489f/md2py/md2py.py#L140-L150", "repo": "md2py", "func_name": "fromHTML", "original_string": ["    def fromHTML(html, *args, **kwargs):\n", "        \"\"\"\n", "        Creates abstraction using HTML\n", "\n", "        :param str html: HTML\n", "        :return: TreeOfContents object\n", "        \"\"\"\n", "        source = BeautifulSoup(html, 'html.parser', *args, **kwargs)\n", "        return TOC('[document]',\n", "            source=source,\n", "            descendants=source.children)\n"], "language": "python", "code": "def fromHTML(html, *args, **kwargs):\n    \"\"\"\"\"\"\n    source = BeautifulSoup(html, 'html.parser', *args, **kwargs)\n    return TOC('[document]', source=source, descendants=source.children)\n", "code_tokens": ["fromhtml", "html", "args", "kwargs", "source", "beautifulsoup", "html", "html", "parser", "args", "kwargs", "return", "toc", "document", "source", "source", "descendants", "source", "children"], "docstring": "reading element from html - <td>", "docstring_tokens": ["reading", "element", "from", "html", "td"], "idx": 432}
{"url": "https://github.com/openvax/sercol/blob/e66a8e8c3c0b21e53eb8f73be4d23409fab311ae/sercol/collection.py#L74-L96", "repo": "sercol", "func_name": "clone_with_new_elements", "original_string": ["    def clone_with_new_elements(\n", "            self,\n", "            new_elements,\n", "            drop_keywords=set([]),\n", "            rename_dict={},\n", "            extra_kwargs={}):\n", "        \"\"\"\n", "        Create another Collection of the same class and with same state but\n", "        possibly different entries. Extra parameters to control which keyword\n", "        arguments get passed to the initializer are necessary since derived\n", "        classes have different constructors than the base class.\n", "        \"\"\"\n", "        kwargs = dict(\n", "            elements=new_elements,\n", "            distinct=self.distinct,\n", "            sort_key=self.sort_key,\n", "            sources=self.sources)\n", "        for name in drop_keywords:\n", "            kwargs.pop(name)\n", "        for old_name, new_name in rename_dict.items():\n", "            kwargs[new_name] = kwargs.pop(old_name)\n", "        kwargs.update(extra_kwargs)\n", "        return self.__class__(**kwargs)\n"], "language": "python", "code": "def clone_with_new_elements(self, new_elements, drop_keywords=set([]),\n    rename_dict={}, extra_kwargs={}):\n    \"\"\"\"\"\"\n    kwargs = dict(elements=new_elements, distinct=self.distinct, sort_key=\n        self.sort_key, sources=self.sources)\n    for name in drop_keywords:\n        kwargs.pop(name)\n    for old_name, new_name in rename_dict.items():\n        kwargs[new_name] = kwargs.pop(old_name)\n    kwargs.update(extra_kwargs)\n    return self.__class__(**kwargs)\n", "code_tokens": ["clone", "with", "new", "elements", "self", "new", "elements", "drop", "keywords", "set", "rename", "dict", "extra", "kwargs", "kwargs", "dict", "elements", "new", "elements", "distinct", "self", "distinct", "sort", "key", "self", "sort", "key", "sources", "self", "sources", "for", "name", "in", "drop", "keywords", "kwargs", "pop", "name", "for", "old", "name", "new", "name", "in", "rename", "dict", "items", "kwargs", "new", "name", "kwargs", "pop", "old", "name", "kwargs", "update", "extra", "kwargs", "return", "self", "class", "kwargs"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 433}
{"url": "https://github.com/pricingassistant/mongokat/blob/61eaf4bc1c4cc359c6f9592ec97b9a04d9561411/mongokat/collection.py#L136-L137", "repo": "mongokat", "func_name": "distinct", "original_string": ["    def distinct(self, *args, **kwargs):\n", "        return self._collection_with_options(kwargs).distinct(*args, **kwargs)\n"], "language": "python", "code": "def distinct(self, *args, **kwargs):\n    return self._collection_with_options(kwargs).distinct(*args, **kwargs)\n", "code_tokens": ["distinct", "self", "args", "kwargs", "return", "self", "collection", "with", "options", "kwargs", "distinct", "args", "kwargs"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 434}
{"url": "https://github.com/merenlab/illumina-utils/blob/246d0611f976471783b83d2aba309b0cb57210f6/IlluminaUtils/lib/fastalib.py#L111-L128", "repo": "illumina-utils", "func_name": "init_unique_hash", "original_string": ["    def init_unique_hash(self):\n", "        while self.next_regular():\n", "            hash = hashlib.sha1(self.seq.upper().encode('utf-8')).hexdigest()\n", "            if hash in self.unique_hash_dict:\n", "                self.unique_hash_dict[hash]['ids'].append(self.id)\n", "                self.unique_hash_dict[hash]['count'] += 1\n", "            else:\n", "                self.unique_hash_dict[hash] = {'id': self.id,\n", "                                               'ids': [self.id],\n", "                                               'seq': self.seq,\n", "                                               'count': 1}\n", "\n", "        self.unique_hash_list = [i[1] for i in sorted([(self.unique_hash_dict[hash]['count'], hash)\\\n", "                        for hash in self.unique_hash_dict], reverse=True)]\n", "\n", "\n", "        self.total_unique = len(self.unique_hash_dict)\n", "        self.reset()\n"], "language": "python", "code": "def init_unique_hash(self):\n    while self.next_regular():\n        hash = hashlib.sha1(self.seq.upper().encode('utf-8')).hexdigest()\n        if hash in self.unique_hash_dict:\n            self.unique_hash_dict[hash]['ids'].append(self.id)\n            self.unique_hash_dict[hash]['count'] += 1\n        else:\n            self.unique_hash_dict[hash] = {'id': self.id, 'ids': [self.id],\n                'seq': self.seq, 'count': 1}\n    self.unique_hash_list = [i[1] for i in sorted([(self.unique_hash_dict[\n        hash]['count'], hash) for hash in self.unique_hash_dict], reverse=True)\n        ]\n    self.total_unique = len(self.unique_hash_dict)\n    self.reset()\n", "code_tokens": ["init", "unique", "hash", "self", "while", "self", "next", "regular", "hash", "hashlib", "self", "seq", "upper", "encode", "utf", "8", "hexdigest", "if", "hash", "in", "self", "unique", "hash", "dict", "self", "unique", "hash", "dict", "hash", "ids", "append", "self", "id", "self", "unique", "hash", "dict", "hash", "count", "1", "else", "self", "unique", "hash", "dict", "hash", "id", "self", "id", "ids", "self", "id", "seq", "self", "seq", "count", "1", "self", "unique", "hash", "list", "1", "for", "in", "sorted", "self", "unique", "hash", "dict", "hash", "count", "hash", "for", "hash", "in", "self", "unique", "hash", "dict", "reverse", "true", "self", "total", "unique", "len", "self", "unique", "hash", "dict", "self", "reset"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 435}
{"url": "https://github.com/firstprayer/monsql/blob/6285c15b574c8664046eae2edfeb548c7b173efd/monsql/queryset.py#L110-L117", "repo": "monsql", "func_name": "distinct", "original_string": ["    def distinct(self):\n", "        \"\"\"\n", "        Only return distinct row. \n", "        Return a new query set with distinct mark\n", "        \"\"\"\n", "        new_query_set = self.clone()\n", "        new_query_set.query.distinct = True\n", "        return new_query_set\n"], "language": "python", "code": "def distinct(self):\n    \"\"\"\"\"\"\n    new_query_set = self.clone()\n    new_query_set.query.distinct = True\n    return new_query_set\n", "code_tokens": ["distinct", "self", "new", "query", "set", "self", "clone", "new", "query", "set", "query", "distinct", "true", "return", "new", "query", "set"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 436}
{"url": "https://github.com/openstates/billy/blob/5fc795347f12a949e410a8cfad0c911ea6bced67/billy/models/base.py#L414-L416", "repo": "billy", "func_name": "distinct", "original_string": ["    def distinct(self, *args, **kwargs):\n", "        return CursorWrapper(\n", "            self.cursor.distinct(*args, **kwargs), self.instance)\n"], "language": "python", "code": "def distinct(self, *args, **kwargs):\n    return CursorWrapper(self.cursor.distinct(*args, **kwargs), self.instance)\n", "code_tokens": ["distinct", "self", "args", "kwargs", "return", "cursorwrapper", "self", "cursor", "distinct", "args", "kwargs", "self", "instance"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 437}
{"url": "https://github.com/emc-openstack/storops/blob/24b4b13bf065c0ef0538dd0b5ebb8f25d24176bd/storops/vnx/resource/disk.py#L141-L166", "repo": "storops", "func_name": "same_disks", "original_string": ["    def same_disks(self, count=2):\n", "        \"\"\" filter self to the required number of disks with same size and type\n", "\n", "        Select the disks with the same type and same size.  If not\n", "        enough disks available, set self to empty.\n", "\n", "        :param count: number of disks to retrieve\n", "        :return: disk list\n", "        \"\"\"\n", "        ret = self\n", "        if len(self) > 0:\n", "            type_counter = Counter(self.drive_type)\n", "            drive_type, counts = type_counter.most_common()[0]\n", "            self.set_drive_type(drive_type)\n", "\n", "        if len(self) > 0:\n", "            size_counter = Counter(self.capacity)\n", "            size, counts = size_counter.most_common()[0]\n", "            self.set_capacity(size)\n", "\n", "        if len(self) >= count:\n", "            indices = self.index[:count]\n", "            self.set_indices(indices)\n", "        else:\n", "            self.set_indices('N/A')\n", "        return ret\n"], "language": "python", "code": "def same_disks(self, count=2):\n    \"\"\"\"\"\"\n    ret = self\n    if len(self) > 0:\n        type_counter = Counter(self.drive_type)\n        drive_type, counts = type_counter.most_common()[0]\n        self.set_drive_type(drive_type)\n    if len(self) > 0:\n        size_counter = Counter(self.capacity)\n        size, counts = size_counter.most_common()[0]\n        self.set_capacity(size)\n    if len(self) >= count:\n        indices = self.index[:count]\n        self.set_indices(indices)\n    else:\n        self.set_indices('N/A')\n    return ret\n", "code_tokens": ["same", "disks", "self", "count", "2", "ret", "self", "if", "len", "self", "0", "type", "counter", "counter", "self", "drive", "type", "drive", "type", "counts", "type", "counter", "most", "common", "0", "self", "set", "drive", "type", "drive", "type", "if", "len", "self", "0", "size", "counter", "counter", "self", "capacity", "size", "counts", "size", "counter", "most", "common", "0", "self", "set", "capacity", "size", "if", "len", "self", "count", "indices", "self", "index", "count", "self", "set", "indices", "indices", "else", "self", "set", "indices", "return", "ret"], "docstring": "hash set for counting distinct elements", "docstring_tokens": ["hash", "set", "for", "counting", "distinct", "elements"], "idx": 438}
