{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100a4b21",
   "metadata": {},
   "source": [
    "This notebook demonstrates the pre-processing of the data used for our experiments in addition to the CodeSearchNet datasets. This notebook is inspired from the CodeSearchNet notebook. For simplicity our experiment is perfromed on the Python dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9054c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth',300)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193144e4",
   "metadata": {},
   "source": [
    "Part 1 : Preview the Dataset\n",
    "\n",
    "Before working on the complete dataset, it will useful to understand small dataset to understand the format and the structure of the data. \n",
    "\n",
    "First we download the dataset from our GitHub Repo. We have three different datasets that we want to look at:\n",
    "1. CodeSearchNet Corpus\n",
    "2. CodeXGLUE dataset\n",
    "3. SemanticCodeSearch Corpus (generated from CodeSearchNet Challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b1d36",
   "metadata": {},
   "source": [
    "## Part 1.1 CodeSearchNet Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ea5fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-18 17:37:00--  https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.226.200, 52.217.75.134, 52.217.200.240, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.226.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 940909997 (897M) [application/zip]\n",
      "Saving to: ‘python.zip.1’\n",
      "\n",
      "python.zip.1        100%[===================>] 897.32M  32.0MB/s    in 34s     \n",
      "\n",
      "2023-03-18 17:37:34 (26.4 MB/s) - ‘python.zip.1’ saved [940909997/940909997]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/code-search-net/CodeSearchNet/v2/python.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7fc12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  python.zip\n",
      "   creating: codesearchnet/python/\n",
      "   creating: codesearchnet/python/final/\n",
      "   creating: codesearchnet/python/final/jsonl/\n",
      "   creating: codesearchnet/python/final/jsonl/train/\n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_9.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_12.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_10.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_0.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_6.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_2.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_4.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_8.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_11.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_5.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_13.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_3.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_1.jsonl.gz  \n",
      "  inflating: codesearchnet/python/final/jsonl/train/python_train_7.jsonl.gz  \n",
      "   creating: codesearchnet/python/final/jsonl/test/\n",
      "  inflating: codesearchnet/python/final/jsonl/test/python_test_0.jsonl.gz  \n",
      "   creating: codesearchnet/python/final/jsonl/valid/\n",
      "  inflating: codesearchnet/python/final/jsonl/valid/python_valid_0.jsonl.gz  \n",
      "  inflating: codesearchnet/python_dedupe_definitions_v2.pkl  \n",
      "  inflating: codesearchnet/python_licenses.pkl  \n"
     ]
    }
   ],
   "source": [
    "!unzip python.zip -d codesearchnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9190a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompress this gzip file\n",
    "!gzip -d codesearchnet/python/final/jsonl/test/python_test_0.jsonl.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d8c90",
   "metadata": {},
   "source": [
    "Read the file and display the first row. The data is stored in JSON Lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914b928e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"repo\": \"soimort/you-get\", \"path\": \"src/you_get/extractors/youtube.py\", \"func_name\": \"YouTube.get_vid_from_url\", \"original_string\": \"def get_vid_from_url(url):\\\\n        \\\\\"\\\\\"\\\\\"Extracts video ID from URL.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        return match1(url, r\\'youtu\\\\\\\\.be/([^?/]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/embed/([^/?]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/v/([^/?]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/watch/([^/?]+)\\') or \\\\\\\\\\\\n          parse_query_param(url, \\'v\\') or \\\\\\\\\\\\n          parse_query_param(parse_query_param(url, \\'u\\'), \\'v\\')\", \"language\": \"python\", \"code\": \"def get_vid_from_url(url):\\\\n        \\\\\"\\\\\"\\\\\"Extracts video ID from URL.\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        return match1(url, r\\'youtu\\\\\\\\.be/([^?/]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/embed/([^/?]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/v/([^/?]+)\\') or \\\\\\\\\\\\n          match1(url, r\\'youtube\\\\\\\\.com/watch/([^/?]+)\\') or \\\\\\\\\\\\n          parse_query_param(url, \\'v\\') or \\\\\\\\\\\\n          parse_query_param(parse_query_param(url, \\'u\\'), \\'v\\')\", \"code_tokens\": [\"def\", \"get_vid_from_url\", \"(\", \"url\", \")\", \":\", \"return\", \"match1\", \"(\", \"url\", \",\", \"r\\'youtu\\\\\\\\.be/([^?/]+)\\'\", \")\", \"or\", \"match1\", \"(\", \"url\", \",\", \"r\\'youtube\\\\\\\\.com/embed/([^/?]+)\\'\", \")\", \"or\", \"match1\", \"(\", \"url\", \",\", \"r\\'youtube\\\\\\\\.com/v/([^/?]+)\\'\", \")\", \"or\", \"match1\", \"(\", \"url\", \",\", \"r\\'youtube\\\\\\\\.com/watch/([^/?]+)\\'\", \")\", \"or\", \"parse_query_param\", \"(\", \"url\", \",\", \"\\'v\\'\", \")\", \"or\", \"parse_query_param\", \"(\", \"parse_query_param\", \"(\", \"url\", \",\", \"\\'u\\'\", \")\", \",\", \"\\'v\\'\", \")\"], \"docstring\": \"Extracts video ID from URL.\", \"docstring_tokens\": [\"Extracts\", \"video\", \"ID\", \"from\", \"URL\", \".\"], \"sha\": \"b746ac01c9f39de94cac2d56f665285b0523b974\", \"url\": \"https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143\", \"partition\": \"test\"}\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('codesearchnet/python/final/jsonl/test/python_test_0.jsonl', 'r') as f:\n",
    "    sample_file = f.readlines()\n",
    "sample_file[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35d961",
   "metadata": {},
   "source": [
    "Pretty printing the JSON file contents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ba5deb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def get_vid_from_url(url):\\n'\n",
      "         '        \"\"\"Extracts video ID from URL.\\n'\n",
      "         '        \"\"\"\\n'\n",
      "         \"        return match1(url, r'youtu\\\\.be/([^?/]+)') or \\\\\\n\"\n",
      "         \"          match1(url, r'youtube\\\\.com/embed/([^/?]+)') or \\\\\\n\"\n",
      "         \"          match1(url, r'youtube\\\\.com/v/([^/?]+)') or \\\\\\n\"\n",
      "         \"          match1(url, r'youtube\\\\.com/watch/([^/?]+)') or \\\\\\n\"\n",
      "         \"          parse_query_param(url, 'v') or \\\\\\n\"\n",
      "         \"          parse_query_param(parse_query_param(url, 'u'), 'v')\",\n",
      " 'code_tokens': ['def',\n",
      "                 'get_vid_from_url',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ')',\n",
      "                 ':',\n",
      "                 'return',\n",
      "                 'match1',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"r'youtu\\\\.be/([^?/]+)'\",\n",
      "                 ')',\n",
      "                 'or',\n",
      "                 'match1',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"r'youtube\\\\.com/embed/([^/?]+)'\",\n",
      "                 ')',\n",
      "                 'or',\n",
      "                 'match1',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"r'youtube\\\\.com/v/([^/?]+)'\",\n",
      "                 ')',\n",
      "                 'or',\n",
      "                 'match1',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"r'youtube\\\\.com/watch/([^/?]+)'\",\n",
      "                 ')',\n",
      "                 'or',\n",
      "                 'parse_query_param',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"'v'\",\n",
      "                 ')',\n",
      "                 'or',\n",
      "                 'parse_query_param',\n",
      "                 '(',\n",
      "                 'parse_query_param',\n",
      "                 '(',\n",
      "                 'url',\n",
      "                 ',',\n",
      "                 \"'u'\",\n",
      "                 ')',\n",
      "                 ',',\n",
      "                 \"'v'\",\n",
      "                 ')'],\n",
      " 'docstring': 'Extracts video ID from URL.',\n",
      " 'docstring_tokens': ['Extracts', 'video', 'ID', 'from', 'URL', '.'],\n",
      " 'func_name': 'YouTube.get_vid_from_url',\n",
      " 'language': 'python',\n",
      " 'original_string': 'def get_vid_from_url(url):\\n'\n",
      "                    '        \"\"\"Extracts video ID from URL.\\n'\n",
      "                    '        \"\"\"\\n'\n",
      "                    \"        return match1(url, r'youtu\\\\.be/([^?/]+)') or \\\\\\n\"\n",
      "                    \"          match1(url, r'youtube\\\\.com/embed/([^/?]+)') or \"\n",
      "                    '\\\\\\n'\n",
      "                    \"          match1(url, r'youtube\\\\.com/v/([^/?]+)') or \\\\\\n\"\n",
      "                    \"          match1(url, r'youtube\\\\.com/watch/([^/?]+)') or \"\n",
      "                    '\\\\\\n'\n",
      "                    \"          parse_query_param(url, 'v') or \\\\\\n\"\n",
      "                    \"          parse_query_param(parse_query_param(url, 'u'), \"\n",
      "                    \"'v')\",\n",
      " 'partition': 'test',\n",
      " 'path': 'src/you_get/extractors/youtube.py',\n",
      " 'repo': 'soimort/you-get',\n",
      " 'sha': 'b746ac01c9f39de94cac2d56f665285b0523b974',\n",
      " 'url': 'https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143'}\n"
     ]
    }
   ],
   "source": [
    "pprint(json.loads(sample_file[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60337f",
   "metadata": {},
   "source": [
    "Definitions for the file will be is documented in README.md in https://github.com/github/CodeSearchNet/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811cf33b",
   "metadata": {},
   "source": [
    "## Exploring The Full Dataset\n",
    "For simplicity, we are going to only focus on the Python dataset \n",
    "To make analysis of the dataset easier, we can load all the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa2ee6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localhome/local-dineshr/cs224n/cs224n-project/demos/codesearchnet\n"
     ]
    }
   ],
   "source": [
    "#define function to load jsonl files to dataframe\n",
    "%cd /localhome/local-dineshr/cs224n/cs224n-project/demos/codesearchnet\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "columns_short_list = ['code_tokens', 'docstring_tokens', \n",
    "                      'language', 'partition']\n",
    "\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a12a32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_files:16\n"
     ]
    }
   ],
   "source": [
    "python_files = sorted(Path('python/').glob('**/*.jsonl'))\n",
    "print(f\"python_files:{len(python_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bae4d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf = jsonl_list_to_dataframe(python_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d257d0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>src/you_get/extractors/youtube.py</td>\n",
       "      <td>https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143</td>\n",
       "      <td>def get_vid_from_url(url):\\n        \"\"\"Extracts video ID from URL.\\n        \"\"\"\\n        return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n          match1(url, r'youtube\\.com/watch/...</td>\n",
       "      <td>[def, get_vid_from_url, (, url, ), :, return, match1, (, url, ,, r'youtu\\.be/([^?/]+)', ), or, match1, (, url, ,, r'youtube\\.com/embed/([^/?]+)', ), or, match1, (, url, ,, r'youtube\\.com/v/([^/?]+)', ), or, match1, (, url, ,, r'youtube\\.com/watch/([^/?]+)', ), or, parse_query_param, (, url, ,, '...</td>\n",
       "      <td>Extracts video ID from URL.</td>\n",
       "      <td>[Extracts, video, ID, from, URL, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>src/you_get/extractors/miomio.py</td>\n",
       "      <td>https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miomio.py#L41-L51</td>\n",
       "      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"str-&gt;list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElementsByTagName('durl'):\\n        url = node.getElementsByTagName('url')[0]\\n        rawurl.append(url.chil...</td>\n",
       "      <td>[def, sina_xml_to_url_list, (, xml_data, ), :, rawurl, =, [, ], dom, =, parseString, (, xml_data, ), for, node, in, dom, ., getElementsByTagName, (, 'durl', ), :, url, =, node, ., getElementsByTagName, (, 'url', ), [, 0, ], rawurl, ., append, (, url, ., childNodes, [, 0, ], ., data, ), return, r...</td>\n",
       "      <td>str-&gt;list\\n    Convert XML to URL List.\\n    From Biligrab.</td>\n",
       "      <td>[str, -, &gt;, list, Convert, XML, to, URL, List, ., From, Biligrab, .]</td>\n",
       "      <td>python</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soimort/you-get</td>\n",
       "      <td>src/you_get/extractors/fc2video.py</td>\n",
       "      <td>https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/fc2video.py#L11-L17</td>\n",
       "      <td>def makeMimi(upid):\\n    \"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\\n    L110\"\"\"\\n    strSeed = \"gGddgPfeaf_gzyr\"\\n    prehash = upid + \"_\" + strSeed\\n    return md5(prehash.encode('utf-8')).hexdigest()</td>\n",
       "      <td>[def, makeMimi, (, upid, ), :, strSeed, =, \"gGddgPfeaf_gzyr\", prehash, =, upid, +, \"_\", +, strSeed, return, md5, (, prehash, ., encode, (, 'utf-8', ), ), ., hexdigest, (, )]</td>\n",
       "      <td>From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\\n    L110</td>\n",
       "      <td>[From, http, :, //, cdn37, ., atwikiimg, ., com, /, sitescript, /, pub, /, dksitescript, /, FC2, ., site, ., js, Also, com, ., hps, ., util, ., fc2, ., FC2EncrptUtil, ., makeMimiLocal, L110]</td>\n",
       "      <td>python</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              repo                                path  \\\n",
       "0  soimort/you-get   src/you_get/extractors/youtube.py   \n",
       "1  soimort/you-get    src/you_get/extractors/miomio.py   \n",
       "2  soimort/you-get  src/you_get/extractors/fc2video.py   \n",
       "\n",
       "                                                                                                                            url  \\\n",
       "0  https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/youtube.py#L135-L143   \n",
       "1     https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/miomio.py#L41-L51   \n",
       "2   https://github.com/soimort/you-get/blob/b746ac01c9f39de94cac2d56f665285b0523b974/src/you_get/extractors/fc2video.py#L11-L17   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          code  \\\n",
       "0  def get_vid_from_url(url):\\n        \"\"\"Extracts video ID from URL.\\n        \"\"\"\\n        return match1(url, r'youtu\\.be/([^?/]+)') or \\\\n          match1(url, r'youtube\\.com/embed/([^/?]+)') or \\\\n          match1(url, r'youtube\\.com/v/([^/?]+)') or \\\\n          match1(url, r'youtube\\.com/watch/...   \n",
       "1  def sina_xml_to_url_list(xml_data):\\n    \"\"\"str->list\\n    Convert XML to URL List.\\n    From Biligrab.\\n    \"\"\"\\n    rawurl = []\\n    dom = parseString(xml_data)\\n    for node in dom.getElementsByTagName('durl'):\\n        url = node.getElementsByTagName('url')[0]\\n        rawurl.append(url.chil...   \n",
       "2            def makeMimi(upid):\\n    \"\"\"From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\\n    L110\"\"\"\\n    strSeed = \"gGddgPfeaf_gzyr\"\\n    prehash = upid + \"_\" + strSeed\\n    return md5(prehash.encode('utf-8')).hexdigest()   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   code_tokens  \\\n",
       "0  [def, get_vid_from_url, (, url, ), :, return, match1, (, url, ,, r'youtu\\.be/([^?/]+)', ), or, match1, (, url, ,, r'youtube\\.com/embed/([^/?]+)', ), or, match1, (, url, ,, r'youtube\\.com/v/([^/?]+)', ), or, match1, (, url, ,, r'youtube\\.com/watch/([^/?]+)', ), or, parse_query_param, (, url, ,, '...   \n",
       "1  [def, sina_xml_to_url_list, (, xml_data, ), :, rawurl, =, [, ], dom, =, parseString, (, xml_data, ), for, node, in, dom, ., getElementsByTagName, (, 'durl', ), :, url, =, node, ., getElementsByTagName, (, 'url', ), [, 0, ], rawurl, ., append, (, url, ., childNodes, [, 0, ], ., data, ), return, r...   \n",
       "2                                                                                                                                [def, makeMimi, (, upid, ), :, strSeed, =, \"gGddgPfeaf_gzyr\", prehash, =, upid, +, \"_\", +, strSeed, return, md5, (, prehash, ., encode, (, 'utf-8', ), ), ., hexdigest, (, )]   \n",
       "\n",
       "                                                                                                                                  docstring  \\\n",
       "0                                                                                                               Extracts video ID from URL.   \n",
       "1                                                                               str->list\\n    Convert XML to URL List.\\n    From Biligrab.   \n",
       "2  From http://cdn37.atwikiimg.com/sitescript/pub/dksitescript/FC2.site.js\\n    Also com.hps.util.fc2.FC2EncrptUtil.makeMimiLocal\\n    L110   \n",
       "\n",
       "                                                                                                                                                                                 docstring_tokens  \\\n",
       "0                                                                                                                                                             [Extracts, video, ID, from, URL, .]   \n",
       "1                                                                                                                            [str, -, >, list, Convert, XML, to, URL, List, ., From, Biligrab, .]   \n",
       "2  [From, http, :, //, cdn37, ., atwikiimg, ., com, /, sitescript, /, pub, /, dksitescript, /, FC2, ., site, ., js, Also, com, ., hps, ., util, ., fc2, ., FC2EncrptUtil, ., makeMimiLocal, L110]   \n",
       "\n",
       "  language partition  \n",
       "0   python      test  \n",
       "1   python      test  \n",
       "2   python      test  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbaf0e",
   "metadata": {},
   "source": [
    "Two columns that will be heavily used in this dataset are code_tokens and docstring_tokens, which represent a parallel corpus that can be used for interesting tasks like information retrieval (for example trying to retrieve a codesnippet using the docstring.). You can find more information regarding the definition of the above columns in the README of this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c68516",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "### Row Counts\n",
    "By Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef39520b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    412178\n",
       "valid     23107\n",
       "test      22176\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydf.partition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e508eee",
   "metadata": {},
   "source": [
    "### Token lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e3774b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydf['code_len'] = pydf.code_tokens.apply(lambda x: len(x))\n",
    "pydf['query_len'] = pydf.docstring_tokens.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76932d",
   "metadata": {},
   "source": [
    "### Code Length Percentile\n",
    "For example, the 80th percentile length for python tokens is 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0330c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>code_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">python</th>\n",
       "      <th>0.50</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               code_len\n",
       "language               \n",
       "python   0.50      72.0\n",
       "         0.70     114.0\n",
       "         0.80     155.0\n",
       "         0.90     237.0\n",
       "         0.95     341.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_len_summary = pydf.groupby('language')['code_len'].quantile([.5, .7, .8, .9, .95])\n",
    "display(pd.DataFrame(code_len_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac034d2",
   "metadata": {},
   "source": [
    "### Query Length Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e237ae05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>query_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">python</th>\n",
       "      <th>0.50</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               query_len\n",
       "language                \n",
       "python   0.50       10.0\n",
       "         0.70       15.0\n",
       "         0.80       20.0\n",
       "         0.90       33.0\n",
       "         0.95       48.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_len_summary = pydf.groupby('language')['query_len'].quantile([.5, .7, .8, .9, .95])\n",
    "display(pd.DataFrame(query_len_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f01db",
   "metadata": {},
   "source": [
    "## PART1.2 CodeXGLUE Dataset\n",
    "Dataset is the same as above, but there is some preproceessing done on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c05274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-18 18:19:17--  https://semanticcodesearch.s3.us-west-2.amazonaws.com/dataset.zip\n",
      "Resolving semanticcodesearch.s3.us-west-2.amazonaws.com (semanticcodesearch.s3.us-west-2.amazonaws.com)... 52.92.226.90, 52.218.218.233, 52.92.165.106, ...\n",
      "Connecting to semanticcodesearch.s3.us-west-2.amazonaws.com (semanticcodesearch.s3.us-west-2.amazonaws.com)|52.92.226.90|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25115627 (24M) [application/zip]\n",
      "Saving to: ‘dataset.zip’\n",
      "\n",
      "dataset.zip         100%[===================>]  23.95M  78.8MB/s    in 0.3s    \n",
      "\n",
      "2023-03-18 18:19:17 (78.8 MB/s) - ‘dataset.zip’ saved [25115627/25115627]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://semanticcodesearch.s3.us-west-2.amazonaws.com/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "443b10cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localhome/local-dineshr/cs224n/cs224n-project/demos\n",
      "/localhome/local-dineshr/cs224n/cs224n-project/demos/CodeXGLUE/dataset\n",
      "/localhome/local-dineshr/cs224n/cs224n-project/demos/CodeXGLUE/dataset\n"
     ]
    }
   ],
   "source": [
    "#downwload and link the codesearchnet data\n",
    "!unzip dataset.zip -d CodeXGLUE\n",
    "!pwd\n",
    "%cd ./CodeXGLUE/dataset\n",
    "!pwd\n",
    "!ln -s ../../codesearchnet codesearchnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43d4ccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traininig data count: 251820\n"
     ]
    }
   ],
   "source": [
    "#preproceess.py\n",
    "import os\n",
    "language='python'\n",
    "\n",
    "train=[]\n",
    "for root, dirs, files in os.walk('codesearchnet/'+language+'/final'):\n",
    "    for file in files:\n",
    "        temp=os.path.join(root,file)\n",
    "        if '.jsonl' in temp:\n",
    "            if 'train' in temp:\n",
    "                train.append(temp)\n",
    "\n",
    "data={}                    \n",
    "for file in train:\n",
    "    if '.gz' in file:\n",
    "        os.system(\"gzip -d {}\".format(file))\n",
    "        file=file.replace('.gz','')\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            js=json.loads(line)\n",
    "            data[js['url']]=js\n",
    "cont=0                    \n",
    "with open('train.jsonl','w') as f, open(\"train.txt\") as f1:\n",
    "    for line in f1:\n",
    "        line=line.strip()\n",
    "        js=data[line].copy()\n",
    "        js['idx']=cont\n",
    "        cont+=1\n",
    "        f.write(json.dumps(js)+'\\n')\n",
    "train_count = cont\n",
    "print(f\"traininig data count: {train_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a287ee3e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def split_phylogeny(p, level=\"s\"):\\n'\n",
      "         '    \"\"\"\\n'\n",
      "         '    Return either the full or truncated version of a QIIME-formatted '\n",
      "         'taxonomy string.\\n'\n",
      "         '\\n'\n",
      "         '    :type p: str\\n'\n",
      "         '    :param p: A QIIME-formatted taxonomy string: k__Foo; p__Bar; '\n",
      "         '...\\n'\n",
      "         '\\n'\n",
      "         '    :type level: str\\n'\n",
      "         '    :param level: The different level of identification are kingdom '\n",
      "         '(k), phylum (p),\\n'\n",
      "         '                  class (c),order (o), family (f), genus (g) and '\n",
      "         'species (s). If level is\\n'\n",
      "         '                  not provided, the default level of identification '\n",
      "         'is species.\\n'\n",
      "         '\\n'\n",
      "         '    :rtype: str\\n'\n",
      "         '    :return: A QIIME-formatted taxonomy string up to the '\n",
      "         'classification given\\n'\n",
      "         '            by param level.\\n'\n",
      "         '    \"\"\"\\n'\n",
      "         '    level = level+\"__\"\\n'\n",
      "         '    result = p.split(level)\\n'\n",
      "         '    return result[0]+level+result[1].split(\";\")[0]',\n",
      " 'code_tokens': ['def',\n",
      "                 'split_phylogeny',\n",
      "                 '(',\n",
      "                 'p',\n",
      "                 ',',\n",
      "                 'level',\n",
      "                 '=',\n",
      "                 '\"s\"',\n",
      "                 ')',\n",
      "                 ':',\n",
      "                 'level',\n",
      "                 '=',\n",
      "                 'level',\n",
      "                 '+',\n",
      "                 '\"__\"',\n",
      "                 'result',\n",
      "                 '=',\n",
      "                 'p',\n",
      "                 '.',\n",
      "                 'split',\n",
      "                 '(',\n",
      "                 'level',\n",
      "                 ')',\n",
      "                 'return',\n",
      "                 'result',\n",
      "                 '[',\n",
      "                 '0',\n",
      "                 ']',\n",
      "                 '+',\n",
      "                 'level',\n",
      "                 '+',\n",
      "                 'result',\n",
      "                 '[',\n",
      "                 '1',\n",
      "                 ']',\n",
      "                 '.',\n",
      "                 'split',\n",
      "                 '(',\n",
      "                 '\";\"',\n",
      "                 ')',\n",
      "                 '[',\n",
      "                 '0',\n",
      "                 ']'],\n",
      " 'docstring': 'Return either the full or truncated version of a '\n",
      "              'QIIME-formatted taxonomy string.\\n'\n",
      "              '\\n'\n",
      "              '    :type p: str\\n'\n",
      "              '    :param p: A QIIME-formatted taxonomy string: k__Foo; '\n",
      "              'p__Bar; ...\\n'\n",
      "              '\\n'\n",
      "              '    :type level: str\\n'\n",
      "              '    :param level: The different level of identification are '\n",
      "              'kingdom (k), phylum (p),\\n'\n",
      "              '                  class (c),order (o), family (f), genus (g) '\n",
      "              'and species (s). If level is\\n'\n",
      "              '                  not provided, the default level of '\n",
      "              'identification is species.\\n'\n",
      "              '\\n'\n",
      "              '    :rtype: str\\n'\n",
      "              '    :return: A QIIME-formatted taxonomy string up to the '\n",
      "              'classification given\\n'\n",
      "              '            by param level.',\n",
      " 'docstring_tokens': ['Return',\n",
      "                      'either',\n",
      "                      'the',\n",
      "                      'full',\n",
      "                      'or',\n",
      "                      'truncated',\n",
      "                      'version',\n",
      "                      'of',\n",
      "                      'a',\n",
      "                      'QIIME',\n",
      "                      '-',\n",
      "                      'formatted',\n",
      "                      'taxonomy',\n",
      "                      'string',\n",
      "                      '.'],\n",
      " 'func_name': 'split_phylogeny',\n",
      " 'idx': 0,\n",
      " 'language': 'python',\n",
      " 'original_string': 'def split_phylogeny(p, level=\"s\"):\\n'\n",
      "                    '    \"\"\"\\n'\n",
      "                    '    Return either the full or truncated version of a '\n",
      "                    'QIIME-formatted taxonomy string.\\n'\n",
      "                    '\\n'\n",
      "                    '    :type p: str\\n'\n",
      "                    '    :param p: A QIIME-formatted taxonomy string: k__Foo; '\n",
      "                    'p__Bar; ...\\n'\n",
      "                    '\\n'\n",
      "                    '    :type level: str\\n'\n",
      "                    '    :param level: The different level of identification '\n",
      "                    'are kingdom (k), phylum (p),\\n'\n",
      "                    '                  class (c),order (o), family (f), genus '\n",
      "                    '(g) and species (s). If level is\\n'\n",
      "                    '                  not provided, the default level of '\n",
      "                    'identification is species.\\n'\n",
      "                    '\\n'\n",
      "                    '    :rtype: str\\n'\n",
      "                    '    :return: A QIIME-formatted taxonomy string up to the '\n",
      "                    'classification given\\n'\n",
      "                    '            by param level.\\n'\n",
      "                    '    \"\"\"\\n'\n",
      "                    '    level = level+\"__\"\\n'\n",
      "                    '    result = p.split(level)\\n'\n",
      "                    '    return result[0]+level+result[1].split(\";\")[0]',\n",
      " 'partition': 'train',\n",
      " 'path': 'phylotoast/util.py',\n",
      " 'repo': 'smdabdoub/phylotoast',\n",
      " 'sha': '0b74ef171e6a84761710548501dfac71285a58a3',\n",
      " 'url': 'https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L159-L177'}\n"
     ]
    }
   ],
   "source": [
    "# printing first line of the train file\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    train_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(train_file[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "681db556",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={}                    \n",
    "with open('test_code.jsonl') as f:\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        js=json.loads(line)\n",
    "        data[js['url']]=js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98345981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid count: 9604\n"
     ]
    }
   ],
   "source": [
    "if cont == 0:\n",
    "    assert train_count != 0\n",
    "    cont = train_count\n",
    "with open('valid.jsonl','w') as f, open(\"valid.txt\") as f1:\n",
    "    for line in f1:\n",
    "        line=line.strip()\n",
    "        js=data[line].copy()\n",
    "        js['idx']=cont\n",
    "        cont+=1\n",
    "        f.write(json.dumps(js)+'\\n')\n",
    "valid_count = cont - train_count\n",
    "print(f\"Valid count: {valid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5f5a6d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'argument_list': '',\n",
      " 'docstring': 'Helper which expand_dims `is_accepted` then applies tf.where.',\n",
      " 'docstring_summary': 'Helper which expand_dims `is_accepted` then applies '\n",
      "                      'tf.where.',\n",
      " 'docstring_tokens': ['Helper',\n",
      "                      'which',\n",
      "                      'expand_dims',\n",
      "                      'is_accepted',\n",
      "                      'then',\n",
      "                      'applies',\n",
      "                      'tf',\n",
      "                      '.',\n",
      "                      'where',\n",
      "                      '.'],\n",
      " 'function': 'def Func(arg_0, arg_1, arg_2, arg_3=None):\\n'\n",
      "             '  \"\"\"Helper which expand_dims `is_accepted` then applies '\n",
      "             'tf.where.\"\"\"\\n'\n",
      "             '  if not is_namedtuple_like(arg_1):\\n'\n",
      "             '    return _Func_base_case(arg_0, arg_1, arg_2, arg_3=arg_3)\\n'\n",
      "             '  if not isinstance(arg_1, type(arg_2)):\\n'\n",
      "             \"    raise TypeError('Type of `accepted` ({}) must be identical \"\n",
      "             \"to '\\n\"\n",
      "             \"                    'type of `rejected` ({})'.format(\\n\"\n",
      "             '                        type(arg_1).__name__,\\n'\n",
      "             '                        type(arg_2).__name__))\\n'\n",
      "             '  return type(arg_1)(**dict(\\n'\n",
      "             '      [(arg_4,\\n'\n",
      "             '        Func(arg_0,\\n'\n",
      "             '               getattr(arg_1, arg_4),\\n'\n",
      "             '               getattr(arg_2, arg_4),\\n'\n",
      "             '               arg_3=arg_3))\\n'\n",
      "             '       for arg_4 in arg_1._fields]))',\n",
      " 'function_tokens': ['def',\n",
      "                     'Func',\n",
      "                     '(',\n",
      "                     'arg_0',\n",
      "                     ',',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     'arg_2',\n",
      "                     ',',\n",
      "                     'arg_3',\n",
      "                     '=',\n",
      "                     'None',\n",
      "                     ')',\n",
      "                     ':',\n",
      "                     'if',\n",
      "                     'not',\n",
      "                     'is_namedtuple_like',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ')',\n",
      "                     ':',\n",
      "                     'return',\n",
      "                     '_Func_base_case',\n",
      "                     '(',\n",
      "                     'arg_0',\n",
      "                     ',',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     'arg_2',\n",
      "                     ',',\n",
      "                     'arg_3',\n",
      "                     '=',\n",
      "                     'arg_3',\n",
      "                     ')',\n",
      "                     'if',\n",
      "                     'not',\n",
      "                     'isinstance',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     'type',\n",
      "                     '(',\n",
      "                     'arg_2',\n",
      "                     ')',\n",
      "                     ')',\n",
      "                     ':',\n",
      "                     'raise',\n",
      "                     'TypeError',\n",
      "                     '(',\n",
      "                     \"'Type of `accepted` ({}) must be identical to '\",\n",
      "                     \"'type of `rejected` ({})'\",\n",
      "                     '.',\n",
      "                     'format',\n",
      "                     '(',\n",
      "                     'type',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ')',\n",
      "                     '.',\n",
      "                     '__name__',\n",
      "                     ',',\n",
      "                     'type',\n",
      "                     '(',\n",
      "                     'arg_2',\n",
      "                     ')',\n",
      "                     '.',\n",
      "                     '__name__',\n",
      "                     ')',\n",
      "                     ')',\n",
      "                     'return',\n",
      "                     'type',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ')',\n",
      "                     '(',\n",
      "                     '**',\n",
      "                     'dict',\n",
      "                     '(',\n",
      "                     '[',\n",
      "                     '(',\n",
      "                     'arg_4',\n",
      "                     ',',\n",
      "                     'Func',\n",
      "                     '(',\n",
      "                     'arg_0',\n",
      "                     ',',\n",
      "                     'getattr',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     'arg_4',\n",
      "                     ')',\n",
      "                     ',',\n",
      "                     'getattr',\n",
      "                     '(',\n",
      "                     'arg_2',\n",
      "                     ',',\n",
      "                     'arg_4',\n",
      "                     ')',\n",
      "                     ',',\n",
      "                     'arg_3',\n",
      "                     '=',\n",
      "                     'arg_3',\n",
      "                     ')',\n",
      "                     ')',\n",
      "                     'for',\n",
      "                     'arg_4',\n",
      "                     'in',\n",
      "                     'arg_1',\n",
      "                     '.',\n",
      "                     '_fields',\n",
      "                     ']',\n",
      "                     ')',\n",
      "                     ')'],\n",
      " 'identifier': 'choose',\n",
      " 'idx': 251820,\n",
      " 'language': 'python',\n",
      " 'nwo': 'tensorflow/probability',\n",
      " 'parameters': '(is_accepted, accepted, rejected, name=None)',\n",
      " 'path': 'tensorflow_probability/python/mcmc/internal/util.py',\n",
      " 'return_statement': 'return type(accepted)(**dict(\\n'\n",
      "                     '      [(fn,\\n'\n",
      "                     '        choose(is_accepted,\\n'\n",
      "                     '               getattr(accepted, fn),\\n'\n",
      "                     '               getattr(rejected, fn),\\n'\n",
      "                     '               name=name))\\n'\n",
      "                     '       for fn in accepted._fields]))',\n",
      " 'score': 0.9937575147981225,\n",
      " 'sha': 'e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5',\n",
      " 'url': 'https://github.com/tensorflow/probability/blob/e87fe34111d68c35db0f9eeb4935f1ece9e1a8f5/tensorflow_probability/python/mcmc/internal/util.py#L114-L129'}\n"
     ]
    }
   ],
   "source": [
    "# printing first line of the valid file\n",
    "with open(\"valid.jsonl\", \"r\") as f:\n",
    "    valid_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(valid_file[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef43c35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test count: 19210\n"
     ]
    }
   ],
   "source": [
    "if cont == 0:\n",
    "    assert train_count != 0\n",
    "    assert valid_count != 0 \n",
    "    cont = train_count + valid_count\n",
    "\n",
    "with open('test.jsonl','w') as f, open(\"test.txt\") as f1:\n",
    "    for line in f1:\n",
    "        line=line.strip()\n",
    "        js=data[line].copy()\n",
    "        js['idx']=cont\n",
    "        cont+=1\n",
    "        f.write(json.dumps(js)+'\\n')\n",
    "\n",
    "test_count = cont - (train_count + valid_count)\n",
    "print(f\"test count: {test_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b296c21",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'argument_list': '',\n",
      " 'docstring': 'Try loading given cache file.',\n",
      " 'docstring_summary': 'Try loading given cache file.',\n",
      " 'docstring_tokens': ['Try', 'loading', 'given', 'cache', 'file', '.'],\n",
      " 'function': 'def Func(arg_0, arg_1, *arg_2, **arg_3):\\n'\n",
      "             '        \"\"\"Try loading given cache file.\"\"\"\\n'\n",
      "             '        try:\\n'\n",
      "             '            arg_4 = shelve.open(arg_1)\\n'\n",
      "             '            return arg_0(arg_1, arg_4, *arg_2, **arg_3)\\n'\n",
      "             '        except OSError as e:\\n'\n",
      "             '            logger.debug(\"Loading {0} failed\".format(arg_1))\\n'\n",
      "             '            raise e',\n",
      " 'function_tokens': ['def',\n",
      "                     'Func',\n",
      "                     '(',\n",
      "                     'arg_0',\n",
      "                     ',',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     '*',\n",
      "                     'arg_2',\n",
      "                     ',',\n",
      "                     '**',\n",
      "                     'arg_3',\n",
      "                     ')',\n",
      "                     ':',\n",
      "                     'try',\n",
      "                     ':',\n",
      "                     'arg_4',\n",
      "                     '=',\n",
      "                     'shelve',\n",
      "                     '.',\n",
      "                     'open',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ')',\n",
      "                     'return',\n",
      "                     'arg_0',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ',',\n",
      "                     'arg_4',\n",
      "                     ',',\n",
      "                     '*',\n",
      "                     'arg_2',\n",
      "                     ',',\n",
      "                     '**',\n",
      "                     'arg_3',\n",
      "                     ')',\n",
      "                     'except',\n",
      "                     'OSError',\n",
      "                     'as',\n",
      "                     'e',\n",
      "                     ':',\n",
      "                     'logger',\n",
      "                     '.',\n",
      "                     'debug',\n",
      "                     '(',\n",
      "                     '\"Loading {0} failed\"',\n",
      "                     '.',\n",
      "                     'format',\n",
      "                     '(',\n",
      "                     'arg_1',\n",
      "                     ')',\n",
      "                     ')',\n",
      "                     'raise',\n",
      "                     'e'],\n",
      " 'identifier': 'Cache.from_file',\n",
      " 'idx': 261424,\n",
      " 'language': 'python',\n",
      " 'nwo': 'buckket/twtxt',\n",
      " 'parameters': '(cls, file, *args, **kwargs)',\n",
      " 'path': 'twtxt/cache.py',\n",
      " 'return_statement': '',\n",
      " 'score': 0.5783854231140674,\n",
      " 'sha': '6c8ad8ef3cbcf0dd335a12285d8b6bbdf93ce851',\n",
      " 'url': 'https://github.com/buckket/twtxt/blob/6c8ad8ef3cbcf0dd335a12285d8b6bbdf93ce851/twtxt/cache.py#L44-L51'}\n"
     ]
    }
   ],
   "source": [
    "# printing first line of the test file\n",
    "with open(\"test.jsonl\", \"r\") as f:\n",
    "    test_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(test_file[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "833c2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count: 280634\n"
     ]
    }
   ],
   "source": [
    "assert train_count != 0\n",
    "assert valid_count != 0\n",
    "assert test_count  != 0\n",
    "print(f\"Total Count: {train_count + valid_count + test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f0c3a2",
   "metadata": {},
   "source": [
    "# PART 1.3 SemanticCodeSearch Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95d0cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/localhome/local-dineshr/cs224n/cs224n-project/demos\n",
      "--2023-03-19 00:08:25--  https://semanticcodesearch.s3.us-west-2.amazonaws.com/query_dataset.zip\n",
      "Resolving semanticcodesearch.s3.us-west-2.amazonaws.com (semanticcodesearch.s3.us-west-2.amazonaws.com)... 52.92.227.178, 52.92.250.146, 3.5.79.14, ...\n",
      "Connecting to semanticcodesearch.s3.us-west-2.amazonaws.com (semanticcodesearch.s3.us-west-2.amazonaws.com)|52.92.227.178|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 236336 (231K) [application/zip]\n",
      "Saving to: ‘query_dataset.zip’\n",
      "\n",
      "query_dataset.zip   100%[===================>] 230.80K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-03-19 00:08:25 (3.50 MB/s) - ‘query_dataset.zip’ saved [236336/236336]\n",
      "\n",
      "Archive:  query_dataset.zip\n",
      "  inflating: semantic_search/train.jsonl  \n",
      "  inflating: semantic_search/valid.jsonl  \n",
      "  inflating: semantic_search/test.jsonl  \n",
      "  inflating: semantic_search/queries.csv  \n",
      "/localhome/local-dineshr/cs224n/cs224n-project/demos/semantic_search\n"
     ]
    }
   ],
   "source": [
    "%cd /localhome/local-dineshr/cs224n/cs224n-project/demos/\n",
    "!wget https://semanticcodesearch.s3.us-west-2.amazonaws.com/query_dataset.zip\n",
    "!unzip query_dataset.zip -d semantic_search\n",
    "%cd semantic_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8af3fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def header_without_lines(header, remove):\\n'\n",
      "         '    \"\"\"\"\"\"\\n'\n",
      "         '    remove = set(remove)\\n'\n",
      "         '    lines = []\\n'\n",
      "         '    for line in header.lines:\\n'\n",
      "         \"        if hasattr(line, 'mapping'):\\n\"\n",
      "         \"            if (line.key, line.mapping.get('ID', None)) in remove:\\n\"\n",
      "         '                continue\\n'\n",
      "         '        elif (line.key, line.value) in remove:\\n'\n",
      "         '            continue\\n'\n",
      "         '        lines.append(line)\\n'\n",
      "         '    return Header(lines, header.samples)\\n',\n",
      " 'code_tokens': ['header',\n",
      "                 'without',\n",
      "                 'lines',\n",
      "                 'header',\n",
      "                 'remove',\n",
      "                 'remove',\n",
      "                 'set',\n",
      "                 'remove',\n",
      "                 'lines',\n",
      "                 'for',\n",
      "                 'line',\n",
      "                 'in',\n",
      "                 'header',\n",
      "                 'lines',\n",
      "                 'if',\n",
      "                 'hasattr',\n",
      "                 'line',\n",
      "                 'mapping',\n",
      "                 'if',\n",
      "                 'line',\n",
      "                 'key',\n",
      "                 'line',\n",
      "                 'mapping',\n",
      "                 'get',\n",
      "                 'id',\n",
      "                 'none',\n",
      "                 'in',\n",
      "                 'remove',\n",
      "                 'continue',\n",
      "                 'elif',\n",
      "                 'line',\n",
      "                 'key',\n",
      "                 'line',\n",
      "                 'value',\n",
      "                 'in',\n",
      "                 'remove',\n",
      "                 'continue',\n",
      "                 'lines',\n",
      "                 'append',\n",
      "                 'line',\n",
      "                 'return',\n",
      "                 'header',\n",
      "                 'lines',\n",
      "                 'header',\n",
      "                 'samples'],\n",
      " 'docstring': 'concatenate several file remove header lines',\n",
      " 'docstring_tokens': ['concatenate',\n",
      "                      'several',\n",
      "                      'file',\n",
      "                      'remove',\n",
      "                      'header',\n",
      "                      'lines'],\n",
      " 'func_name': 'header_without_lines',\n",
      " 'idx': 0,\n",
      " 'language': 'python',\n",
      " 'original_string': ['def header_without_lines(header, remove):\\n',\n",
      "                     '    \"\"\"Return :py:class:`Header` without lines given in '\n",
      "                     '``remove``\\n',\n",
      "                     '\\n',\n",
      "                     '    ``remove`` is an iterable of pairs ``key``/``ID`` '\n",
      "                     'with the VCF header key\\n',\n",
      "                     '    and ``ID`` of entry to remove.  In the case that a '\n",
      "                     'line does not have\\n',\n",
      "                     '    a ``mapping`` entry, you can give the full value to '\n",
      "                     'remove.\\n',\n",
      "                     '\\n',\n",
      "                     '    .. code-block:: python\\n',\n",
      "                     '\\n',\n",
      "                     '        # header is a vcfpy.Header, e.g., as read '\n",
      "                     'earlier from file\\n',\n",
      "                     '        new_header = vcfpy.without_header_lines(\\n',\n",
      "                     \"            header, [('assembly', None), ('FILTER', \"\n",
      "                     \"'PASS')])\\n\",\n",
      "                     '        # now, the header lines starting with '\n",
      "                     '\"##assembly=\" and the \"PASS\"\\n',\n",
      "                     '        # filter line will be missing from new_header\\n',\n",
      "                     '    \"\"\"\\n',\n",
      "                     '    remove = set(remove)\\n',\n",
      "                     '    # Copy over lines that are not removed\\n',\n",
      "                     '    lines = []\\n',\n",
      "                     '    for line in header.lines:\\n',\n",
      "                     '        if hasattr(line, \"mapping\"):\\n',\n",
      "                     '            if (line.key, line.mapping.get(\"ID\", None)) '\n",
      "                     'in remove:\\n',\n",
      "                     '                continue  # filter out\\n',\n",
      "                     '        else:\\n',\n",
      "                     '            if (line.key, line.value) in remove:\\n',\n",
      "                     '                continue  # filter out\\n',\n",
      "                     '        lines.append(line)\\n',\n",
      "                     '    return Header(lines, header.samples)\\n'],\n",
      " 'repo': 'vcfpy',\n",
      " 'url': 'https://github.com/bihealth/vcfpy/blob/99e2165df30f11e0c95f3170f31bc5191d9e9e15/vcfpy/header.py#L227-L253'}\n",
      "no of trainining samples: 356\n"
     ]
    }
   ],
   "source": [
    "# Dump example train file\n",
    "with open(\"train.jsonl\", \"r\") as f:\n",
    "    train_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(train_file[0]))\n",
    "print(f\"no of trainining samples: {len(train_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "635a0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def to_bool(self, value):\\n'\n",
      "         '    if value == None:\\n'\n",
      "         '        return False\\n'\n",
      "         '    elif isinstance(value, bool):\\n'\n",
      "         '        return value\\n'\n",
      "         \"    elif str(value).lower() in ['true', '1', 'yes']:\\n\"\n",
      "         '        return True\\n'\n",
      "         '    else:\\n'\n",
      "         '        return False\\n',\n",
      " 'code_tokens': ['to',\n",
      "                 'bool',\n",
      "                 'self',\n",
      "                 'value',\n",
      "                 'if',\n",
      "                 'value',\n",
      "                 'none',\n",
      "                 'return',\n",
      "                 'false',\n",
      "                 'elif',\n",
      "                 'isinstance',\n",
      "                 'value',\n",
      "                 'bool',\n",
      "                 'return',\n",
      "                 'value',\n",
      "                 'elif',\n",
      "                 'str',\n",
      "                 'value',\n",
      "                 'lower',\n",
      "                 'in',\n",
      "                 'true',\n",
      "                 '1',\n",
      "                 'yes',\n",
      "                 'return',\n",
      "                 'true',\n",
      "                 'else',\n",
      "                 'return',\n",
      "                 'false'],\n",
      " 'docstring': 'convert int to bool',\n",
      " 'docstring_tokens': ['convert', 'int', 'to', 'bool'],\n",
      " 'func_name': 'to_bool',\n",
      " 'idx': 356,\n",
      " 'language': 'python',\n",
      " 'original_string': ['    def to_bool(self, value):\\n',\n",
      "                     '         if value == None:\\n',\n",
      "                     '             return False\\n',\n",
      "                     '         elif isinstance(value, bool):\\n',\n",
      "                     '             return value\\n',\n",
      "                     '         else:\\n',\n",
      "                     '             if str(value).lower() in [\"true\", \"1\", '\n",
      "                     '\"yes\"]:\\n',\n",
      "                     '                 return True\\n',\n",
      "                     '             else:\\n',\n",
      "                     '                 return False\\n'],\n",
      " 'repo': '511-transit',\n",
      " 'url': 'https://github.com/rberrelleza/511-transit/blob/ab676d6e3b57a073405cbfa2ffe1a57b85808fd1/fiveoneone/model.py#L18-L27'}\n",
      "no of valid samples: 83\n"
     ]
    }
   ],
   "source": [
    "# Dump example valid file\n",
    "with open(\"valid.jsonl\", \"r\") as f:\n",
    "    valid_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(valid_file[0]))\n",
    "print(f\"no of valid samples: {len(valid_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36747b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def pack_unsigned_int(number, size, le):\\n'\n",
      "         '    if not isinstance(number, int):\\n'\n",
      "         \"        raise StructError('argument for i,I,l,L,q,Q,h,H must be \"\n",
      "         \"integer')\\n\"\n",
      "         '    if number < 0:\\n'\n",
      "         '        raise TypeError(\"can\\'t convert negative long to unsigned\")\\n'\n",
      "         '    if number > (1 << 8 * size) - 1:\\n'\n",
      "         \"        raise OverflowError('Number:%i too large to convert' % \"\n",
      "         'number)\\n'\n",
      "         '    return pack_int(number, size, le)\\n',\n",
      " 'code_tokens': ['pack',\n",
      "                 'unsigned',\n",
      "                 'int',\n",
      "                 'number',\n",
      "                 'size',\n",
      "                 'le',\n",
      "                 'if',\n",
      "                 'not',\n",
      "                 'isinstance',\n",
      "                 'number',\n",
      "                 'int',\n",
      "                 'raise',\n",
      "                 'structerror',\n",
      "                 'argument',\n",
      "                 'for',\n",
      "                 'must',\n",
      "                 'be',\n",
      "                 'integer',\n",
      "                 'if',\n",
      "                 'number',\n",
      "                 '0',\n",
      "                 'raise',\n",
      "                 'typeerror',\n",
      "                 'can',\n",
      "                 'convert',\n",
      "                 'negative',\n",
      "                 'long',\n",
      "                 'to',\n",
      "                 'unsigned',\n",
      "                 'if',\n",
      "                 'number',\n",
      "                 '1',\n",
      "                 '8',\n",
      "                 'size',\n",
      "                 '1',\n",
      "                 'raise',\n",
      "                 'overflowerror',\n",
      "                 'number',\n",
      "                 'too',\n",
      "                 'large',\n",
      "                 'to',\n",
      "                 'convert',\n",
      "                 'number',\n",
      "                 'return',\n",
      "                 'pack',\n",
      "                 'int',\n",
      "                 'number',\n",
      "                 'size',\n",
      "                 'le'],\n",
      " 'docstring': 'convert string to number',\n",
      " 'docstring_tokens': ['convert', 'string', 'to', 'number'],\n",
      " 'func_name': 'pack_unsigned_int',\n",
      " 'idx': 439,\n",
      " 'language': 'python',\n",
      " 'original_string': ['def pack_unsigned_int(number, size, le):\\n',\n",
      "                     '  if not isinstance(number, int):\\n',\n",
      "                     '    raise StructError(\"argument for i,I,l,L,q,Q,h,H must '\n",
      "                     'be integer\")\\n',\n",
      "                     '  if number < 0:\\n',\n",
      "                     '    raise TypeError(\"can\\'t convert negative long to '\n",
      "                     'unsigned\")\\n',\n",
      "                     '  if number > (1 << (8 * size)) - 1:\\n',\n",
      "                     '    raise OverflowError(\"Number:%i too large to convert\" '\n",
      "                     '% number)\\n',\n",
      "                     '  return pack_int(number, size, le)\\n'],\n",
      " 'repo': 'grumpy',\n",
      " 'url': 'https://github.com/google/grumpy/blob/3ec87959189cfcdeae82eb68a47648ac25ceb10b/third_party/pypy/_struct.py#L101-L108'}\n",
      "no of test samples: 83\n"
     ]
    }
   ],
   "source": [
    "# Dump example test file\n",
    "with open(\"test.jsonl\", \"r\") as f:\n",
    "    test_file = f.readlines()\n",
    "\n",
    "pprint(json.loads(test_file[0]))\n",
    "print(f\"no of test samples: {len(test_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d475f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
